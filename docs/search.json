[
  {
    "objectID": "class_notes/week_9.html",
    "href": "class_notes/week_9.html",
    "title": "Week 9: Recommender Systems",
    "section": "",
    "text": "Talking about Recommender Systems\nWhat kind of data would you need for your project?\nMonday: Basic Recommender Code\nWednesday: Including Spotify Features"
  },
  {
    "objectID": "class_notes/week_9.html#the-cold-start-problem",
    "href": "class_notes/week_9.html#the-cold-start-problem",
    "title": "Week 9: Recommender Systems",
    "section": "The Cold Start Problem",
    "text": "The Cold Start Problem\nThis was all random data. How will you get data for your project? What will it look like for your model to be accurate?"
  },
  {
    "objectID": "class_notes/week_9.html#two-spotify-discover-playlists",
    "href": "class_notes/week_9.html#two-spotify-discover-playlists",
    "title": "Week 9: Recommender Systems",
    "section": "Two Spotify Discover Playlists",
    "text": "Two Spotify Discover Playlists\nWhat if I take my own discover playlist, and find someone else’s and see what it might recommend?\nWe can start by getting data from playlists. Put in your own Spotify data here. I was having some cache issues with my client id, so I’m using the MemoryCacheHandler function from Spotipy.\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom surprise import Dataset, Reader, KNNBasic\nimport pandas as pd\nfrom spotipy.cache_handler import MemoryCacheHandler\n\nclient_credentials_manager = SpotifyClientCredentials(\n    client_id = 'YOUR OWN CLIENT ID',\n    client_secret = 'YOUR OWN CLIENT SECRET',\n    cache_handler=MemoryCacheHandler()\n)\nsp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n\nHere’s a function that grabs the audio data from Spotify, using spotipy and pandas:\n\n# Function to get playlist tracks and audio features\ndef get_playlist_data(playlist_id):\n    results = sp.playlist_tracks(playlist_id)\n    tracks = results['items']\n    \n    data = []\n    for track in tracks:\n        track_id = track['track']['id']\n        audio_features = sp.audio_features(track_id)[0]\n        \n        data.append({\n            'track_id': track_id,\n            'acousticness': audio_features['acousticness'],\n            'danceability': audio_features['danceability'],\n            'energy': audio_features['energy'],\n            'instrumentalness': audio_features['instrumentalness'],\n            'liveness': audio_features['liveness']\n        })\n    \n    return pd.DataFrame(data)\n\nAnd we can add all of the Spotify URIs for the playlist:\n\n# Get data for both playlists\nplaylist1_id = '37i9dQZEVXcIDdjTZ1FKnJ'\nplaylist2_id = '2VYB4MjPYJx3ZOkrjyUvsx'\n\ndf1 = get_playlist_data(playlist1_id)\ndf2 = get_playlist_data(playlist2_id)\n\nNow we will read it into Surprise with the Reader function:\n\n# Assign user IDs (1 for playlist1, 2 for playlist2)\ndf1['user_id'] = 'Dannah Shanalee'\ndf2['user_id'] = 'Hannah Ashlee'\n\n# Combine dataframes\ncombined_df = pd.concat([df1, df2], ignore_index=True)\n\n# Prepare data for Surprise\nreader = Reader(rating_scale=(0, 1))\ndata = Dataset.load_from_df(combined_df[['user_id', 'track_id', 'acousticness']], reader)\n\nHere we have a function that gets the track information (name, artist, and id) to print it later (it was only printing URIs), and then recommend 5 tracks from the other playlist:\n\ndef get_track_info(track_id):\n    try:\n        track_info = sp.track(track_id)\n        return {\n            'name': track_info['name'],\n            'artist': track_info['artists'][0]['name'],\n            'id': track_id\n        }\n    except:\n        return {'name': 'Unknown', 'artist': 'Unknown', 'id': track_id}\n\ndef get_recommendations(track_id, model, n=5):\n    inner_id = model.trainset.to_inner_iid(track_id)\n    neighbors = model.get_neighbors(inner_id, k=n)\n    raw_neighbors = [model.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n    return [get_track_info(track_id) for track_id in raw_neighbors]\n\n# Example: Get recommendations for a track\nsample_track = combined_df['track_id'].iloc[0]\nsample_track_info = get_track_info(sample_track)\nrecommendations = get_recommendations(sample_track, algo)\n\nprint(f\"Recommendations for '{sample_track_info['name']}' by {sample_track_info['artist']}:\")\nfor rec in recommendations:\n    print(f\"- '{rec['name']}' by {rec['artist']} (ID: {rec['id']})\")\n\nAnd we get five new recommendations from the other playlist:\n\nRecommendations for 'Lily Pad on Your Doorstep' by Don't Stop or We'll Die:\n- 'Amazing Glow' by Pernice Brothers (ID: 6ViAxolMqWD1d6JrqgPZKc)\n- 'Rang Tang Ring Toon' by Mountain Man (ID: 2HZRjBrPeo3HwyZVUZxK62)\n- 'Amsterdam' by Guster (ID: 3fv9cBtpMOaFaIAO4uVRBV)\n- 'Bernadette' by Elle Cordova (ID: 4NFhb4AOPBulDFgxyoXaLH)\n- 'Tire Swing' by Kimya Dawson (ID: 0vbhRDi46TDNHkhKbZa81B)"
  },
  {
    "objectID": "class_notes/week_8.html",
    "href": "class_notes/week_8.html",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "",
    "text": "Today:\n\nTalk about discussion posts\nQuick aside on grabbing specific features from Timbre\nLooking at lyric analysis\n\nWednesday:\n\nProjects due this week (Wednesday Night at 11:59)\nBegin discussion on Recommender Systems (the topic of project 4)\n\n\n\n## Loading some libraries\nlibrary(tidytext)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(textdata)\nlibrary(DT)\nlibrary(spotifyr)\n\n\nAttaching package: 'spotifyr'\n\nThe following object is masked from 'package:tidytext':\n\n    tidy\n\nlibrary(compmus)"
  },
  {
    "objectID": "class_notes/week_8.html#what-dataset-to-use",
    "href": "class_notes/week_8.html#what-dataset-to-use",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "What dataset to use?",
    "text": "What dataset to use?\nIt’s quite difficult to get lyrics from online sources at the moment. Many of the R interfaces for the Genius API seem to be quite deprecated. Kaggle does have many datasets available, including about 10GB of Genius data. For today, let’s just look at a small dataset of Taylor Swift lyrics."
  },
  {
    "objectID": "class_notes/week_8.html#what-is-tf-idf",
    "href": "class_notes/week_8.html#what-is-tf-idf",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "What is TF-IDF?",
    "text": "What is TF-IDF?\n\ntaylor &lt;- read.csv(\"~/Downloads/taylor_swift_lyrics.csv\")\n\nThere’s been some interesting stuff done on lyrics already. We can modify an existing tutorial on Ed Sheeran for today’s discussion.\n\ntaylor_word_count &lt;- taylor %&gt;%\n  unnest_tokens(word, lyric) %&gt;%\n  group_by(track_title, album) %&gt;%\n  summarise(num_words = n()) %&gt;%\n  arrange(desc(num_words)) \n\n`summarise()` has grouped output by 'track_title'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "class_notes/week_8.html#filtering-words",
    "href": "class_notes/week_8.html#filtering-words",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "Filtering Words",
    "text": "Filtering Words\nThe anti_join function from the tidyverse basically joins all columns that don’t match something. Here, it’s the words that tidytext has defined has stop words.\n\nwords_filtered &lt;- taylor %&gt;%\n  unnest_tokens(word, lyric) %&gt;%\n  anti_join(stop_words) %&gt;%\n  distinct()\n\nJoining with `by = join_by(word)`"
  },
  {
    "objectID": "class_notes/week_8.html#plotting-the-most-words",
    "href": "class_notes/week_8.html#plotting-the-most-words",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "Plotting the most words",
    "text": "Plotting the most words\n\nwords_filtered %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(30) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot() +\n    geom_col(aes(word, n), fill = 'light blue') +\n    theme(legend.position = \"none\", \n          plot.title = element_text(hjust = 0.5),\n          panel.grid.major = element_blank()) +\n    xlab(\"\") + \n    ylab(\"Song Count\") +\n    ggtitle(\"Most Frequently Used Words in Lyrics\") +\n    coord_flip() +\n     theme_bw()\n\nSelecting by n"
  },
  {
    "objectID": "class_notes/week_8.html#word-counts",
    "href": "class_notes/week_8.html#word-counts",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "Word Counts",
    "text": "Word Counts\n\ntaylor_word_count %&gt;%\n  ggplot() +\n    geom_density(aes(x = num_words, fill = album), alpha = 0.5, position = 'stack') +\n    ylab(\"Song Density\") + \n    xlab(\"Word Count per Song\") +\n    ggtitle(\"Word Count Distribution\") +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.title = element_blank(),\n          panel.grid.minor.y = element_blank()) +\n          theme_bw()\n\n\n\n\n\nWords over Time\nHere we can see the changing word count over time in Taylor Swift’s albums.\n\nwords &lt;- words_filtered %&gt;%\n  group_by(year) %&gt;%\n  count(word, year, sort = TRUE) %&gt;%\n  slice(seq_len(8)) %&gt;%\n  ungroup() %&gt;%\n  arrange(year, n) %&gt;%\n  mutate(row = row_number())\n\nwords %&gt;%\n  ggplot(aes(row, n, fill = year)) +\n    geom_col(show.legend = NULL) +\n    labs(x = NULL, y = \"Song Count\") +\n    ggtitle(\"Words Across the Year\") + \n    theme_bw() +  \n    facet_wrap(~year, scales = \"free\") +\n    scale_x_continuous(  # This handles replacement of row \n      breaks = words$row, # notice need to reuse data frame\n      labels = words$word) +\n    coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_8.html#words-by-album",
    "href": "class_notes/week_8.html#words-by-album",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "Words by Album",
    "text": "Words by Album\nThis basically does the same as before, but breaks it down by album and not year.\n\nwords &lt;- words_filtered %&gt;%\n  group_by(album) %&gt;%\n  count(word, album, sort = TRUE) %&gt;%\n  slice(seq_len(8)) %&gt;%\n  ungroup() %&gt;%\n  arrange(album, n) %&gt;%\n  mutate(row = row_number())\n\nwords %&gt;%\n  ggplot(aes(row, n, fill = album)) +\n    geom_col(show.legend = NULL) +\n    labs(x = NULL, y = \"Song Count\") +\n    ggtitle(\"Words Across the Album\") + \n    theme_bw() +  \n    facet_wrap(~album, scales = \"free\") +\n    scale_x_continuous(  # This handles replacement of row \n      breaks = words$row, # notice need to reuse data frame\n      labels = words$word) +\n    coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_8.html#tf-idf",
    "href": "class_notes/week_8.html#tf-idf",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "TF-IDF",
    "text": "TF-IDF\nWhere it starts to get interesting is when we can begin to employ metrics of frequency in relation to other data points. The Term Infrequency-Inverse Document Frequency (TF-IDF) metric is a good starting point for that.\nBasically, TF-IDF measures not just how often a word occurs, but how often it occurs in relation to other collections. So if there’s a word that occurs everywhere (like “love”), it’s not really weighted as highly.\n\ntfidf_words_album &lt;- taylor %&gt;%\n  unnest_tokens(word, lyric) %&gt;%\n  distinct() %&gt;%\n  count(album, word, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  bind_tf_idf(word, album, n) %&gt;%\n  arrange(desc(tf_idf))\n\nThis grabs the top 10 words per album. Notice that the tf_idf metric is simply the product of tf (term frequency) multiplied by idf (inverse document frequency).\n\ntop_tfidf_words_album &lt;- tfidf_words_album %&gt;% \n  group_by(album) %&gt;% \n  slice(seq_len(10)) %&gt;%\n  ungroup() %&gt;%\n  arrange(album, tf_idf) %&gt;%\n  mutate(row = row_number())  \n\ntop_tfidf_words_album %&gt;% datatable(filter=\"top\")\n\n\n\n\n\n\nWe can plot the data like so:\n\ntop_tfidf_words_album %&gt;%\n  ggplot(aes(x = row, tf_idf, fill = album)) +\n  geom_col(show.legend = NULL) +\n  labs(x = NULL, y = \"TF-IDF\") + \n  ggtitle(\"Important Words by Album (as measured by TF-IDF)\") +\n  theme_bw() +  \n  facet_wrap(~album,\n             scales = \"free\") +\n  scale_x_continuous(  # this handles replacement of row \n    breaks = top_tfidf_words_album$row, # notice need to reuse data frame\n    labels = top_tfidf_words_album$word) +\n  coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_8.html#sentiment-analysis",
    "href": "class_notes/week_8.html#sentiment-analysis",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nWe can then run sentiment analysis on the lyrics after unnesting and getting rid of stop words.\n\ntaylor_words &lt;- taylor %&gt;%\n  ##this breaks the lyrics up into words.\n  unnest_tokens(word, lyric) %&gt;% \n  ## the stop words come from tidytext.\n  anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\n\nWe will start with the bing classification (named after the PI of the research group, Liu Bing). This classifies words as either positive or negative sentiment. See this PsychStat book for more on these metrics.\n\ntaylor_bing &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"bing\"))\n\nJoining with `by = join_by(word)`\n\n\nWe can also run the nrc word list, which puts words into positive or negative categories, but also uses 8 other emotions, including:\n\nanger\nanticipation\ndisgust\nfear\njoy\nsadness\nsurprise\ntrust\n\nSee the “sentiment” column below in the table. To what extent do we agree with these categories? Do they seem useful to you?\n\ntaylor_nrc &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"nrc\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc %&gt;% datatable(filter =\"top\") \n\n\n\n\n\n\nWe can clean this up by getting rid of the positive and negative emotions, if we’d like:\n\ntaylor_nrc_no_pos_neg &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"nrc\")) %&gt;%\n  filter(!sentiment %in% c(\"positive\", \"negative\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc_no_pos_neg %&gt;% datatable(filter =\"top\")\n\n\n\n\n\n\nAnd here we can get have only the listing of words rated as “positive” or “negative”.\n\ntaylor_nrc_pos_neg &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"nrc\")) %&gt;%\n  filter(sentiment %in% c(\"positive\", \"negative\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc_pos_neg %&gt;% datatable(filter =\"top\")\n\n\n\n\n\n\nAnd here we can plot everything:\n\nnrc_plot &lt;- taylor_nrc %&gt;%\n  group_by(sentiment) %&gt;%\n  summarise(word_count = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(sentiment = reorder(sentiment, word_count)) %&gt;%\n  ggplot(aes(sentiment, word_count, fill = -word_count)) +\n  geom_col() +\n  theme_bw() +\n  labs(x = NULL, y = \"Word Count\") +\n  ggtitle(\"NRC Sentiment\") +\n  coord_flip()\nnrc_plot + guides(fill=FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\nWe can write a function to look at the various sentiments of a tune, which we can then join with other data.\n\ncalculate_sentiment &lt;- function(df){\n  df %&gt;%\n    group_by(track_title) %&gt;%\n    unnest_tokens(word, lyric) %&gt;%\n    left_join(get_sentiments(\"nrc\"), multiple = \"all\") %&gt;%\n    filter(!is.na(sentiment)) %&gt;%\n    count(sentiment) %&gt;%\n    pivot_wider(names_from = sentiment, values_from = n) %&gt;%\n    mutate(sentiment = positive - negative)\n}\n\ncalculate_sentiment(taylor) \n\nJoining with `by = join_by(word)`\n\n\nWarning in left_join(., get_sentiments(\"nrc\"), multiple = \"all\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 14 of `x` matches multiple rows in `y`.\nℹ Row 7687 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 94 × 12\n# Groups:   track_title [94]\n   track_title  anger anticipation disgust  fear   joy negative positive sadness\n   &lt;chr&gt;        &lt;int&gt;        &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;    &lt;int&gt;   &lt;int&gt;\n 1 ...Ready fo…     3           10       4     9     8        9        9       4\n 2 22               9           13       9     7    11       12       14      10\n 3 A Perfectly…     4            8       4     4    12        5       14       5\n 4 A Place In …     1            4       1     1     3        4        4       2\n 5 All Too Well     5            6       3     2     4       11        7       6\n 6 All You Had…    NA           NA       1    NA     2        5        2       4\n 7 Back To Dec…     1           17      NA     9    16        9       22       7\n 8 Bad Blood       22            3      20    22    27       24       27      22\n 9 Begin Again     NA            4      NA    NA     6        1       13       1\n10 Better Than…     9           14       6    12    11       14       17       5\n# ℹ 84 more rows\n# ℹ 3 more variables: surprise &lt;int&gt;, trust &lt;int&gt;, sentiment &lt;int&gt;\n\n\nAnd we can combine it with Spotify data!\nLet’s get the spotify data…\n\nts &lt;- get_artist_audio_features(\"Taylor Swift\")\n# ts &lt;- get_playlist_audio_fea\"tures(\"spotify\", \"3dgpO6mDWzdpMhyttrVi9t?si=b4f962245cb7468a\")\n\nAnd now we can combine the data together…\n\nts_basic_audio &lt;- ts %&gt;%\n  select(track_name, danceability:tempo, album_name) %&gt;%\n  rename(track_title = track_name)\n\njoined_ts &lt;- calculate_sentiment(taylor) %&gt;%\n  left_join(ts_basic_audio)\n\nJoining with `by = join_by(word)`\n\n\nWarning in left_join(., get_sentiments(\"nrc\"), multiple = \"all\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 14 of `x` matches multiple rows in `y`.\nℹ Row 7687 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nJoining with `by = join_by(track_title)`\n\njoined_ts %&gt;% \n  datatable(filter=\"top\")\n\n\n\n\n\n\nHere’s the code to plot the overall positive/negative of the tune:\n\nts &lt;- get_artist_audio_features(\"Taylor Swift\")\n\n\nts_basic_audio &lt;- ts %&gt;%\n  select(track_name, danceability:tempo) %&gt;%\n  rename(track_title = track_name) |&gt;\n  distinct()\n\njoined_ts &lt;- calculate_sentiment(taylor) %&gt;%\n  left_join(ts_basic_audio, multiple = \"all\")\n\nJoining with `by = join_by(word)`\n\n\nWarning in left_join(., get_sentiments(\"nrc\"), multiple = \"all\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 14 of `x` matches multiple rows in `y`.\nℹ Row 7687 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nJoining with `by = join_by(track_title)`\n\njoined_ts %&gt;%\n  select(track_title, positive, negative) %&gt;%\n  pivot_longer(cols = positive:negative, names_to = \"sentiment\", values_to = \"value\") %&gt;%\n  ggplot(aes(x = reorder(track_title, value), y = value, color = sentiment)) +\n  geom_point() +\n  coord_flip() +\n  theme_classic() +\n  labs(title = \"Taylor's Sentiments Across Tracks\",\n       y = 'Sentiment Value',\n       x = \"Track\")\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "class_notes/week_8.html#blur-and-oasis",
    "href": "class_notes/week_8.html#blur-and-oasis",
    "title": "Week 8: Text, TF-IDF, etc.",
    "section": "Blur and Oasis",
    "text": "Blur and Oasis\nThis data is taken from the “Million Song Dataset” from Spotify.\n\noasis &lt;- read.csv(\"oasis.csv\")\nblur &lt;- read.csv(\"blur.csv\")\n\nAnd we can begin getting words like this:\n\noasis_words &lt;- oasis %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  anti_join(stop_words) %&gt;%\n  distinct()\n\nContinuing with a summary like so…\n\nfull_word_count &lt;- oasis %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  group_by(track_title) %&gt;%\n  summarise(num_words = n()) %&gt;%\n  arrange(desc(num_words))"
  }
]