{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Week 9: Recommender Systems\"\n",
    "execute:\n",
    "  echo: true\n",
    "  eval: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan for the Week \n",
    "\n",
    "- Talking about Recommender Systems\n",
    "- What kind of data would you need for your project? \n",
    "- Monday: Basic Recommender Code \n",
    "- Wednesday: Including Spotify Features\n",
    "\n",
    "\n",
    "# Monday\n",
    "\n",
    "The code below generates fake ratings for each user for a bunch of songs: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                         track_title  ratings\n",
      "0        Khoi                             Imagine        2\n",
      "1         Leo                Sounds of a Campfire        5\n",
      "2        Khoi                Sounds of a Campfire        4\n",
      "3         Leo                     Johnny B. Goode        5\n",
      "4         Sid                      2 Legit 2 Quit        5\n",
      "..        ...                                 ...      ...\n",
      "95  Stephanie                   The NU Fight Song        1\n",
      "96       Khoi                       Fade to Black        5\n",
      "97       Khoi                     Good Vibrations        5\n",
      "98       Khoi  Dan Shanahan Rocking on the Guitar        4\n",
      "99       Khoi                         Schools Out        4\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Define users and songs\n",
    "users = ['Alex', 'Stephanie', 'Hannah', 'Kelvin', 'Khoi', 'Leo', 'Ally', 'Jordan', 'Sid', 'Jacob']\n",
    "songs = [\n",
    "    'Respect', 'In The Mood', 'White Christmas', 'Johnny B. Goode', 'Over The Rainbow',\n",
    "    'Thriller', 'Imagine', 'Billie Jean', 'Hotel California', 'Stairway to Heaven', 'Shake it Off', \n",
    "    'As it Was', 'Truth Hurts', 'All I Want for Christmas', 'Fade to Black', 'Enter Sandman', 'Smells Like Teen Spirit',\n",
    "    'Paranoid Android', 'Sgt. Pepper', 'Help', 'Good Vibrations', 'Happy', '2 Legit 2 Quit', 'Happy Birthday', 'Happy', \n",
    "    'The Theme from the 90s TV Show E.R', 'Elephants Playing Gongs', 'Raindrops Keep Falling on My Head', 'Beethoven 9',\n",
    "    'Dolphins Singing', 'The NU Fight Song', 'Bach?', 'Do you really want to hurt me?', 'Schools Out', 'Jesses Girl',\n",
    "    'Dan Shanahan Yelling', 'Dan Shanahan Rocking on the Guitar', 'Sounds of a Campfire'\n",
    "\n",
    "]\n",
    "\n",
    "# Generate random ratings\n",
    "data = []\n",
    "for i in range(2000):\n",
    "    user = random.choice(users)\n",
    "    song = random.choice(songs)\n",
    "    rating = random.randint(1, 5)\n",
    "    data.append({'user_id': user, 'track_title': song, 'ratings': rating})\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "# if you want to save it as a csv:\n",
    "# df.to_csv('spotify_data.csv', index=False)\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It ends up looking something like this:\n",
    "\n",
    "```{txt}\n",
    "      user_id       track_title  ratings\n",
    "0         Leo       Schools Out        2\n",
    "1      Jordan     Enter Sandman        4\n",
    "2       Jacob  Over The Rainbow        1\n",
    "3      Jordan  Paranoid Android        4\n",
    "4      Hannah     Fade to Black        1\n",
    "..        ...               ...      ...\n",
    "95        Leo       Jesses Girl        4\n",
    "96      Jacob             Happy        4\n",
    "97  Stephanie     Fade to Black        4\n",
    "98     Kelvin       Truth Hurts        2\n",
    "99        Leo              Help        1\n",
    "```\n",
    "\n",
    "### Beginning Recommender Code with Surprise\n",
    "\n",
    "First, we will begin by loading all of the libraries. Here, I'm going to be using pandas, and a number of modules from the Surprise toolkit. If you don't already have it installed, typing `pip intall surprise` into your Python environment will install it for you.\n",
    "\n",
    "Once the libraries are loaded, you can import the dataframe `df` that we created above, and load it into surprise's `Reader` object. Then, we can do an 80/20 training and testing split quite easily with the built-in train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic, KNNWithMeans\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Create a Surprise Reader object\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data into the Surprise Dataset format\n",
    "data = Dataset.load_from_df(df[['user_id', 'track_title', 'ratings']], reader)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to, in effect, fill in the blank spots in our matrix. Surprise has a number of algorithms built in. Singular Value Decomposition (SVD) is probably the most commonly-used one, but there are many KNNs bundled, as well. Here I've used the KNNBasic. I then use that algorithm to train on the training dataset, and then predict with the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Use SVD algorithm\n",
    "# algo = SVD()\n",
    "algo = KNNBasic()\n",
    "# algo = KNNWithMeans()\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make predictions on the testset\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could also look at a content based system with a different form of similarity, here using a geometric approach, if I wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # compute  similarities between items, not users!!!\n",
    "}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "# algo = KNNWithMeans()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some functions for getting the top recommendations for each user. Note that I loop over the user id, item id, and rating, as well as the estimate. I then grab the top 10 from these and sort the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N recommendations for a user\n",
    "def get_top_n_recommendations(predictions, n=10):\n",
    "    top_n = {}\n",
    "    for user_id, item_id, true_rating, est, i in predictions:\n",
    "        if user_id not in top_n:\n",
    "            top_n[user_id] = []\n",
    "        top_n[user_id].append((item_id, est))\n",
    "    \n",
    "    # Sort the predictions for each user and retrieve the top ones\n",
    "    for user_id, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[user_id] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# Get top 5 recommendations for each user\n",
    "top_n = get_top_n_recommendations(predictions, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a printing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top track recommendations for user Jordan:\n",
      "Track Title: Dan Shanahan Rocking on the Guitar, Estimated Rating: 3.51\n",
      "Track Title: Happy, Estimated Rating: 3.42\n",
      "Track Title: Happy, Estimated Rating: 3.42\n",
      "Track Title: Happy, Estimated Rating: 3.42\n",
      "Track Title: Happy, Estimated Rating: 3.42\n",
      "\n",
      "Top track recommendations for user Stephanie:\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.65\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.65\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.65\n",
      "Track Title: Schools Out, Estimated Rating: 3.60\n",
      "Track Title: Schools Out, Estimated Rating: 3.60\n",
      "\n",
      "Top track recommendations for user Alex:\n",
      "Track Title: Stairway to Heaven, Estimated Rating: 3.77\n",
      "Track Title: Elephants Playing Gongs, Estimated Rating: 3.52\n",
      "Track Title: Happy Birthday, Estimated Rating: 3.46\n",
      "Track Title: Happy Birthday, Estimated Rating: 3.46\n",
      "Track Title: Happy Birthday, Estimated Rating: 3.46\n",
      "\n",
      "Top track recommendations for user Kelvin:\n",
      "Track Title: Schools Out, Estimated Rating: 3.76\n",
      "Track Title: Schools Out, Estimated Rating: 3.76\n",
      "Track Title: Happy Birthday, Estimated Rating: 3.48\n",
      "Track Title: Happy Birthday, Estimated Rating: 3.48\n",
      "Track Title: The Theme from the 90s TV Show E.R, Estimated Rating: 3.36\n",
      "\n",
      "Top track recommendations for user Jacob:\n",
      "Track Title: As it Was, Estimated Rating: 3.52\n",
      "Track Title: Fade to Black, Estimated Rating: 3.42\n",
      "Track Title: Fade to Black, Estimated Rating: 3.42\n",
      "Track Title: Hotel California, Estimated Rating: 3.40\n",
      "Track Title: Schools Out, Estimated Rating: 3.38\n",
      "\n",
      "Top track recommendations for user Leo:\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.54\n",
      "Track Title: Happy Birthday, Estimated Rating: 3.53\n",
      "Track Title: The Theme from the 90s TV Show E.R, Estimated Rating: 3.43\n",
      "Track Title: Johnny B. Goode, Estimated Rating: 3.36\n",
      "Track Title: Johnny B. Goode, Estimated Rating: 3.36\n",
      "\n",
      "Top track recommendations for user Hannah:\n",
      "Track Title: Dan Shanahan Rocking on the Guitar, Estimated Rating: 3.67\n",
      "Track Title: Johnny B. Goode, Estimated Rating: 3.55\n",
      "Track Title: Do you really want to hurt me?, Estimated Rating: 3.38\n",
      "Track Title: Happy, Estimated Rating: 3.36\n",
      "Track Title: Happy, Estimated Rating: 3.36\n",
      "\n",
      "Top track recommendations for user Khoi:\n",
      "Track Title: Hotel California, Estimated Rating: 3.68\n",
      "Track Title: Hotel California, Estimated Rating: 3.68\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.60\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.60\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.60\n",
      "\n",
      "Top track recommendations for user Sid:\n",
      "Track Title: Dan Shanahan Rocking on the Guitar, Estimated Rating: 3.73\n",
      "Track Title: The Theme from the 90s TV Show E.R, Estimated Rating: 3.50\n",
      "Track Title: Dolphins Singing, Estimated Rating: 3.50\n",
      "Track Title: Fade to Black, Estimated Rating: 3.44\n",
      "Track Title: Imagine, Estimated Rating: 3.42\n",
      "\n",
      "Top track recommendations for user Ally:\n",
      "Track Title: Johnny B. Goode, Estimated Rating: 3.82\n",
      "Track Title: Hotel California, Estimated Rating: 3.55\n",
      "Track Title: Schools Out, Estimated Rating: 3.49\n",
      "Track Title: Elephants Playing Gongs, Estimated Rating: 3.30\n",
      "Track Title: Elephants Playing Gongs, Estimated Rating: 3.30\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 recommendations\n",
    "for i, (user, recommendations) in enumerate(list(top_n.items())):\n",
    "    print(f\"\\nTop track recommendations for user {user}:\")\n",
    "    for j, (track_id, estimated_rating) in enumerate(recommendations, 10):\n",
    "        print(f\"Track Title: {track_id}, Estimated Rating: {estimated_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this gets the following results:\n",
    "\n",
    "```{txt}\n",
    "Computing the msd similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "\n",
    "Top track recommendations for user Khoi:\n",
    "Track Title: Schools Out, Estimated Rating: 3.38\n",
    "Track Title: Help, Estimated Rating: 3.29\n",
    "Track Title: Beethoven 9, Estimated Rating: 3.18\n",
    "Track Title: Over The Rainbow, Estimated Rating: 3.16\n",
    "Track Title: Stairway to Heaven, Estimated Rating: 3.14\n",
    "\n",
    "Top track recommendations for user Hannah:\n",
    "Track Title: Good Vibrations, Estimated Rating: 3.39\n",
    "Track Title: Good Vibrations, Estimated Rating: 3.39\n",
    "Track Title: Good Vibrations, Estimated Rating: 3.39\n",
    "Track Title: Imagine, Estimated Rating: 3.32\n",
    "Track Title: Imagine, Estimated Rating: 3.32\n",
    "\n",
    "etc.\n",
    "```\n",
    "\n",
    "The standard way for evaluating the accuracy of the algorithm is the RMSE (root mean square error). Again, Surprise has a built-in method for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we end up with:\n",
    "\n",
    "```{txt}\n",
    "RMSE: 1.4986\n",
    "```\n",
    "\n",
    "This isn't great. I think for movies, I've seen people shoot for .8; for other things it's even better than that (lower is better).\n",
    "\n",
    "### Visualizing the Similarity\n",
    "\n",
    "We can look at the similarity of items with a bit of help from Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # Extract the similarity matrix\n",
    "# sim_matrix = algo.sim\n",
    "# \n",
    "# # Convert to a pandas DataFrame\n",
    "# df_sim = pd.DataFrame(sim_matrix)\n",
    "\n",
    "# Create a heatmap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(df_sim, cmap='YlGnBu')\n",
    "# plt.title('Item Similarity Matrix Heatmap')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give us this:\n",
    "![Item Similarity Matrix](../images/item-similarity-matrix.png)\n",
    "\n",
    "\n",
    "## The Cold Start Problem\n",
    "\n",
    "This was all random data. How will you get data for your project? What will it look like for your model to be accurate?\n",
    "\n",
    "\n",
    "## Two Spotify Discover Playlists\n",
    "\n",
    "What if I take my own discover playlist, and find someone else's and see what it might recommend?\n",
    "\n",
    "We can start by getting data from playlists. Put in your own Spotify data here. I was having some cache issues with my client id, so I'm using the `MemoryCacheHandler` function from Spotipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "import pandas as pd\n",
    "from spotipy.cache_handler import MemoryCacheHandler\n",
    "\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id = 'YOUR OWN CLIENT ID',\n",
    "    client_secret = 'YOUR OWN CLIENT SECRET',\n",
    "    cache_handler=MemoryCacheHandler()\n",
    ")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function that grabs the audio data from Spotify, using spotipy and pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get playlist tracks and audio features\n",
    "def get_playlist_data(playlist_id):\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    tracks = results['items']\n",
    "    \n",
    "    data = []\n",
    "    for track in tracks:\n",
    "        track_id = track['track']['id']\n",
    "        audio_features = sp.audio_features(track_id)[0]\n",
    "        \n",
    "        data.append({\n",
    "            'track_id': track_id,\n",
    "            'acousticness': audio_features['acousticness'],\n",
    "            'danceability': audio_features['danceability'],\n",
    "            'energy': audio_features['energy'],\n",
    "            'instrumentalness': audio_features['instrumentalness'],\n",
    "            'liveness': audio_features['liveness']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can add all of the Spotify URIs for the playlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SpotifyOauthError",
     "evalue": "error: invalid_client, error_description: Invalid client",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/oauth2.py\u001b[0m in \u001b[0;36m_request_access_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m             )\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0mtoken_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://accounts.spotify.com/api/token",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSpotifyOauthError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qm/x0jnv3rn5nggh1kkgswgjjlc0000gn/T/ipykernel_45529/151028551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplaylist2_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2VYB4MjPYJx3ZOkrjyUvsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_playlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist1_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_playlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist2_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/qm/x0jnv3rn5nggh1kkgswgjjlc0000gn/T/ipykernel_45529/3712135545.py\u001b[0m in \u001b[0;36mget_playlist_data\u001b[0;34m(playlist_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function to get playlist tracks and audio features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_playlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaylist_tracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36mplaylist_tracks\u001b[0;34m(self, playlist_id, fields, limit, offset, market, additional_types)\u001b[0m\n\u001b[1;32m    682\u001b[0m         )\n\u001b[1;32m    683\u001b[0m         return self.playlist_items(playlist_id, fields, limit, offset,\n\u001b[0;32m--> 684\u001b[0;31m                                    market, additional_types)\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     def playlist_items(\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36mplaylist_items\u001b[0;34m(self, playlist_id, fields, limit, offset, market, additional_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0mmarket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0madditional_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         )\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, args, payload, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_internal_call\u001b[0;34m(self, method, url, payload, params)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auth_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"content_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_auth_headers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/oauth2.py\u001b[0m in \u001b[0;36mget_access_token\u001b[0;34m(self, as_dict, check_cache)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_info\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mas_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtoken_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"access_token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mtoken_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mtoken_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_custom_values_to_token_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_token_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/oauth2.py\u001b[0m in \u001b[0;36m_request_access_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_oauth_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_custom_values_to_token_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/r-miniconda/lib/python3.7/site-packages/spotipy/oauth2.py\u001b[0m in \u001b[0;36m_handle_oauth_error\u001b[0;34m(self, http_error)\u001b[0m\n\u001b[1;32m    149\u001b[0m             ),\n\u001b[1;32m    150\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0merror_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSpotifyOauthError\u001b[0m: error: invalid_client, error_description: Invalid client"
     ]
    }
   ],
   "source": [
    "# Get data for both playlists\n",
    "playlist1_id = '37i9dQZEVXcIDdjTZ1FKnJ'\n",
    "playlist2_id = '2VYB4MjPYJx3ZOkrjyUvsx'\n",
    "\n",
    "df1 = get_playlist_data(playlist1_id)\n",
    "df2 = get_playlist_data(playlist2_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will read it into Surprise with the Reader function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign user IDs (1 for playlist1, 2 for playlist2)\n",
    "df1['user_id'] = 'Dannah Shanalee'\n",
    "df2['user_id'] = 'Hannah Ashlee'\n",
    "\n",
    "# Combine dataframes\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(combined_df[['user_id', 'track_id', 'acousticness']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a function that gets the track information (name, artist, and id) to print it later (it was only printing URIs), and then recommend 5 tracks from the other playlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_info(track_id):\n",
    "    try:\n",
    "        track_info = sp.track(track_id)\n",
    "        return {\n",
    "            'name': track_info['name'],\n",
    "            'artist': track_info['artists'][0]['name'],\n",
    "            'id': track_id\n",
    "        }\n",
    "    except:\n",
    "        return {'name': 'Unknown', 'artist': 'Unknown', 'id': track_id}\n",
    "\n",
    "def get_recommendations(track_id, model, n=5):\n",
    "    inner_id = model.trainset.to_inner_iid(track_id)\n",
    "    neighbors = model.get_neighbors(inner_id, k=n)\n",
    "    raw_neighbors = [model.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "    return [get_track_info(track_id) for track_id in raw_neighbors]\n",
    "\n",
    "# Example: Get recommendations for a track\n",
    "sample_track = combined_df['track_id'].iloc[0]\n",
    "sample_track_info = get_track_info(sample_track)\n",
    "recommendations = get_recommendations(sample_track, algo)\n",
    "\n",
    "print(f\"Recommendations for '{sample_track_info['name']}' by {sample_track_info['artist']}:\")\n",
    "for rec in recommendations:\n",
    "    print(f\"- '{rec['name']}' by {rec['artist']} (ID: {rec['id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we get five new recommendations:\n",
    "\n",
    "```{txt}\n",
    "\n",
    "Recommendations for 'Lily Pad on Your Doorstep' by Don't Stop or We'll Die:\n",
    "- 'Amazing Glow' by Pernice Brothers (ID: 6ViAxolMqWD1d6JrqgPZKc)\n",
    "- 'Rang Tang Ring Toon' by Mountain Man (ID: 2HZRjBrPeo3HwyZVUZxK62)\n",
    "- 'Amsterdam' by Guster (ID: 3fv9cBtpMOaFaIAO4uVRBV)\n",
    "- 'Bernadette' by Elle Cordova (ID: 4NFhb4AOPBulDFgxyoXaLH)\n",
    "- 'Tire Swing' by Kimya Dawson (ID: 0vbhRDi46TDNHkhKbZa81B)\n",
    "```\n",
    "\n",
    "After working through this example, in class, we realized that it wasn't really doing what we thought it was doing. We thought it was picking the top tracks from the other playlist, but in fact it was taking a *single track* and picking five similar tracks from *that same playlist*. \n",
    "\n",
    "So for Wednesday we want to do a few things:\n",
    "\n",
    "1. Look at two playlists, and **use the entire set of songs** to predict a single new song from playlist 1 for the user of playlist 2.\n",
    "2. We want to compare a few different models and see what this looks like, comparing the accuracy as needed.\n",
    "\n",
    "# Wednesday\n",
    "\n",
    "So let's start from scratch.\n",
    "\n",
    "## Importing the Libraries and the Data\n",
    "\n",
    "First, I'm going to import the spotipy, pandas, and surprise. I'm also going to import specific authentication and cache things with spotipy, and some models with Surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import os\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD\n",
    "import pandas as pd\n",
    "from spotipy.cache_handler import MemoryCacheHandler\n",
    "from surprise.model_selection import cross_validate\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've stored my id stuff locally so you can't add things to my playlists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Access environment variables\n",
    "client_id = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
    "\n",
    "# Set up Spotify client credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getenv('SPOTIFY_CLIENT_ID'))\n",
    "print(os.getenv('SPOTIFY_CLIENT_SECRET'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that those are loaded, let's grab the data from two playlists from Spotify. \n",
    "\n",
    "We will start with a function that takes the playlist uri as an argument, grabs the audio features from the tracks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get playlist tracks and audio features\n",
    "def get_playlist_data(playlist_id):\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    tracks = results['items']\n",
    "    \n",
    "    data = []\n",
    "    for track in tracks:\n",
    "        track_id = track['track']['id']\n",
    "        audio_features = sp.audio_features(track_id)[0]\n",
    "        \n",
    "        data.append({\n",
    "            'track_id': track_id,\n",
    "            'acousticness': audio_features['acousticness'],\n",
    "            'danceability': audio_features['danceability'],\n",
    "            'energy': audio_features['energy'],\n",
    "            'instrumentalness': audio_features['instrumentalness'],\n",
    "            'liveness': audio_features['liveness'],\n",
    "            'mode': audio_features['mode'],\n",
    "            'tempo': audio_features['tempo'],\n",
    "\n",
    "\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function and grab the information from the playlist with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for both playlists\n",
    "playlist1_id = '37i9dQZEVXcIDdjTZ1FKnJ'\n",
    "playlist2_id = '2VYB4MjPYJx3ZOkrjyUvsx'\n",
    "\n",
    "df1 = get_playlist_data(playlist1_id)\n",
    "df2 = get_playlist_data(playlist2_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of data we have from this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how it gets the track URI, and then all of the variables we asked for. All of these are continuous, with the exception of mode, which is a binary (0 or 1).\n",
    "\n",
    "We can add our user data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign user IDs (1 for playlist1, 2 for playlist2)\n",
    "df1['user_id'] = 'Dannah Shanalee'\n",
    "df2['user_id'] = 'Hannah Ashlee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the data has specific user names (here only the first five rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the two dataframes into one here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "combined_df['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see (using the `value_counts` function in `pandas`), that there are 100 songs in Hannah Ashlee's list, and 30 in mine. Not ideal, but we will try to see where it takes us.\n",
    "\n",
    "Now we will load the data into the surprise toolkkit, using the `Reader` function. The rating_scale option gives it a range of ratings. Here it's just 0 or 1, as it's if it's present in a playlist or not, but it could also be from 1 to 5 (if it's reviews) or something like that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_from_df` function in `surprise` is meant to accept three things: the user id, the item id, and a rating. Here, we don't really have a rating, which again isn't ideal. So here I'm just adding in a third thing (acousticness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(combined_df[['user_id', 'track_id', 'acousticness']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Item-Item Recommender System\n",
    "\n",
    "Here I'm going to look at the `sim_options` argument for surprise, which is short for \"similarity options\". \n",
    "\n",
    "There are a few options to try for the name argument:\n",
    "\n",
    "1. `cosine` give us [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "2. `msd` gives use the [mean squared difference similarity](https://en.wikipedia.org/wiki/Mean_squared_error)\n",
    "3. `pearson` gives us the [pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "4. `pearson_baseline` gives us the pearson correlation coefficient with a baseline estimate for ratings, which is meant to account for the overall average rating, and any user or item bias. \n",
    "\n",
    "For now, we can just use `pearson`, but it's worth comparing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I'm going to give options for the model here, including specific model, and whether it's item based or user based.\n",
    "sim_options = {\n",
    "    'name': 'msd',\n",
    "    'user_based': False  # Item-based similarity\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my code for implementing a K-nearest neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dans_algorithm = KNNBasic(sim_options=sim_options)\n",
    "trainset = data.build_full_trainset()\n",
    "dans_algorithm.fit(trainset)\n",
    "sim_matrix = dans_algorithm.compute_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a similarity matrix between items. Here I'll convert it to a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix\n",
    "# Convert to a pandas DataFrame\n",
    "df_sim = pd.DataFrame(sim_matrix)\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is telling me pairwise similarities using msd between the songs in the columns and the songs in the rows.\n",
    "\n",
    "Now that we have similarities, and compare between lists.\n",
    "\n",
    "\n",
    "## Using Data from One List to Recommend to Another\n",
    "\n",
    "Let's start with a function to grab the track info based on the URI. This isn't necessary, but if we want to be able to interpret anything past the URI, we should do this. \n",
    "\n",
    "NOTE: I kept getting errors because of Unknown IDs, it would choke the Spotify API up here. the `try` and `except` are meant to get around that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_info(track_id):\n",
    "    try:\n",
    "        track_info = sp.track(track_id)\n",
    "        return {\n",
    "            'name': track_info['name'],\n",
    "            'artist': track_info['artists'][0]['name'],\n",
    "            'id': track_id\n",
    "        }\n",
    "    except:\n",
    "        return {'name': 'Unknown', 'artist': 'Unknown', 'id': track_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take those original track URIs and write a function to get the recommendations. Here, we get the \"inner id\", which is basically an internal representation used by `surprise`. Then we get the neighbors. \n",
    "\n",
    "A couple of other things:\n",
    "\n",
    "- k is referring to the amount of neighbors; here I've set it to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(track_id, model, n=10):\n",
    "    inner_id = model.trainset.to_inner_iid(track_id)\n",
    "    neighbors = model.get_neighbors(inner_id, k=n)\n",
    "    raw_neighbors = [model.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "    return [get_track_info(track_id) for track_id in raw_neighbors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is code to get the recommendations *for myself* based on this other playlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendations for the user from playlist 2\n",
    "user_id = 'Dannah Shanalee'\n",
    "playlist2_tracks = df2['track_id'].tolist()\n",
    "recommendations = []\n",
    "for track_id in playlist2_tracks:\n",
    "    recs = get_recommendations(track_id, dans_algorithm, n=10)\n",
    "    recommendations.extend(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top 10 recommendations in a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(recommendations).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it might be worth using the `cross_validate` function to see how well this did.\n",
    "\n",
    "In the code below, I use a 5-fold cross validation. Just as a reminder, this does the following steps:\n",
    "\n",
    "1. Partitions the data into 5 \"folds\"\n",
    "2. It then trains the data on 4 folds, and tests it on the other.\n",
    "\n",
    "Then, I look at both \"RMSE\" (Root Mean Square Error) and \"MAE\" (Mean Absolute Error). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(dans_algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qm/x0jnv3rn5nggh1kkgswgjjlc0000gn/T/ipykernel_45529/1984330360.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd_results = pd.DataFrame(results)\n",
    "pd_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to look up what \"good\" RMSE numbers might be for this, and it seems that with a binary rating (as we have here) or lower is considered \"good\", so I think we've done a decent job here.\n",
    "\n",
    "# Some Future Steps\n",
    "\n",
    "1. Here we don't have ratings, which would have actually made this much easier. How might you get ratings?\n",
    "2. Here we are just using audio data, but metadata would really help. We could look at things like genre or artist between playlists, and pre-process the data with a one-hot encoding or something like that.\n",
    "\n",
    "This unworkable code might be one way to do it?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# \n",
    "# # Example DataFrame\n",
    "# data = {\n",
    "#     'user_id': [1, 1, 2, 2, 3, 3],\n",
    "#     'track_id': [101, 102, 101, 103, 102, 104],\n",
    "#     'genres': [['rock', 'pop'], ['pop'], ['rock'], ['jazz'], ['pop', 'jazz'], ['rock', 'jazz']]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# \n",
    "# # One-hot encode the genres\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# genre_encoded = mlb.fit_transform(df['genres'])\n",
    "# genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_)\n",
    "# \n",
    "# # Combine with user_id and track_id\n",
    "# combined_df = pd.concat([df[['user_id', 'track_id']], genre_df], axis=1)\n",
    "# \n",
    "# # Display the combined DataFrame\n",
    "# print(combined_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
