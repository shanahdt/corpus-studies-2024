---
title: "Week 1: Representing Musical Data"
---

# Overview 

This week, we will be working through what it means to represent musical ideas through text. 

It's also probably worth having another look at the [syllabus](../course-syllabus.qmd) and the [course structure](../course-schedule.qmd).

Going forward, it might be worth adding a few things to your computer: I would recommend downloading [R](https://www.r-project.org/about.html) and [RStudio](https://posit.co/download/rstudio-desktop/) onto your personal
machine, as soon as you can.

# Representing Musical Information




# Counting Pitches


## HumdrumR
We will also be doing a lot of in-class examples in R, specifically with the [HumdrumR toolkit](https://computational-cognitive-musicology-lab.github.io/humdrumR/). Some of you may prefer using Python or even the command line for projects, and that's fine, but in class we will mainly be working with R.

 In the code below, we install the necessary library. As you can see, you will need to install `devtools`, which will allow you to install packages that aren't on CRAN from github. 

Then, we install the package (you can uncomment these installation lines as necessary for you.
```{r, warnings=FALSE, message=FALSE, eval=FALSE}
### installing everything as needed
library(devtools)
devtools::install_github("Computational-Cognitive-Musicology-Lab/humdrumR", build_vignettes = TRUE)

```

Once that installation has worked, you can try to load the library:
```{r, warnings=FALSE, message=FALSE, eval=TRUE}
library(humdrumR)
```

In the code below, you can see how we load all of the Chopin files into a `preludes` variable with the `readHumdrum` function. 

Then we subset it by _spines_. We are interested in various ways of calculating pitch, so we looked at `pc` (pitch class), as well as `solfa` and `deg`, which gave us solfege syllables and scale degrees, respectively. 

We then plot this data in a barplot. Note the `|>` or "pipe" that we are using. The older tidyverse-style pipe (`%>%`) will also work here.

```{r, warning=FALSE, message=FALSE}
### Load in Chopin preludes, grab the left hand and see all the scale degrees.
# preludes <- readHumdrum("~/gitcloud/corpora/humdrum_scores/Chopin/Preludes/*.krn")
# left_hand <- subset(preludes, Spine == 1)
# ###solfa, deg, pc
# table_data <- with(left_hand, pc(Token,simple=TRUE)) |> table() 
# barplot(table_data)
```

You can use a similar `with` syntax to get rhythm variables, as seen below:
```{r, warnings=FALSE}
## rhythminterval
# rhythms <- with(preludes[2], duration(Token))

#### group exercise:
#### using a repertoire in the Humdrum scores collection, 
#### print a table of most common musical events.

```

## Playing with Spotify

We can start by loading our `spotifyr` library, and `tidyverse` for good measure:
```{r, warnings=FALSE}
# library(spotifyr)
# library(tidyverse)
```

You will need your own spotify client ID and client secret. You can get them by filling out the brief online form [here](https://developer.spotify.com/dashboard).


For the most part, in this class we will be looking at global features data (the "danceability" of a song), and track-level analysis features, such as chroma vectors.

Here we see how you might grab artist features for Ryan Adams and Taylor Swift, comparing the performances of each of their **1989** albums.
