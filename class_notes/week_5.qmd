---
title: "Week 5: Practicing with Spotify"
---
# The plan for the week:

## Monday
- Check in on discussion posts 
- Check in on Project 2
- Looking at chords and chroma vectors.
- How can we ask research questions of the pitch data and the "global" tempo provided by the API (akin to the in-class project from two weeks ago).

## Wednesday

** No class on Wednesday. **

# Working more with Spotify

## Chroma Vectors

The [Spotify API reference](https://developer.spotify.com/documentation/web-api/reference/get-audio-analysis) defines chroma vector as follows:

This week, we spent quite a bit of time discussing _chroma vectors_.
> Pitch content is given by a “chroma” vector, 
> corresponding to the 12 pitch classes C, C#, D to B, 
> with values ranging from 0 to 1 that describe the relative 
> dominance of every pitch in the chromatic scale. For example 
> a C Major chord would likely be represented by large 
> values of C, E and G (i.e. classes 0, 4, and 7)
> Vectors are normalized to 1 by their strongest dimension, 
> therefore noisy sounds are likely represented by values 
> that are all close to 1, while pure tones are described 
> by one value at 1 (the pitch) and others near 0. 
> As can be seen below, the 12 vector indices are a 
> combination of low-power spectrum values at their 
> respective pitch frequencies.

 ![Chroma Vectors in Spotify](images/chroma_vectors_in_spotify.png)

### Looking at Chroma with `compmus`

[Ashley Burygone's](https://www.amsterdammusiclab.nl/author/john-ashley-burgoyne/)
brilliant compmus library has a nice feature called `get_tidy_audio_analysis` that can get the chroma vectors for us, and the following code can put it into a nice format for us.
```{r}
####loading my libraries
library(tidyverse)
library(compmus)
library(spotifyr)
library(corrplot)
access_token <- get_spotify_access_token()
```

```{r}
### grabbing the "shake it off" pitches.
shake_it_off <-
  get_tidy_audio_analysis("0cqRj7pUJDkTCEsJkx8snD") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
```

The following code allows you to turn it all into a list, and then a matrix, which will allow you to look at pitch-to-pitch transitions (of the most likely choice for pitch in the chroma vector):

```{r}
chroma_names <- c("C", "C#|Db","D", "D#|Eb", "E", "F", "F#|Gb","G", "G#|Ab","A", "A#|Bb","B" )
### here I'm unnesting the data and making it "long"
long_shake_it <- unnest(shake_it_off, cols = pitches)
```


```{r}
### note that I'm using the rep function to repeat all of the chroma names for however long the data frame is, dividing
### it by 12 because of the 12 pitches.
long_shake_it$chroma <- rep(chroma_names, nrow(long_shake_it)/12)

long_shake_it <- long_shake_it |>
  filter(pitches == 1) |>
  mutate(chroma2 = lead(chroma))

x <- as.matrix(table(long_shake_it |> select(chroma, chroma2)))
corrplot(x, is.corr = FALSE, method = "pie")
```

## Chords

Burgoyne's chordogram functions allow us to look at the likely chordal spaces for specific piecses. The code below does a few things:

1. First we define what a major, minor, and seventh chord looks like in terms of pitch space.
2. We then use the key-profiles from the Krumhansl-Kessler article on the probe tone experiments and store them into `major_key` and `minor_key` variables.
3. The circshift function rotates these key profiles through the chord variables and provides the best fit for that moment. This is done through the `key_templates` variable (Notice the `compmus_match_pitch_template` below).


The code below should look familiar from the last week's discussions on key-finding.
```{r}
#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}
chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

```


Here we have a piece of code that grabs a single audio file ("Those magic changes"). In class we listened to it while going through the chordogram. Can you spot the modulation? Why do we get that yellowish color at the end of the graph?

```{r}
those_magic_changes <-
  get_tidy_audio_analysis("1WHauHX7U6FqOWh46lK4IV") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

those_magic_changes |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

### Exercise

1. Find a song that you like, explore it in terms of chord transitions and see what you think of it. Note that this might not be entirely different from your discussion post, but might yield different results. Why do you think that is?
   

## Time


Let's turn our focus now to tempo and time. There are a few different ways to examine tempo with the Spotify API. Today we will look at:

We can elements of tempo such as variability within sections. Here we have a question about the differences in tempo between punk in the 1980s and later punk (1990s and 2000s). I'm interested not just in the tempo, but also the variation of tempo.

There are a couple of points to notice in this code: 

1. Note how we are able to get data from a playlist. A playlist can be a good way for you to construct a sample.
2. Note the add_audio_analysis function from the `compmus` library. This adds **track level analysis information** to the broader list of global information. It's great.

Sit for a minute with this data. You'll see the columns at the end that provided the specific audio analysis for each piece. 

```{r}

eighties_punk <-
  get_playlist_audio_features(
    "kristian",
    "5sxuwIQlaByb6Sx2OEwWTx"
  ) |>
  slice(1:30) |>
  add_audio_analysis()

nineties_and_aughts_punk <-
  get_playlist_audio_features(
    "CW",
    "39sVxPTg7BKwrf2MfgrtcD"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
```

Here we bind both playlists together as a single data frame:

```{r}
punk <- 
  eighties_punk |>
  mutate(genre = "eighties") |>
  bind_rows(nineties_and_aughts_punk |> mutate(genre = "newer"))
```

The spotify analysis gives us section markers as well, and we can use the code below to summarise the tempo, loudness, and duration for each section. Note the use of the `map` function, which takes the input and applies a function to that input (here the `summarise_at` function, and the `summarise_at` itself, which provides a summary of each of these columns. 

Here we are storing it in a variable called `summarised_punk`. 
```{r}
summarised_punk <- punk |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  )
```

Now we take this variable and plot it using ggplot.

The process below is as follows:

1. take the table above with summarized section information and unnest it (this takes the sections list of information and turns it into rows and columns).
2. Pipe that into ggplot, with the aesthetics function plotting the tempo on the x-axis, the standard deviation on the y-axis, the color being which genre we used (eighties or not). The color saturation is set to the loudness variable.
3. We then tell ggplot that we want this to be a scatterplot with the `geom_point` function, and that the size of each point should be the duration of the piece (divided by 60 as Spotify just gives it in seconds).
4. We then add a _rug_ plot which gives the ticks on both axes to show the distribution of events.
5. We then add a black and white theme because nobody likes default graphics.
6. We then add the size of the graph and the axis labels.


```{r}
  summarised_punk |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_bw() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )  
```

In-class exercises:
 
1. How is tempo treated differently across the albums of the Beatles? 
