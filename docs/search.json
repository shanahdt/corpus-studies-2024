[
  {
    "objectID": "class_notes/week_4.html",
    "href": "class_notes/week_4.html",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "Let’s talk about key-finding algorithms.\nExplore where they might disagree, and try to figure out why.\nWhat would it look like to devise your own key-finding algorithm?\n\n\n\nWhen we hear this ringtone, it sounds as though it’s in C, but why?\n\n\n\nNokia\n\n\n\nIt doesn’t begin with C, it begins with G.\nC isn’t the most common note–in fact, it only occurs once before the final bar, and it’s on the “and” of 2 in the third measure (a pretty weak position metrically).\nIs a key just whatever key the piece ends in? If we ended this on A, would it sound like it’s in A minor? It would be the same key signature, and we’d actually have a nice cadential ascent to the final A from the G in the third measure.\n\nSo what gives? Why do we hear this as being in C?\nPerhaps a follow-up question might simply be: what makes us hear something as being in a key?\n\n\n\n\n\nThis approach used what we might call an exclusionary approach, eliminating different key possibilities as pitch classes were introduced over the course of a musical passage.\nFor example, with the Nokia theme, the opening G would fit into seven major keys (G, C, D, F, B-flats, A-flat, E-flat;); six of those keys would include the opening two notes; and three of those six would still be possible when presented with the first three notes. By the end of the first measure, however, the only major key that would encompass all four melody notes would be C major. If more than one key was still available however, the algorithm would place more weight on the pitches present at the start of the piece. This worked quite well on pieces that were overtly tonal, but it was less effective for pieces that contained non-diatonic pitches (which is most pieces!)\n\n\n\nLonguet-Higgins and Steedman's 1971 Key-Finding Algorithm\n\n\n\n\n\nAs you might guess, the Longuet-Higgins and Steedman would miss a lot of musical instances. For example, pieces that have non-harmonic chords would struggle, as would pieces that had a lot of chromatic ornamentations. Ideally an algorithm would allow for these pitches to occur, but acknowledge that pitches in the key might be a better fit than those outside of the key, and that certain pitches in the key should be more heavily weighted than others.\nCarol Krumhansl and Mark Schmuckler (Krumhansl, 1990) would devise an algorithm that tallied up the pitch classes of an excerpt and compared the distribution of these pitch classes to ratings from an earlier probe-tone experiment. (Krumhansl and Kessler, 1982). The weightings can be seen below.\nWe might think of this as a correlational approach. We tally up all of the pitches in a corpus, and then run a correlation on this key-profile. We run this over all of the keys, and the one that best fits is then labeled as “the key”.\n\nlibrary(spotifyr)\nlibrary(compmus)\nlibrary(tidyverse)\nlibrary(purrr)\n\n\nks_major_key &lt;-\n  c(6.35, \n   2.23, \n   3.48, \n   2.33, \n   4.38, \n   4.09, \n   2.52, \n   5.19, \n   2.39, \n   3.66, \n   2.29, \n   2.88)\n\nks_minor_key &lt;-\n  c(6.33, \n  2.68, \n  3.52, \n  5.38, \n  2.60, \n  3.53, \n  2.54, \n  4.75, \n  3.98, \n  2.69, \n  3.34, \n  3.17)\n\nAn interesting distinction here is that of experiment-derived vs. corpus-derived weightings. Should a key-finding algorithm intend to match how we hear key in a controlled lab environment (with basic harmonic progression stimuli), or should they use real music as a starting point? If they use real music, which music?\n\n\n\nHector Bellman created a key-finding algorithm that used Helen Budge’s dissertation from the 1940s as a starting point. Budge tallied up note occurrences in composers from the classical music canon, looking at the tonal makeup of a large collection of pieces. Bellman then used these frequencies as the starting point for his own key-finding algorithm.\n\nmajor &lt;- c(16.80, \n            0.86,\n            12.95,\n            1.41,\n            13.49,\n            11.93,\n            1.25,\n            20.28,\n            1.80,\n            8.04,\n            0.62,\n            10.57)\n\nminor &lt;- c(18.16,\n            0.69,\n            12.99,\n            13.34,\n            1.07,\n            11.15,\n            1.38,\n            21.07,\n            7.49,\n            1.53,\n            0.92,\n            10.21)\n\n\n\n\nDavid Temperley (2001) also employed Western classical music as a starting point for his early key-finding work (not to be confused with his more dynamic Bayesian-informed later work). He used examples from a commonly used music theory textbook (Stefan Kostka and Dorothy Payne’s Tonal Harmony).\n\nmajor &lt;- c(0.748, \n            0.060, \n            0.488,\n            0.082, \n            0.670, \n            0.460, \n            0.096, \n            0.715, \n            0.104, \n            0.366,\n            0.057, \n            0.400)\n\nminor &lt;- c(0.712, \n            0.084, \n            0.474, \n            0.618, \n            0.049, \n            0.460, \n            0.105, \n            0.747, \n            0.404, \n            0.067, \n            0.133, \n            0.330)\n\n\n\n\nBret Aarden (2003) argued that folk music would be a better fit than those generated from classical music. He used the Essen Folksong collection (consisting of thousands of folksongs throughout Europe, although with an uneven balance toward German folksong), to come up with the weightings below.\n\nmajor &lt;- c(17.7661, \n            0.145624, \n            14.9265, \n            0.160186, \n            19.8049, \n            11.3587, \n            0.291248, \n            22.062, \n            0.145624, \n            8.15494, \n            0.232998, \n            4.95122)\n            \nminor &lt;- c(18.2648, \n            0.737619, \n            14.0499, \n            16.8599, \n            0.702494, \n            14.4362, \n            0.702494, \n            18.6161, \n            4.56621, \n            1.93186, \n            7.37619, \n            1.75623)\n\n\n\n\nCraig Sapp argued that we probably didn’t even need to get frequencies from corpora or experiments. If we just assume that the tonic and the dominant (scale degrees 1 and 5) are the most important, and the other pitches in the key are less important, but more important than those not in the key, then we have a pretty simple weighting system (that works quite well!).\n\nmajor &lt;- c(2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1)\n\nminor &lt;- c(2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0.5, 0.5)\n\n\n\n\nJosh Albrecht and I tried our hands at this problem, and picked a set of classical works from the Humdrum corpus, looking at only the first and last eight measures of each. The numbers are below.\n\nmajor &lt;- c(0.238, \n            0.006, \n            0.111, \n            0.006, \n            0.137, \n            0.094, \n            0.016, \n            0.214, \n            0.009, \n            0.080, \n            0.008, \n            0.081) \n\nminor &lt;- c(0.220, \n            0.006, \n            0.104, \n            0.123, \n            0.019, \n            0.103, \n            0.012, \n            0.214, \n            0.062, \n            0.022, \n            0.061, \n            0.052)\n\nWe also tried a Euclidean distance approach, rather than a correlational approach.\nWe tried to explain it as follows:\n\nIn a two-dimensional space, if there were 70% of pitch X and 30% pitch Y, the Cartesian location of the point representing this pitch-class distribution would be at X 1⁄4 0.7 and Y 1⁄4 0.3. In this case, we are examining the distribution of 12 pitch classes, resulting in a 12-dimensional Cartesian space. The pitch-class distribution of each piece is represented by a point in that 12-dimensional space. The distance is then measured between this point and the 24 points representing the 12 major and 12 minor key pitch-class distributions, and the key separated by the shortest distance is taken to be the key of the work.\n\nBelow is a table comparing how well this did to the others.\n\n\n\nComparing the Albrecht and Shanahan to others\n\n\n\n\n\nThey each perform a bit differently on different types of tasks.\n\n\n\nComparing key-finding algorithms in major, minor, and overall (from Albrecht and Shanahan, 2013)\n\n\n\n\n\n\nmusic21 has a number of built-in key-finding algorithms, and it’s nice to be able to compare keys in specific pieces. You can start to see the differences between them, and their respective biases.\nThis code will grab all of the files in a folder (here a number of Yugoslav folk songs):\n\nimport glob\n\n###change this path to be your own!\ndef filebrowser(ext=\"/Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/*.krn\"):\n    \"Returns files with an extension\"\n    return [f for f in glob.glob(ext)]\n\nfile_list = filebrowser()\n\nAnd here I will grab the key of each one and print it out using different algorithms:\n\nfrom music21 import *\nfor kern_file in file_list:\n\n  melody = converter.parse(kern_file)       \n  krum = analysis.discrete.KrumhanslKessler(melody)\n  krum_key = krum.getSolution(melody)\n  \n  aarden = analysis.discrete.AardenEssen(melody)\n  aarden_key = aarden.getSolution(melody)\n\n  bellman = analysis.discrete.BellmanBudge(melody)\n  bellman_key = bellman.getSolution(melody)\n\n  temperley = analysis.discrete.TemperleyKostkaPayne(melody)\n  temperley_key = temperley.getSolution(melody)\n\n  sapp = analysis.discrete.SimpleWeights(melody)\n  sapp_key = sapp.getSolution(melody)\n\nAnd then we can call all of our variables like so:\n\n  print(f'File name: {kern_file}\\nKrumhansl-Kessler: {krum_key}\\nAarden Essen: {aarden_key}\\nBellman-Budge: {bellman_key}\\nTemperley-Kostka-Payne: {temperley_key}\\nSapp Simple-Weightings: {sapp_key}\\n')\n\nThis returns the following results (with a very long list):\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos039.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos005.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: D major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos011.krn\nKrumhansl-Kessler: D major\nAarden Essen: D major\nBellman-Budge: D major\nTemperley-Kostka-Payne: D major\nSapp Simple-Weightings: D major\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos010.krn\nKrumhansl-Kessler: A- major\nAarden Essen: A- major\nBellman-Budge: A- major\nTemperley-Kostka-Payne: A- major\nSapp Simple-Weightings: C# major\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos004.krn\nKrumhansl-Kessler: F major\nAarden Essen: g minor\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: B- major\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos038.krn\nKrumhansl-Kessler: G major\nAarden Essen: e minor\nBellman-Budge: e minor\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos012.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: C major\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos006.krn\nKrumhansl-Kessler: C major\nAarden Essen: C major\nBellman-Budge: C major\nTemperley-Kostka-Payne: C major\nSapp Simple-Weightings: C major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos007.krn\nKrumhansl-Kessler: F major\nAarden Essen: B- major\nBellman-Budge: B- major\nTemperley-Kostka-Payne: B- major\nSapp Simple-Weightings: F major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos013.krn\nKrumhansl-Kessler: D major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos017.krn\nKrumhansl-Kessler: A- major\nAarden Essen: f minor\nBellman-Budge: f minor\nTemperley-Kostka-Payne: A- major\nSapp Simple-Weightings: A- major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos003.krn\nKrumhansl-Kessler: B major\nAarden Essen: E major\nBellman-Budge: E major\nTemperley-Kostka-Payne: E major\nSapp Simple-Weightings: B major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos002.krn\nKrumhansl-Kessler: F major\nAarden Essen: F major\nBellman-Budge: B- major\nTemperley-Kostka-Payne: B- major\nSapp Simple-Weightings: B- major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos016.krn\nKrumhansl-Kessler: D major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: D major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos014.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos028.krn\nKrumhansl-Kessler: a minor\nAarden Essen: g minor\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: d minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos029.krn\nKrumhansl-Kessler: C major\nAarden Essen: C major\nBellman-Budge: C major\nTemperley-Kostka-Payne: C major\nSapp Simple-Weightings: C major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos015.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos001.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos112.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos106.krn\nKrumhansl-Kessler: F major\nAarden Essen: F major\nBellman-Budge: B- major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: B- major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos066.krn\nKrumhansl-Kessler: g minor\nAarden Essen: g minor\nBellman-Budge: g minor\nTemperley-Kostka-Payne: g minor\nSapp Simple-Weightings: g minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos072.krn\nKrumhansl-Kessler: a minor\nAarden Essen: F major\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: F major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos099.krn\nKrumhansl-Kessler: G major\nAarden Essen: a minor\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos098.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos073.krn\nKrumhansl-Kessler: a minor\nAarden Essen: F major\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: d minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos067.krn\nKrumhansl-Kessler: D major\nAarden Essen: e minor\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\nThis code will give us the key, and the confidence of each key, with different algorithms:\n\nimport pandas as pd\nfrom music21 import *\nkrum_kess = []\naarden_essen = []\ntemperley_kp = []\nbellman_budge = []\nsapp_weighted = []\n\ntitles = []\nfor file in file_list:\n  titles.append(file.split(\"/\")[-1])\n  melody = converter.parse(file) \n \n  krum = analysis.discrete.KrumhanslKessler(melody)\n  krum_key = krum.getSolution(melody)\n  coef_krum = round(krum_key.correlationCoefficient, 3)\n  krum_kess.append(f'{krum_key} ({coef_krum})')\n\n  aarden = analysis.discrete.AardenEssen(melody)\n  coef_aarden = round(aarden_key.correlationCoefficient, 3)\n  aarden_key = aarden.getSolution(melody)\n  aarden_essen.append(f'{aarden_key} ({coef_aarden})')\n  \n  bellman = analysis.discrete.BellmanBudge(melody)\n  bellman_key = bellman.getSolution(melody)\n  coef_bellman = round(bellman_key.correlationCoefficient, 3)\n  bellman_budge.append(f'{bellman_key} ({coef_bellman})')\n\n  sapp = analysis.discrete.SimpleWeights(melody)\n  sapp_key = sapp.getSolution(melody)\n  coef_sapp = round(sapp_key.correlationCoefficient, 3)\n  sapp_weighted.append(f'{sapp_key} ({coef_sapp})')\n  \n  temperley = analysis.discrete.TemperleyKostkaPayne(melody)\n  temperley_key = temperley.getSolution(melody)\n  coef_temperley = round(temperley_key.correlationCoefficient, 3)\n  temperley_kp.append(f'{temperley_key} ({coef_temperley})')\n\npd.set_option('max_rows', 371)\ndf = pd.DataFrame(list(zip(titles, krum_kess, aarden_essen, bellman_budge, sapp_weighted, temperley_kp)), columns= ['Chorale','Krumhansl-Kessler', 'Aarden-Essen', 'Bellman-Budge', 'Sapp Weighted', 'Temperley-KP'])\ndf\n\nHere is a table of each key decided by each algorithm:\n\n\n\n\n\n\n\n\n\nChorale\n\n\nKrumhansl-Kessler\n\n\nAarden-Essen\n\n\nBellman-Budge\n\n\nSapp Weighted\n\n\nTemperley-KP\n\n\n\n\n\n\n0\n\n\njugos039.krn\n\n\nb minor (0.64)\n\n\nG major (0.848)\n\n\nG major (0.653)\n\n\ne minor (0.663)\n\n\nG major (0.693)\n\n\n\n\n1\n\n\njugos005.krn\n\n\nG major (0.765)\n\n\nG major (0.793)\n\n\nG major (0.79)\n\n\nD major (0.711)\n\n\nG major (0.827)\n\n\n\n\n2\n\n\njugos011.krn\n\n\nD major (0.839)\n\n\nD major (0.887)\n\n\nD major (0.757)\n\n\nD major (0.753)\n\n\nD major (0.839)\n\n\n\n\n3\n\n\njugos010.krn\n\n\nA- major (0.762)\n\n\nA- major (0.83)\n\n\nA- major (0.773)\n\n\nC# major (0.692)\n\n\nA- major (0.838)\n\n\n\n\n4\n\n\njugos004.krn\n\n\nF major (0.618)\n\n\ng minor (0.886)\n\n\nF major (0.727)\n\n\nB- major (0.686)\n\n\nF major (0.715)\n\n\n\n\n5\n\n\njugos038.krn\n\n\nG major (0.598)\n\n\ne minor (0.827)\n\n\ne minor (0.636)\n\n\nG major (0.587)\n\n\nG major (0.688)\n\n\n\n\n6\n\n\njugos012.krn\n\n\nG major (0.858)\n\n\nG major (0.727)\n\n\nG major (0.688)\n\n\nC major (0.716)\n\n\nG major (0.789)\n\n\n\n\n7\n\n\njugos006.krn\n\n\nC major (0.705)\n\n\nC major (0.753)\n\n\nC major (0.594)\n\n\nC major (0.582)\n\n\nC major (0.696)\n\n\n\n\n8\n\n\njugos007.krn\n\n\nF major (0.768)\n\n\nB- major (0.685)\n\n\nB- major (0.787)\n\n\nF major (0.801)\n\n\nB- major (0.82)\n\n\n\n\n9\n\n\njugos013.krn\n\n\nD major (0.822)\n\n\nG major (0.882)\n\n\nG major (0.859)\n\n\nG major (0.796)\n\n\nG major (0.826)\n\n\n\n\n10\n\n\njugos017.krn\n\n\nA- major (0.696)\n\n\nf minor (0.906)\n\n\nf minor (0.586)\n\n\nA- major (0.575)\n\n\nA- major (0.672)\n\n\n\n\n11\n\n\njugos003.krn\n\n\nB major (0.815)\n\n\nE major (0.683)\n\n\nE major (0.793)\n\n\nB major (0.817)\n\n\nE major (0.781)\n\n\n\n\n12\n\n\njugos002.krn\n\n\nF major (0.837)\n\n\nF major (0.858)\n\n\nB- major (0.828)\n\n\nB- major (0.884)\n\n\nB- major (0.806)\n\n\n\n\n13\n\n\njugos016.krn\n\n\nD major (0.829)\n\n\nG major (0.77)\n\n\nG major (0.843)\n\n\nD major (0.77)\n\n\nG major (0.851)\n\n\n\n\n14\n\n\njugos014.krn\n\n\nG major (0.797)\n\n\nG major (0.907)\n\n\nG major (0.784)\n\n\nG major (0.708)\n\n\nG major (0.857)\n\n\n\n\n15\n\n\njugos028.krn\n\n\na minor (0.547)\n\n\ng minor (0.902)\n\n\nF major (0.667)\n\n\nd minor (0.547)\n\n\nF major (0.659)\n\n\n\n\n16\n\n\njugos029.krn\n\n\nC major (0.64)\n\n\nC major (0.787)\n\n\nC major (0.616)\n\n\nC major (0.577)\n\n\nC major (0.682)\n\n\n\n\n17\n\n\njugos015.krn\n\n\nG major (0.744)\n\n\nG major (0.675)\n\n\nG major (0.611)\n\n\nG major (0.616)\n\n\nG major (0.709)\n\n\n\n\n18\n\n\njugos001.krn\n\n\nb minor (0.733)\n\n\nG major (0.688)\n\n\nG major (0.703)\n\n\ne minor (0.725)\n\n\nG major (0.809)\n\n\n\n\n19\n\n\njugos112.krn\n\n\nb minor (0.66)\n\n\nG major (0.84)\n\n\nG major (0.511)\n\n\ne minor (0.617)\n\n\nG major (0.576)\n\n\n\n\n20\n\n\njugos106.krn\n\n\nF major (0.872)\n\n\nF major (0.649)\n\n\nB- major (0.777)\n\n\nB- major (0.843)\n\n\nF major (0.795)\n\n\n\n\n21\n\n\njugos066.krn\n\n\ng minor (0.771)\n\n\ng minor (0.763)\n\n\ng minor (0.745)\n\n\ng minor (0.713)\n\n\ng minor (0.734)\n\n\n\n\n22\n\n\njugos072.krn\n\n\na minor (0.818)\n\n\nF major (0.734)\n\n\nF major (0.702)\n\n\nF major (0.566)\n\n\nF major (0.692)\n\n\n\n\n23\n\n\njugos099.krn\n\n\nG major (0.662)\n\n\na minor (0.773)\n\n\nG major (0.767)\n\n\nG major (0.719)\n\n\nG major (0.752)\n\n\n\n\n24\n\n\njugos098.krn\n\n\nb minor (0.697)\n\n\nG major (0.847)\n\n\nG major (0.499)\n\n\ne minor (0.568)\n\n\nG major (0.568)\n\n\n\n\n25\n\n\njugos073.krn\n\n\na minor (0.677)\n\n\nF major (0.642)\n\n\nF major (0.619)\n\n\nd minor (0.578)\n\n\nF major (0.648)\n\n\n\n\n26\n\n\njugos067.krn\n\n\nD major (0.619)\n\n\ne minor (0.746)\n\n\nG major (0.663)\n\n\nG major (0.628)\n\n\nG major (0.694)\n\n\n\n\n27\n\n\njugos107.krn\n\n\nG major (0.696)\n\n\nG major (0.718)\n\n\nG major (0.82)\n\n\nG major (0.708)\n\n\nG major (0.833)\n\n\n\n\n28\n\n\njugos113.krn\n\n\nG major (0.788)\n\n\nG major (0.932)\n\n\nG major (0.662)\n\n\nC major (0.699)\n\n\nG major (0.737)\n\n\n\n\n29\n\n\njugos105.krn\n\n\nG major (0.782)\n\n\nG major (0.678)\n\n\nG major (0.854)\n\n\nG major (0.745)\n\n\nG major (0.866)\n\n\n\n\n30\n\n\njugos111.krn\n\n\nG major (0.765)\n\n\nG major (0.943)\n\n\nG major (0.684)\n\n\nC major (0.719)\n\n\nG major (0.75)\n\n\n\n\n31\n\n\njugos059.krn\n\n\nF major (0.81)\n\n\nF major (0.723)\n\n\nF major (0.823)\n\n\nF major (0.729)\n\n\nF major (0.877)\n\n\n\n\n32\n\n\njugos071.krn\n\n\nF major (0.771)\n\n\nF major (0.929)\n\n\nF major (0.888)\n\n\nF major (0.82)\n\n\nF major (0.832)\n\n\n\n\n33\n\n\njugos065.krn\n\n\nF major (0.627)\n\n\nF major (0.908)\n\n\nF major (0.577)\n\n\nB- major (0.631)\n\n\nF major (0.662)\n\n\n\n\n34\n\n\njugos064.krn\n\n\ng minor (0.797)\n\n\ng minor (0.668)\n\n\ng minor (0.836)\n\n\ng minor (0.775)\n\n\ng minor (0.822)\n\n\n\n\n35\n\n\njugos070.krn\n\n\nF major (0.84)\n\n\nF major (0.824)\n\n\nF major (0.832)\n\n\nF major (0.822)\n\n\nF major (0.867)\n\n\n\n\n36\n\n\njugos058.krn\n\n\nF major (0.819)\n\n\nF major (0.901)\n\n\nF major (0.777)\n\n\nF major (0.709)\n\n\nF major (0.856)\n\n\n\n\n37\n\n\njugos110.krn\n\n\nC major (0.756)\n\n\nC major (0.89)\n\n\nC major (0.713)\n\n\nC major (0.791)\n\n\nC major (0.735)\n\n\n\n\n38\n\n\njugos104.krn\n\n\nG major (0.641)\n\n\ne minor (0.597)\n\n\ng minor (0.492)\n\n\nG major (0.568)\n\n\nG major (0.509)\n\n\n\n\n39\n\n\njugos100.krn\n\n\ng minor (0.691)\n\n\nC major (0.476)\n\n\nC major (0.626)\n\n\nc minor (0.652)\n\n\nc minor (0.558)\n\n\n\n\n40\n\n\njugos114.krn\n\n\nC major (0.861)\n\n\nF major (0.576)\n\n\nF major (0.798)\n\n\nC major (0.804)\n\n\nF major (0.741)\n\n\n\n\n41\n\n\njugos074.krn\n\n\nG major (0.636)\n\n\nG major (0.78)\n\n\nG major (0.647)\n\n\nG major (0.651)\n\n\nG major (0.651)\n\n\n\n\n42\n\n\njugos060.krn\n\n\ng minor (0.627)\n\n\nd minor (0.573)\n\n\nF major (0.621)\n\n\nB- major (0.586)\n\n\nF major (0.664)\n\n\n\n\n43\n\n\njugos048.krn\n\n\nF major (0.696)\n\n\nF major (0.687)\n\n\nF major (0.647)\n\n\nF major (0.589)\n\n\nF major (0.737)\n\n\n\n\n44\n\n\njugos049.krn\n\n\nA major (0.821)\n\n\nA major (0.754)\n\n\nA major (0.707)\n\n\nA major (0.74)\n\n\nA major (0.738)\n\n\n\n\n45\n\n\njugos061.krn\n\n\nC major (0.684)\n\n\nC major (0.716)\n\n\nF major (0.579)\n\n\nF major (0.68)\n\n\nC major (0.625)\n\n\n\n\n46\n\n\njugos075.krn\n\n\nG major (0.896)\n\n\nG major (0.54)\n\n\nG major (0.814)\n\n\nG major (0.837)\n\n\nG major (0.829)\n\n\n\n\n47\n\n\njugos115.krn\n\n\nG major (0.898)\n\n\nG major (0.835)\n\n\nG major (0.947)\n\n\nG major (0.939)\n\n\nG major (0.948)\n\n\n\n\n48\n\n\njugos101.krn\n\n\nG major (0.819)\n\n\nG major (0.958)\n\n\nG major (0.777)\n\n\nG major (0.709)\n\n\nG major (0.856)\n\n\n\n\n49\n\n\njugos117.krn\n\n\nC major (0.85)\n\n\nC major (0.89)\n\n\nC major (0.784)\n\n\na minor (0.765)\n\n\nC major (0.893)\n\n\n\n\n50\n\n\njugos103.krn\n\n\nG major (0.676)\n\n\nG major (0.862)\n\n\nG major (0.688)\n\n\nD major (0.62)\n\n\nG major (0.737)\n\n\n\n\n51\n\n\njugos063.krn\n\n\nF major (0.572)\n\n\nd minor (0.775)\n\n\nF major (0.561)\n\n\nB- major (0.524)\n\n\nF major (0.635)\n\n\n\n\n52\n\n\njugos077.krn\n\n\na minor (0.622)\n\n\na minor (0.648)\n\n\nG major (0.64)\n\n\nd minor (0.533)\n\n\na minor (0.581)\n\n\n\n\n53\n\n\njugos088.krn\n\n\na minor (0.622)\n\n\nD major (0.689)\n\n\nD major (0.545)\n\n\nD major (0.564)\n\n\nA major (0.439)\n\n\n\n\n54\n\n\njugos089.krn\n\n\na minor (0.594)\n\n\nG major (0.506)\n\n\nG major (0.544)\n\n\nC major (0.583)\n\n\nG major (0.619)\n\n\n\n\n55\n\n\njugos076.krn\n\n\nC major (0.828)\n\n\nC major (0.659)\n\n\nC major (0.733)\n\n\nC major (0.725)\n\n\nC major (0.809)\n\n\n\n\n56\n\n\njugos062.krn\n\n\nG major (0.603)\n\n\ne minor (0.812)\n\n\nG major (0.594)\n\n\nC major (0.597)\n\n\nG major (0.622)\n\n\n\n\n57\n\n\njugos102.krn\n\n\na minor (0.495)\n\n\nG major (0.57)\n\n\ne minor (0.577)\n\n\ne minor (0.54)\n\n\nG major (0.602)\n\n\n\n\n58\n\n\njugos116.krn\n\n\nG major (0.676)\n\n\nG major (0.651)\n\n\nG major (0.749)\n\n\ne minor (0.666)\n\n\nG major (0.774)\n\n\n\n\n59\n\n\njugos047.krn\n\n\nG major (0.835)\n\n\nC major (0.834)\n\n\nC major (0.861)\n\n\nC major (0.834)\n\n\nC major (0.861)\n\n\n\n\n60\n\n\njugos053.krn\n\n\nG major (0.903)\n\n\nG major (0.904)\n\n\nG major (0.786)\n\n\nG major (0.777)\n\n\nG major (0.859)\n\n\n\n\n61\n\n\njugos084.krn\n\n\nD major (0.65)\n\n\ne minor (0.859)\n\n\nG major (0.685)\n\n\nD major (0.665)\n\n\nG major (0.708)\n\n\n\n\n62\n\n\njugos090.krn\n\n\na minor (0.925)\n\n\na minor (0.695)\n\n\na minor (0.79)\n\n\na minor (0.774)\n\n\na minor (0.838)\n\n\n\n\n63\n\n\njugos091.krn\n\n\nE- major (0.711)\n\n\nE- major (0.868)\n\n\nE- major (0.666)\n\n\nE- major (0.632)\n\n\nE- major (0.726)\n\n\n\n\n64\n\n\njugos085.krn\n\n\nG major (0.639)\n\n\nG major (0.739)\n\n\nG major (0.772)\n\n\nG major (0.665)\n\n\nG major (0.805)\n\n\n\n\n65\n\n\njugos052.krn\n\n\nG major (0.769)\n\n\nG major (0.791)\n\n\nG major (0.701)\n\n\ne minor (0.708)\n\n\nG major (0.816)\n\n\n\n\n66\n\n\njugos046.krn\n\n\nG major (0.872)\n\n\nG major (0.839)\n\n\nG major (0.769)\n\n\nG major (0.772)\n\n\nG major (0.835)\n\n\n\n\n67\n\n\njugos118.krn\n\n\nb minor (0.878)\n\n\nG major (0.831)\n\n\nG major (0.801)\n\n\nG major (0.725)\n\n\nG major (0.86)\n\n\n\n\n68\n\n\njugos078.krn\n\n\ng minor (0.705)\n\n\ng minor (0.907)\n\n\nF major (0.565)\n\n\nB- major (0.567)\n\n\ng minor (0.607)\n\n\n\n\n69\n\n\njugos050.krn\n\n\nC major (0.82)\n\n\nF major (0.721)\n\n\nF major (0.951)\n\n\nF major (0.877)\n\n\nF major (0.894)\n\n\n\n\n70\n\n\njugos044.krn\n\n\nG major (0.853)\n\n\nG major (0.93)\n\n\nG major (0.86)\n\n\nG major (0.825)\n\n\nG major (0.865)\n\n\n\n\n71\n\n\njugos093.krn\n\n\nG major (0.729)\n\n\nG major (0.889)\n\n\nG major (0.657)\n\n\nG major (0.644)\n\n\nG major (0.712)\n\n\n\n\n72\n\n\njugos087.krn\n\n\na minor (0.585)\n\n\nG major (0.709)\n\n\nG major (0.55)\n\n\nC major (0.587)\n\n\nG major (0.611)\n\n\n\n\n73\n\n\njugos086.krn\n\n\nb- minor (0.794)\n\n\nb- minor (0.632)\n\n\nb- minor (0.505)\n\n\nb- minor (0.583)\n\n\nb- minor (0.554)\n\n\n\n\n74\n\n\njugos092.krn\n\n\nG major (0.621)\n\n\nG major (0.6)\n\n\nG major (0.686)\n\n\nD major (0.647)\n\n\nG major (0.727)\n\n\n\n\n75\n\n\njugos045.krn\n\n\nG major (0.546)\n\n\ne minor (0.791)\n\n\ne minor (0.652)\n\n\ne minor (0.56)\n\n\ne minor (0.687)\n\n\n\n\n76\n\n\njugos051.krn\n\n\ne minor (0.565)\n\n\nb minor (0.74)\n\n\nD major (0.566)\n\n\nG major (0.579)\n\n\nD major (0.589)\n\n\n\n\n77\n\n\njugos079.krn\n\n\nG major (0.837)\n\n\nG major (0.555)\n\n\nG major (0.903)\n\n\nG major (0.832)\n\n\nG major (0.924)\n\n\n\n\n78\n\n\njugos119.krn\n\n\nG major (0.778)\n\n\nG major (0.933)\n\n\nG major (0.778)\n\n\nG major (0.71)\n\n\nG major (0.858)\n\n\n\n\n79\n\n\njugos109.krn\n\n\nG major (0.637)\n\n\nG major (0.883)\n\n\nG major (0.668)\n\n\nG major (0.583)\n\n\nG major (0.748)\n\n\n\n\n80\n\n\njugos055.krn\n\n\nG major (0.868)\n\n\nG major (0.756)\n\n\nG major (0.816)\n\n\nG major (0.842)\n\n\nG major (0.796)\n\n\n\n\n81\n\n\njugos041.krn\n\n\nG major (0.482)\n\n\ne minor (0.814)\n\n\nG major (0.55)\n\n\nG major (0.547)\n\n\nG major (0.546)\n\n\n\n\n82\n\n\njugos069.krn\n\n\na minor (0.686)\n\n\nG major (0.532)\n\n\nG major (0.719)\n\n\nC major (0.607)\n\n\nG major (0.716)\n\n\n\n\n83\n\n\njugos096.krn\n\n\nG major (0.825)\n\n\nG major (0.805)\n\n\nG major (0.869)\n\n\nG major (0.815)\n\n\nG major (0.865)\n\n\n\n\n84\n\n\njugos082.krn\n\n\nG major (0.705)\n\n\nG major (0.904)\n\n\nG major (0.733)\n\n\nC major (0.609)\n\n\nG major (0.806)\n\n\n\n\n85\n\n\njugos083.krn\n\n\nD major (0.855)\n\n\nG major (0.864)\n\n\nG major (0.864)\n\n\nD major (0.8)\n\n\nG major (0.813)\n\n\n\n\n86\n\n\njugos097.krn\n\n\nG major (0.617)\n\n\nG major (0.885)\n\n\nG major (0.637)\n\n\nD major (0.631)\n\n\nG major (0.638)\n\n\n\n\n87\n\n\njugos068.krn\n\n\nG major (0.829)\n\n\nC major (0.666)\n\n\nC major (0.843)\n\n\nC major (0.77)\n\n\nC major (0.851)\n\n\n\n\n88\n\n\njugos040.krn\n\n\nb minor (0.753)\n\n\nG major (0.907)\n\n\nG major (0.68)\n\n\nD major (0.606)\n\n\nG major (0.673)\n\n\n\n\n89\n\n\njugos054.krn\n\n\nG major (0.838)\n\n\nG major (0.791)\n\n\nG major (0.824)\n\n\nG major (0.765)\n\n\nG major (0.869)\n\n\n\n\n90\n\n\njugos108.krn\n\n\na minor (0.504)\n\n\nd minor (0.905)\n\n\nd minor (0.585)\n\n\nd minor (0.553)\n\n\nd minor (0.566)\n\n\n\n\n91\n\n\njugos042.krn\n\n\nG major (0.66)\n\n\nG major (0.597)\n\n\nG major (0.628)\n\n\nC major (0.622)\n\n\nG major (0.733)\n\n\n\n\n92\n\n\njugos056.krn\n\n\nG major (0.874)\n\n\nG major (0.758)\n\n\nG major (0.854)\n\n\nG major (0.816)\n\n\nG major (0.874)\n\n\n\n\n93\n\n\njugos081.krn\n\n\nG major (0.79)\n\n\nG major (0.916)\n\n\nG major (0.762)\n\n\nG major (0.682)\n\n\nG major (0.848)\n\n\n\n\n94\n\n\njugos095.krn\n\n\nG major (0.792)\n\n\nG major (0.886)\n\n\nG major (0.771)\n\n\nG major (0.728)\n\n\nG major (0.836)\n\n\n\n\n95\n\n\njugos094.krn\n\n\ng minor (0.771)\n\n\ng minor (0.796)\n\n\ng minor (0.745)\n\n\ng minor (0.713)\n\n\ng minor (0.734)\n\n\n\n\n96\n\n\njugos080.krn\n\n\nG major (0.891)\n\n\nG major (0.734)\n\n\nC major (0.692)\n\n\nG major (0.738)\n\n\nG major (0.798)\n\n\n\n\n97\n\n\njugos057.krn\n\n\nF major (0.861)\n\n\nF major (0.754)\n\n\nF major (0.836)\n\n\nF major (0.776)\n\n\nF major (0.89)\n\n\n\n\n98\n\n\njugos043.krn\n\n\nb minor (0.735)\n\n\nG major (0.932)\n\n\nG major (0.823)\n\n\nD major (0.732)\n\n\nG major (0.855)\n\n\n\n\n99\n\n\njugos018.krn\n\n\nb- minor (0.807)\n\n\nb- minor (0.934)\n\n\nb- minor (0.551)\n\n\nb- minor (0.588)\n\n\nb- minor (0.587)\n\n\n\n\n100\n\n\njugos024.krn\n\n\nG major (0.824)\n\n\nG major (0.578)\n\n\nG major (0.873)\n\n\nG major (0.808)\n\n\nG major (0.895)\n\n\n\n\n101\n\n\njugos030.krn\n\n\nG major (0.793)\n\n\nG major (0.968)\n\n\nG major (0.837)\n\n\nG major (0.85)\n\n\nG major (0.848)\n\n\n\n\n102\n\n\njugos031.krn\n\n\nC major (0.797)\n\n\nF major (0.732)\n\n\nF major (0.823)\n\n\nC major (0.776)\n\n\nF major (0.804)\n\n\n\n\n103\n\n\njugos025.krn\n\n\nC major (0.908)\n\n\nC major (0.89)\n\n\nC major (0.831)\n\n\nC major (0.811)\n\n\nC major (0.894)\n\n\n\n\n104\n\n\njugos019.krn\n\n\na minor (0.611)\n\n\nf# minor (0.879)\n\n\na minor (0.53)\n\n\na minor (0.544)\n\n\na minor (0.504)\n\n\n\n\n105\n\n\njugos033.krn\n\n\nD major (0.664)\n\n\nG major (0.488)\n\n\nG major (0.667)\n\n\nG major (0.635)\n\n\nG major (0.602)\n\n\n\n\n106\n\n\njugos027.krn\n\n\ng minor (0.686)\n\n\nF major (0.685)\n\n\nF major (0.51)\n\n\nB- major (0.543)\n\n\nF major (0.549)\n\n\n\n\n107\n\n\njugos026.krn\n\n\nG major (0.895)\n\n\nG major (0.592)\n\n\nG major (0.805)\n\n\nG major (0.791)\n\n\nG major (0.87)\n\n\n\n\n108\n\n\njugos032.krn\n\n\nG major (0.936)\n\n\nG major (0.836)\n\n\nG major (0.878)\n\n\nG major (0.942)\n\n\nG major (0.913)\n\n\n\n\n109\n\n\njugos036.krn\n\n\nb minor (0.715)\n\n\nG major (0.853)\n\n\nG major (0.81)\n\n\nG major (0.726)\n\n\nG major (0.787)\n\n\n\n\n110\n\n\njugos022.krn\n\n\nD major (0.768)\n\n\nD major (0.88)\n\n\nD major (0.819)\n\n\nG major (0.781)\n\n\nD major (0.826)\n\n\n\n\n111\n\n\njugos023.krn\n\n\nC major (0.601)\n\n\nF major (0.883)\n\n\nF major (0.704)\n\n\nC major (0.639)\n\n\nF major (0.714)\n\n\n\n\n112\n\n\njugos037.krn\n\n\nG major (0.767)\n\n\nG major (0.822)\n\n\nG major (0.774)\n\n\nG major (0.724)\n\n\nG major (0.798)\n\n\n\n\n113\n\n\njugos021.krn\n\n\nD major (0.688)\n\n\ne minor (0.806)\n\n\nD major (0.739)\n\n\nG major (0.731)\n\n\nG major (0.762)\n\n\n\n\n114\n\n\njugos035.krn\n\n\nG major (0.881)\n\n\nG major (0.869)\n\n\nG major (0.952)\n\n\nG major (0.951)\n\n\nG major (0.938)\n\n\n\n\n115\n\n\njugos009.krn\n\n\nC major (0.762)\n\n\na minor (0.927)\n\n\nC major (0.752)\n\n\nC major (0.746)\n\n\nC major (0.814)\n\n\n\n\n116\n\n\njugos008.krn\n\n\nG major (0.896)\n\n\nG major (0.77)\n\n\nG major (0.806)\n\n\nG major (0.806)\n\n\nG major (0.872)\n\n\n\n\n117\n\n\njugos034.krn\n\n\nG major (0.897)\n\n\nG major (0.851)\n\n\nG major (0.779)\n\n\nG major (0.756)\n\n\nG major (0.866)\n\n\n\n\n118\n\n\njugos020.krn\n\n\nG major (0.888)\n\n\nG major (0.861)\n\n\nG major (0.86)\n\n\nG major (0.892)\n\n\nG major (0.897)\n\n\n\n\n\n\n\n\nHere, we can see the various windows of keys in a song:\n\nfor kern_file in file_list:\n  krum = analysis.discrete.KrumhanslKessler(kern_file)\n  krum_key = krum.getSolution(kern_file)\n  krum_key.correlationCoefficient\n  p = graph.plot.WindowedKey(kern_file.parts[0])\n  p.run()\n\nOne of these would look like this:\n\n\n\nWindowed analysis using the K-S algorithm\n\n\n\n\n\n\nIt might be worth having a look at some audio data now. For this, we will use the Spotify API and Ashley Burgoyne’s compmus package, and the spotifyr toolkit.\n\n\nIn order to explore the Spotify API, you will need a client ID and a client “secret”. You can find those here.\n\n\ncorrplot 0.92 loaded\n\n\n\ncircshift &lt;- function(v, n) {\n  if (n == 0) v else c(tail(v, n), head(v, -n))\n}\n# \n# # ### uses the Krumhansl Schmuckler Profiles\nmajor_key &lt;- c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)\nminor_key &lt;- c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)\n\n##sapp's simple weightings\n# major_key &lt;- c(2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1)\n# \n# minor_key &lt;- c(2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0.5, 0.5)\n\nkey_templates &lt;-\n  tribble(\n    ~name, ~template,\n    \"Gb:maj\", circshift(major_key, 6),\n    \"Bb:min\", circshift(minor_key, 10),\n    \"Db:maj\", circshift(major_key, 1),\n    \"F:min\", circshift(minor_key, 5),\n    \"Ab:maj\", circshift(major_key, 8),\n    \"C:min\", circshift(minor_key, 0),\n    \"Eb:maj\", circshift(major_key, 3),\n    \"G:min\", circshift(minor_key, 7),\n    \"Bb:maj\", circshift(major_key, 10),\n    \"D:min\", circshift(minor_key, 2),\n    \"F:maj\", circshift(major_key, 5),\n    \"A:min\", circshift(minor_key, 9),\n    \"C:maj\", circshift(major_key, 0),\n    \"E:min\", circshift(minor_key, 4),\n    \"G:maj\", circshift(major_key, 7),\n    \"B:min\", circshift(minor_key, 11),\n    \"D:maj\", circshift(major_key, 2),\n    \"F#:min\", circshift(minor_key, 6),\n    \"A:maj\", circshift(major_key, 9),\n    \"C#:min\", circshift(minor_key, 1),\n    \"E:maj\", circshift(major_key, 4),\n    \"G#:min\", circshift(minor_key, 8),\n    \"B:maj\", circshift(major_key, 11),\n    \"D#:min\", circshift(minor_key, 3)\n  )\n\nLet’s look at Lucy Dacus’s “Night Shift”.\nThis grabs the track and does all the magic:\n\nnight_shift &lt;-\n  get_tidy_audio_analysis(\"1yYlpGuBiRRf33e1gY61bN\") |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  )\n\nAnd this is just a plotting function:\n\nnight_shift |&gt; \n  compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"euclidean\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n  ) |&gt;\n  ggplot(\n    aes(x = start + duration / 2, width = duration, y = name, fill = d)\n  ) +\n  geom_tile() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_minimal() +\n  labs(x = \"Time (s)\", y = \"\")\n\n\n\n\n\nnight_shift &lt;-\n  get_tidy_audio_analysis(\"1yYlpGuBiRRf33e1gY61bN\") |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  )\n\nLet’s do some exercises:\n\nVisualize a song with all of these weightings.\n\nHow do the algorithms differ?\n\nCan you write a function that would call each weighting as an argument? What would that look like?\n\n\n\n\n\nThere are many different ways of calculating key, and what constitutes “tonality” can change quite a bit depending on how you approach it. If using a set of pitches from a corpus to define a key-profile, the question becomes “which corpus?”\nToday, we are going to look at what it means to generate a key-profile for more appropriate key-finding algorithms. We are going to break the class into a few separate sections:\n\nLooking at getting a broad key-profile from a playlist.\nBreaking that into a major and minor key-profile (and discussing the issues and implications with this)\nWorking on an in-class exercise that generates a key-profile from a corpus and then looks at\n\n\n\n\nThe basic code for getting a key-profile from a playlist is below. The process is as follows:\n\nGet the audio features from a playlist, and add the audio analysis onto the datafame.\nWe then create a “segments” column by using a map function from the tidyverse. Map functions basically apply a function over each element in a list. Here, we are saying “apply the compmus_c_transpose function to the key and segments lists from the add_audio_analysis function.”\n\nWhat does the compmus_c_transpose function do? It takes all of the chroma vectors and transposes them to the key of C, so that we can construct a single set of weightings from pieces in different keys.\n\nWe then only grab this transposed segments column and turn it into a more readable list with the unnest function.\n\nWe then grab the start, duration, and pitches info.\n\nWe then create a “pitches” column, and normalize these raw pitch counts. There are a few ways to do this, and there are different options for this.\nWe then used the compmus_gather_chroma function to take all of those chroma vectors and turn them into a list.\nWe then use the group_by and summarise functions from tidyverse, and get the mean count of each pitch class in the distribution.\n\n\n### grabs the key-profile of the indie-pop playlist.\nindie_pop_key_profile &lt;- get_playlist_audio_features(\"\", \"37i9dQZF1DWWEcRhUVtL8n\") |&gt;\n  add_audio_analysis() |&gt;\n  ## transpose all the chroma vectors to C.\n  mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n  ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n  select(segments) |&gt;\n  unnest(segments) |&gt; \n  select(start, duration, pitches) |&gt; \n  mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n  compmus_gather_chroma() |&gt;\n  group_by(pitch_class) |&gt;\n  summarise(mean_value = mean(value)) \n\nindie_pop_key_profile\n\nIdeally, we’d be able to turn this into a more reusable function. Below we’ve just turned made the playlist URI an argument:\n\nget_key_profile_broad &lt;- function(uri){\n   get_playlist_audio_features(\"\", uri) |&gt;\n   add_audio_analysis() |&gt;\n   ## transpose all the chroma vectors to C. (have I mentioned how great Burgoyne's library is??)\n   mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n   ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n   select(segments) |&gt;\n   unnest(segments) |&gt; \n   select(start, duration, pitches) |&gt; \n   mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n   compmus_gather_chroma() |&gt;\n   group_by(pitch_class) |&gt;\n   summarise(mean_value = median(value)) \n}\n\nAnd now we can just run the function like so:\n\nindie_pop &lt;- get_key_profile_broad(\"37i9dQZF1DWWEcRhUVtL8n\")\nindie_pop\n\nand we can plot it in a pretty straightforward way:\n\nbarplot(indie_pop$mean_value)\n\nSo we can look at other genres pretty easily. Here is me looking at Spotify’s “EDM 2023” playlist:\n\n\n\n\nedm &lt;- get_key_profile_broad(\"37i9dQZF1DX1kCIzMYtzum\")\nedm\n\n# A tibble: 12 × 2\n   pitch_class mean_value\n   &lt;fct&gt;            &lt;dbl&gt;\n 1 C                0.250\n 2 C#|Db            0.142\n 3 D                0.182\n 4 D#|Eb            0.169\n 5 E                0.157\n 6 F                0.165\n 7 F#|Gb            0.145\n 8 G                0.228\n 9 G#|Ab            0.148\n10 A                0.154\n11 A#|Bb            0.152\n12 B                0.167\n\n\nand once again we can plot it:\n\nbarplot(edm$mean_value)\n\n\n\n\n\n\n\nFor both of these distributions, we see a strong showing for scale degrees 1 and 5 (they aren’t really labeled in these quickie plots, but it would be the first and seventh column, respectively).\nWith the “Indie Pop” plot, we see a strong showing of scale degrees 1 and 5, and are followed by the diatonic pitches, but with the “EDM” list, scale degrees 2, flat 3, and 3 occur with pretty much the same frequency. It might be worth splitting the major and minor pieces up a bit?\n\n\n\n\n\nWe could break this into a few parts for our own comfort. Let’s start by just creating a function that grabs the data. As that’s the one that’s quite time intensive, and calls to the API, let’s try to run it only once.\n\ngrab_playlist_info &lt;- function(uri){\n   get_playlist_audio_features(\"\", uri) |&gt;\n   add_audio_analysis() \n}\n\nOnce we have that in place, we can create a variable, and then subset it from there. Here, I’m saving the full list, and then creating a major and a minor variable.\n\nplaylist &lt;- grab_playlist_info(\"37i9dQZF1DX1kCIzMYtzum\")  \nminor &lt;- playlist |&gt; filter(mode == 0)\nmajor &lt;- playlist |&gt; filter(mode == 1)\n\n\nget_pitch_list &lt;- function(input){\n   input |&gt;     \n   mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n   ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n   select(segments) |&gt;\n   unnest(segments) |&gt; \n   select(start, duration, pitches) |&gt; \n   mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n   compmus_gather_chroma() |&gt;\n   group_by(pitch_class) |&gt;\n   summarise(mean_value = mean(value))\n}\n\nAnd now we can get separate pitch lists for major and minor:\n\nminor_key &lt;- get_pitch_list(minor)\nmajor_key &lt;- get_pitch_list(major)\n\nand then of course we can use these to inform our own key mapping.\nWe can start by putting this all into a super quick but inefficient function like this (hoping to improve it as we go along):\n\nkey_plotter &lt;- function(uri, major, minor){\n   major_key &lt;- major\n   minor_key &lt;- minor\n   key_templates &lt;-\n   tribble(\n      ~name, ~template,\n      \"Gb:maj\", circshift(major_key, 6),\n      \"Bb:min\", circshift(minor_key, 10),\n      \"Db:maj\", circshift(major_key, 1),\n      \"F:min\", circshift(minor_key, 5),\n      \"Ab:maj\", circshift(major_key, 8),\n      \"C:min\", circshift(minor_key, 0),\n      \"Eb:maj\", circshift(major_key, 3),\n      \"G:min\", circshift(minor_key, 7),\n      \"Bb:maj\", circshift(major_key, 10),\n      \"D:min\", circshift(minor_key, 2),\n      \"F:maj\", circshift(major_key, 5),\n      \"A:min\", circshift(minor_key, 9),\n      \"C:maj\", circshift(major_key, 0),\n      \"E:min\", circshift(minor_key, 4),\n      \"G:maj\", circshift(major_key, 7),\n      \"B:min\", circshift(minor_key, 11),\n      \"D:maj\", circshift(major_key, 2),\n      \"F#:min\", circshift(minor_key, 6),\n      \"A:maj\", circshift(major_key, 9),\n      \"C#:min\", circshift(minor_key, 1),\n      \"E:maj\", circshift(major_key, 4),\n      \"G#:min\", circshift(minor_key, 8),\n      \"B:maj\", circshift(major_key, 11),\n      \"D#:min\", circshift(minor_key, 3)\n  )\n\ntune &lt;-\n  get_tidy_audio_analysis(uri) |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  ) \n\ntune |&gt; compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"euclidean\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n  ) |&gt; \n  ggplot(\n    aes(x = start + duration / 2, width = duration, y = name, fill = d)\n  ) +\n  geom_tile() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_minimal() +\n  labs(x = \"Time (s)\", y = \"\")\n\n}\n\n\n\n\nLooking at Lucy Dacus’s “Night Shift” with EDM Key Profiles:\n\nedm_major_key &lt;- c(0.2949827,0.1842662, 0.2249348, 0.1796559, 0.2532545, 0.2391564, 0.2028676, 0.2607747, 0.1765553, 0.2105823, 0.1806760, 0.2562869)\n# \nedm_minor_key &lt;- c(0.3247214, 0.1767437, 0.2066454, 0.2482824, 0.1811887, 0.2263670, 0.1830838, 0.2662832, 0.2340293, 0.1888321, 0.2203257, 0.2047107)\nkey_plotter(\"1yYlpGuBiRRf33e1gY61bN\", edm_major_key, edm_minor_key)\n\n\n\n\nAnd here is the piece with the more traditional Krumhansl-Schmuckler key profiles:\n\nkey_plotter(\"1yYlpGuBiRRf33e1gY61bN\", ks_major_key, ks_minor_key)\n\n\n\n\nWe can load our “indie pop” but now in major and minor:\n\nplaylist &lt;- grab_playlist_info(\"37i9dQZF1DWWEcRhUVtL8n\")  \nindie_minor &lt;- playlist |&gt; filter(mode == 0)\nindie_major &lt;- playlist |&gt; filter(mode == 1)\nindie_minor &lt;- get_pitch_list(indie_minor)\nindie_major &lt;- get_pitch_list(indie_major)\n\nAnd then we put these weightings into the plotter:\n\nkey_plotter(\"1yYlpGuBiRRf33e1gY61bN\", ks_major_key, ks_minor_key)\n\n\n\n\n\n\n\n\nPick one piece and construct a genre-specific key-profile that might be used to explain its tonal make-up.\n\nExplain this musically."
  },
  {
    "objectID": "class_notes/week_4.html#why-is-key-finding-interesting",
    "href": "class_notes/week_4.html#why-is-key-finding-interesting",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "When we hear this ringtone, it sounds as though it’s in C, but why?\n\n\n\nNokia\n\n\n\nIt doesn’t begin with C, it begins with G.\nC isn’t the most common note–in fact, it only occurs once before the final bar, and it’s on the “and” of 2 in the third measure (a pretty weak position metrically).\nIs a key just whatever key the piece ends in? If we ended this on A, would it sound like it’s in A minor? It would be the same key signature, and we’d actually have a nice cadential ascent to the final A from the G in the third measure.\n\nSo what gives? Why do we hear this as being in C?\nPerhaps a follow-up question might simply be: what makes us hear something as being in a key?"
  },
  {
    "objectID": "class_notes/week_4.html#a-brief-history-of-key-finding",
    "href": "class_notes/week_4.html#a-brief-history-of-key-finding",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "This approach used what we might call an exclusionary approach, eliminating different key possibilities as pitch classes were introduced over the course of a musical passage.\nFor example, with the Nokia theme, the opening G would fit into seven major keys (G, C, D, F, B-flats, A-flat, E-flat;); six of those keys would include the opening two notes; and three of those six would still be possible when presented with the first three notes. By the end of the first measure, however, the only major key that would encompass all four melody notes would be C major. If more than one key was still available however, the algorithm would place more weight on the pitches present at the start of the piece. This worked quite well on pieces that were overtly tonal, but it was less effective for pieces that contained non-diatonic pitches (which is most pieces!)\n\n\n\nLonguet-Higgins and Steedman's 1971 Key-Finding Algorithm\n\n\n\n\n\nAs you might guess, the Longuet-Higgins and Steedman would miss a lot of musical instances. For example, pieces that have non-harmonic chords would struggle, as would pieces that had a lot of chromatic ornamentations. Ideally an algorithm would allow for these pitches to occur, but acknowledge that pitches in the key might be a better fit than those outside of the key, and that certain pitches in the key should be more heavily weighted than others.\nCarol Krumhansl and Mark Schmuckler (Krumhansl, 1990) would devise an algorithm that tallied up the pitch classes of an excerpt and compared the distribution of these pitch classes to ratings from an earlier probe-tone experiment. (Krumhansl and Kessler, 1982). The weightings can be seen below.\nWe might think of this as a correlational approach. We tally up all of the pitches in a corpus, and then run a correlation on this key-profile. We run this over all of the keys, and the one that best fits is then labeled as “the key”.\n\nlibrary(spotifyr)\nlibrary(compmus)\nlibrary(tidyverse)\nlibrary(purrr)\n\n\nks_major_key &lt;-\n  c(6.35, \n   2.23, \n   3.48, \n   2.33, \n   4.38, \n   4.09, \n   2.52, \n   5.19, \n   2.39, \n   3.66, \n   2.29, \n   2.88)\n\nks_minor_key &lt;-\n  c(6.33, \n  2.68, \n  3.52, \n  5.38, \n  2.60, \n  3.53, \n  2.54, \n  4.75, \n  3.98, \n  2.69, \n  3.34, \n  3.17)\n\nAn interesting distinction here is that of experiment-derived vs. corpus-derived weightings. Should a key-finding algorithm intend to match how we hear key in a controlled lab environment (with basic harmonic progression stimuli), or should they use real music as a starting point? If they use real music, which music?\n\n\n\nHector Bellman created a key-finding algorithm that used Helen Budge’s dissertation from the 1940s as a starting point. Budge tallied up note occurrences in composers from the classical music canon, looking at the tonal makeup of a large collection of pieces. Bellman then used these frequencies as the starting point for his own key-finding algorithm.\n\nmajor &lt;- c(16.80, \n            0.86,\n            12.95,\n            1.41,\n            13.49,\n            11.93,\n            1.25,\n            20.28,\n            1.80,\n            8.04,\n            0.62,\n            10.57)\n\nminor &lt;- c(18.16,\n            0.69,\n            12.99,\n            13.34,\n            1.07,\n            11.15,\n            1.38,\n            21.07,\n            7.49,\n            1.53,\n            0.92,\n            10.21)\n\n\n\n\nDavid Temperley (2001) also employed Western classical music as a starting point for his early key-finding work (not to be confused with his more dynamic Bayesian-informed later work). He used examples from a commonly used music theory textbook (Stefan Kostka and Dorothy Payne’s Tonal Harmony).\n\nmajor &lt;- c(0.748, \n            0.060, \n            0.488,\n            0.082, \n            0.670, \n            0.460, \n            0.096, \n            0.715, \n            0.104, \n            0.366,\n            0.057, \n            0.400)\n\nminor &lt;- c(0.712, \n            0.084, \n            0.474, \n            0.618, \n            0.049, \n            0.460, \n            0.105, \n            0.747, \n            0.404, \n            0.067, \n            0.133, \n            0.330)\n\n\n\n\nBret Aarden (2003) argued that folk music would be a better fit than those generated from classical music. He used the Essen Folksong collection (consisting of thousands of folksongs throughout Europe, although with an uneven balance toward German folksong), to come up with the weightings below.\n\nmajor &lt;- c(17.7661, \n            0.145624, \n            14.9265, \n            0.160186, \n            19.8049, \n            11.3587, \n            0.291248, \n            22.062, \n            0.145624, \n            8.15494, \n            0.232998, \n            4.95122)\n            \nminor &lt;- c(18.2648, \n            0.737619, \n            14.0499, \n            16.8599, \n            0.702494, \n            14.4362, \n            0.702494, \n            18.6161, \n            4.56621, \n            1.93186, \n            7.37619, \n            1.75623)\n\n\n\n\nCraig Sapp argued that we probably didn’t even need to get frequencies from corpora or experiments. If we just assume that the tonic and the dominant (scale degrees 1 and 5) are the most important, and the other pitches in the key are less important, but more important than those not in the key, then we have a pretty simple weighting system (that works quite well!).\n\nmajor &lt;- c(2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1)\n\nminor &lt;- c(2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0.5, 0.5)\n\n\n\n\nJosh Albrecht and I tried our hands at this problem, and picked a set of classical works from the Humdrum corpus, looking at only the first and last eight measures of each. The numbers are below.\n\nmajor &lt;- c(0.238, \n            0.006, \n            0.111, \n            0.006, \n            0.137, \n            0.094, \n            0.016, \n            0.214, \n            0.009, \n            0.080, \n            0.008, \n            0.081) \n\nminor &lt;- c(0.220, \n            0.006, \n            0.104, \n            0.123, \n            0.019, \n            0.103, \n            0.012, \n            0.214, \n            0.062, \n            0.022, \n            0.061, \n            0.052)\n\nWe also tried a Euclidean distance approach, rather than a correlational approach.\nWe tried to explain it as follows:\n\nIn a two-dimensional space, if there were 70% of pitch X and 30% pitch Y, the Cartesian location of the point representing this pitch-class distribution would be at X 1⁄4 0.7 and Y 1⁄4 0.3. In this case, we are examining the distribution of 12 pitch classes, resulting in a 12-dimensional Cartesian space. The pitch-class distribution of each piece is represented by a point in that 12-dimensional space. The distance is then measured between this point and the 24 points representing the 12 major and 12 minor key pitch-class distributions, and the key separated by the shortest distance is taken to be the key of the work.\n\nBelow is a table comparing how well this did to the others.\n\n\n\nComparing the Albrecht and Shanahan to others\n\n\n\n\n\nThey each perform a bit differently on different types of tasks.\n\n\n\nComparing key-finding algorithms in major, minor, and overall (from Albrecht and Shanahan, 2013)"
  },
  {
    "objectID": "class_notes/week_4.html#analyzing-key-with-music21",
    "href": "class_notes/week_4.html#analyzing-key-with-music21",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "music21 has a number of built-in key-finding algorithms, and it’s nice to be able to compare keys in specific pieces. You can start to see the differences between them, and their respective biases.\nThis code will grab all of the files in a folder (here a number of Yugoslav folk songs):\n\nimport glob\n\n###change this path to be your own!\ndef filebrowser(ext=\"/Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/*.krn\"):\n    \"Returns files with an extension\"\n    return [f for f in glob.glob(ext)]\n\nfile_list = filebrowser()\n\nAnd here I will grab the key of each one and print it out using different algorithms:\n\nfrom music21 import *\nfor kern_file in file_list:\n\n  melody = converter.parse(kern_file)       \n  krum = analysis.discrete.KrumhanslKessler(melody)\n  krum_key = krum.getSolution(melody)\n  \n  aarden = analysis.discrete.AardenEssen(melody)\n  aarden_key = aarden.getSolution(melody)\n\n  bellman = analysis.discrete.BellmanBudge(melody)\n  bellman_key = bellman.getSolution(melody)\n\n  temperley = analysis.discrete.TemperleyKostkaPayne(melody)\n  temperley_key = temperley.getSolution(melody)\n\n  sapp = analysis.discrete.SimpleWeights(melody)\n  sapp_key = sapp.getSolution(melody)\n\nAnd then we can call all of our variables like so:\n\n  print(f'File name: {kern_file}\\nKrumhansl-Kessler: {krum_key}\\nAarden Essen: {aarden_key}\\nBellman-Budge: {bellman_key}\\nTemperley-Kostka-Payne: {temperley_key}\\nSapp Simple-Weightings: {sapp_key}\\n')\n\nThis returns the following results (with a very long list):\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos039.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos005.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: D major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos011.krn\nKrumhansl-Kessler: D major\nAarden Essen: D major\nBellman-Budge: D major\nTemperley-Kostka-Payne: D major\nSapp Simple-Weightings: D major\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos010.krn\nKrumhansl-Kessler: A- major\nAarden Essen: A- major\nBellman-Budge: A- major\nTemperley-Kostka-Payne: A- major\nSapp Simple-Weightings: C# major\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos004.krn\nKrumhansl-Kessler: F major\nAarden Essen: g minor\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: B- major\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos038.krn\nKrumhansl-Kessler: G major\nAarden Essen: e minor\nBellman-Budge: e minor\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos012.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: C major\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos006.krn\nKrumhansl-Kessler: C major\nAarden Essen: C major\nBellman-Budge: C major\nTemperley-Kostka-Payne: C major\nSapp Simple-Weightings: C major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos007.krn\nKrumhansl-Kessler: F major\nAarden Essen: B- major\nBellman-Budge: B- major\nTemperley-Kostka-Payne: B- major\nSapp Simple-Weightings: F major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos013.krn\nKrumhansl-Kessler: D major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos017.krn\nKrumhansl-Kessler: A- major\nAarden Essen: f minor\nBellman-Budge: f minor\nTemperley-Kostka-Payne: A- major\nSapp Simple-Weightings: A- major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos003.krn\nKrumhansl-Kessler: B major\nAarden Essen: E major\nBellman-Budge: E major\nTemperley-Kostka-Payne: E major\nSapp Simple-Weightings: B major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos002.krn\nKrumhansl-Kessler: F major\nAarden Essen: F major\nBellman-Budge: B- major\nTemperley-Kostka-Payne: B- major\nSapp Simple-Weightings: B- major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos016.krn\nKrumhansl-Kessler: D major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: D major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos014.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos028.krn\nKrumhansl-Kessler: a minor\nAarden Essen: g minor\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: d minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos029.krn\nKrumhansl-Kessler: C major\nAarden Essen: C major\nBellman-Budge: C major\nTemperley-Kostka-Payne: C major\nSapp Simple-Weightings: C major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos015.krn\nKrumhansl-Kessler: G major\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos001.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos112.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos106.krn\nKrumhansl-Kessler: F major\nAarden Essen: F major\nBellman-Budge: B- major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: B- major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos066.krn\nKrumhansl-Kessler: g minor\nAarden Essen: g minor\nBellman-Budge: g minor\nTemperley-Kostka-Payne: g minor\nSapp Simple-Weightings: g minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos072.krn\nKrumhansl-Kessler: a minor\nAarden Essen: F major\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: F major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos099.krn\nKrumhansl-Kessler: G major\nAarden Essen: a minor\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos098.krn\nKrumhansl-Kessler: b minor\nAarden Essen: G major\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: e minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos073.krn\nKrumhansl-Kessler: a minor\nAarden Essen: F major\nBellman-Budge: F major\nTemperley-Kostka-Payne: F major\nSapp Simple-Weightings: d minor\n\n\n\n\nFile name: /Users/danielshanahan/gitcloud/Teaching/corpus-studies-2024/data/Essen/Jugoslav/jugos067.krn\nKrumhansl-Kessler: D major\nAarden Essen: e minor\nBellman-Budge: G major\nTemperley-Kostka-Payne: G major\nSapp Simple-Weightings: G major\n\nThis code will give us the key, and the confidence of each key, with different algorithms:\n\nimport pandas as pd\nfrom music21 import *\nkrum_kess = []\naarden_essen = []\ntemperley_kp = []\nbellman_budge = []\nsapp_weighted = []\n\ntitles = []\nfor file in file_list:\n  titles.append(file.split(\"/\")[-1])\n  melody = converter.parse(file) \n \n  krum = analysis.discrete.KrumhanslKessler(melody)\n  krum_key = krum.getSolution(melody)\n  coef_krum = round(krum_key.correlationCoefficient, 3)\n  krum_kess.append(f'{krum_key} ({coef_krum})')\n\n  aarden = analysis.discrete.AardenEssen(melody)\n  coef_aarden = round(aarden_key.correlationCoefficient, 3)\n  aarden_key = aarden.getSolution(melody)\n  aarden_essen.append(f'{aarden_key} ({coef_aarden})')\n  \n  bellman = analysis.discrete.BellmanBudge(melody)\n  bellman_key = bellman.getSolution(melody)\n  coef_bellman = round(bellman_key.correlationCoefficient, 3)\n  bellman_budge.append(f'{bellman_key} ({coef_bellman})')\n\n  sapp = analysis.discrete.SimpleWeights(melody)\n  sapp_key = sapp.getSolution(melody)\n  coef_sapp = round(sapp_key.correlationCoefficient, 3)\n  sapp_weighted.append(f'{sapp_key} ({coef_sapp})')\n  \n  temperley = analysis.discrete.TemperleyKostkaPayne(melody)\n  temperley_key = temperley.getSolution(melody)\n  coef_temperley = round(temperley_key.correlationCoefficient, 3)\n  temperley_kp.append(f'{temperley_key} ({coef_temperley})')\n\npd.set_option('max_rows', 371)\ndf = pd.DataFrame(list(zip(titles, krum_kess, aarden_essen, bellman_budge, sapp_weighted, temperley_kp)), columns= ['Chorale','Krumhansl-Kessler', 'Aarden-Essen', 'Bellman-Budge', 'Sapp Weighted', 'Temperley-KP'])\ndf\n\nHere is a table of each key decided by each algorithm:\n\n\n\n\n\n\n\n\n\nChorale\n\n\nKrumhansl-Kessler\n\n\nAarden-Essen\n\n\nBellman-Budge\n\n\nSapp Weighted\n\n\nTemperley-KP\n\n\n\n\n\n\n0\n\n\njugos039.krn\n\n\nb minor (0.64)\n\n\nG major (0.848)\n\n\nG major (0.653)\n\n\ne minor (0.663)\n\n\nG major (0.693)\n\n\n\n\n1\n\n\njugos005.krn\n\n\nG major (0.765)\n\n\nG major (0.793)\n\n\nG major (0.79)\n\n\nD major (0.711)\n\n\nG major (0.827)\n\n\n\n\n2\n\n\njugos011.krn\n\n\nD major (0.839)\n\n\nD major (0.887)\n\n\nD major (0.757)\n\n\nD major (0.753)\n\n\nD major (0.839)\n\n\n\n\n3\n\n\njugos010.krn\n\n\nA- major (0.762)\n\n\nA- major (0.83)\n\n\nA- major (0.773)\n\n\nC# major (0.692)\n\n\nA- major (0.838)\n\n\n\n\n4\n\n\njugos004.krn\n\n\nF major (0.618)\n\n\ng minor (0.886)\n\n\nF major (0.727)\n\n\nB- major (0.686)\n\n\nF major (0.715)\n\n\n\n\n5\n\n\njugos038.krn\n\n\nG major (0.598)\n\n\ne minor (0.827)\n\n\ne minor (0.636)\n\n\nG major (0.587)\n\n\nG major (0.688)\n\n\n\n\n6\n\n\njugos012.krn\n\n\nG major (0.858)\n\n\nG major (0.727)\n\n\nG major (0.688)\n\n\nC major (0.716)\n\n\nG major (0.789)\n\n\n\n\n7\n\n\njugos006.krn\n\n\nC major (0.705)\n\n\nC major (0.753)\n\n\nC major (0.594)\n\n\nC major (0.582)\n\n\nC major (0.696)\n\n\n\n\n8\n\n\njugos007.krn\n\n\nF major (0.768)\n\n\nB- major (0.685)\n\n\nB- major (0.787)\n\n\nF major (0.801)\n\n\nB- major (0.82)\n\n\n\n\n9\n\n\njugos013.krn\n\n\nD major (0.822)\n\n\nG major (0.882)\n\n\nG major (0.859)\n\n\nG major (0.796)\n\n\nG major (0.826)\n\n\n\n\n10\n\n\njugos017.krn\n\n\nA- major (0.696)\n\n\nf minor (0.906)\n\n\nf minor (0.586)\n\n\nA- major (0.575)\n\n\nA- major (0.672)\n\n\n\n\n11\n\n\njugos003.krn\n\n\nB major (0.815)\n\n\nE major (0.683)\n\n\nE major (0.793)\n\n\nB major (0.817)\n\n\nE major (0.781)\n\n\n\n\n12\n\n\njugos002.krn\n\n\nF major (0.837)\n\n\nF major (0.858)\n\n\nB- major (0.828)\n\n\nB- major (0.884)\n\n\nB- major (0.806)\n\n\n\n\n13\n\n\njugos016.krn\n\n\nD major (0.829)\n\n\nG major (0.77)\n\n\nG major (0.843)\n\n\nD major (0.77)\n\n\nG major (0.851)\n\n\n\n\n14\n\n\njugos014.krn\n\n\nG major (0.797)\n\n\nG major (0.907)\n\n\nG major (0.784)\n\n\nG major (0.708)\n\n\nG major (0.857)\n\n\n\n\n15\n\n\njugos028.krn\n\n\na minor (0.547)\n\n\ng minor (0.902)\n\n\nF major (0.667)\n\n\nd minor (0.547)\n\n\nF major (0.659)\n\n\n\n\n16\n\n\njugos029.krn\n\n\nC major (0.64)\n\n\nC major (0.787)\n\n\nC major (0.616)\n\n\nC major (0.577)\n\n\nC major (0.682)\n\n\n\n\n17\n\n\njugos015.krn\n\n\nG major (0.744)\n\n\nG major (0.675)\n\n\nG major (0.611)\n\n\nG major (0.616)\n\n\nG major (0.709)\n\n\n\n\n18\n\n\njugos001.krn\n\n\nb minor (0.733)\n\n\nG major (0.688)\n\n\nG major (0.703)\n\n\ne minor (0.725)\n\n\nG major (0.809)\n\n\n\n\n19\n\n\njugos112.krn\n\n\nb minor (0.66)\n\n\nG major (0.84)\n\n\nG major (0.511)\n\n\ne minor (0.617)\n\n\nG major (0.576)\n\n\n\n\n20\n\n\njugos106.krn\n\n\nF major (0.872)\n\n\nF major (0.649)\n\n\nB- major (0.777)\n\n\nB- major (0.843)\n\n\nF major (0.795)\n\n\n\n\n21\n\n\njugos066.krn\n\n\ng minor (0.771)\n\n\ng minor (0.763)\n\n\ng minor (0.745)\n\n\ng minor (0.713)\n\n\ng minor (0.734)\n\n\n\n\n22\n\n\njugos072.krn\n\n\na minor (0.818)\n\n\nF major (0.734)\n\n\nF major (0.702)\n\n\nF major (0.566)\n\n\nF major (0.692)\n\n\n\n\n23\n\n\njugos099.krn\n\n\nG major (0.662)\n\n\na minor (0.773)\n\n\nG major (0.767)\n\n\nG major (0.719)\n\n\nG major (0.752)\n\n\n\n\n24\n\n\njugos098.krn\n\n\nb minor (0.697)\n\n\nG major (0.847)\n\n\nG major (0.499)\n\n\ne minor (0.568)\n\n\nG major (0.568)\n\n\n\n\n25\n\n\njugos073.krn\n\n\na minor (0.677)\n\n\nF major (0.642)\n\n\nF major (0.619)\n\n\nd minor (0.578)\n\n\nF major (0.648)\n\n\n\n\n26\n\n\njugos067.krn\n\n\nD major (0.619)\n\n\ne minor (0.746)\n\n\nG major (0.663)\n\n\nG major (0.628)\n\n\nG major (0.694)\n\n\n\n\n27\n\n\njugos107.krn\n\n\nG major (0.696)\n\n\nG major (0.718)\n\n\nG major (0.82)\n\n\nG major (0.708)\n\n\nG major (0.833)\n\n\n\n\n28\n\n\njugos113.krn\n\n\nG major (0.788)\n\n\nG major (0.932)\n\n\nG major (0.662)\n\n\nC major (0.699)\n\n\nG major (0.737)\n\n\n\n\n29\n\n\njugos105.krn\n\n\nG major (0.782)\n\n\nG major (0.678)\n\n\nG major (0.854)\n\n\nG major (0.745)\n\n\nG major (0.866)\n\n\n\n\n30\n\n\njugos111.krn\n\n\nG major (0.765)\n\n\nG major (0.943)\n\n\nG major (0.684)\n\n\nC major (0.719)\n\n\nG major (0.75)\n\n\n\n\n31\n\n\njugos059.krn\n\n\nF major (0.81)\n\n\nF major (0.723)\n\n\nF major (0.823)\n\n\nF major (0.729)\n\n\nF major (0.877)\n\n\n\n\n32\n\n\njugos071.krn\n\n\nF major (0.771)\n\n\nF major (0.929)\n\n\nF major (0.888)\n\n\nF major (0.82)\n\n\nF major (0.832)\n\n\n\n\n33\n\n\njugos065.krn\n\n\nF major (0.627)\n\n\nF major (0.908)\n\n\nF major (0.577)\n\n\nB- major (0.631)\n\n\nF major (0.662)\n\n\n\n\n34\n\n\njugos064.krn\n\n\ng minor (0.797)\n\n\ng minor (0.668)\n\n\ng minor (0.836)\n\n\ng minor (0.775)\n\n\ng minor (0.822)\n\n\n\n\n35\n\n\njugos070.krn\n\n\nF major (0.84)\n\n\nF major (0.824)\n\n\nF major (0.832)\n\n\nF major (0.822)\n\n\nF major (0.867)\n\n\n\n\n36\n\n\njugos058.krn\n\n\nF major (0.819)\n\n\nF major (0.901)\n\n\nF major (0.777)\n\n\nF major (0.709)\n\n\nF major (0.856)\n\n\n\n\n37\n\n\njugos110.krn\n\n\nC major (0.756)\n\n\nC major (0.89)\n\n\nC major (0.713)\n\n\nC major (0.791)\n\n\nC major (0.735)\n\n\n\n\n38\n\n\njugos104.krn\n\n\nG major (0.641)\n\n\ne minor (0.597)\n\n\ng minor (0.492)\n\n\nG major (0.568)\n\n\nG major (0.509)\n\n\n\n\n39\n\n\njugos100.krn\n\n\ng minor (0.691)\n\n\nC major (0.476)\n\n\nC major (0.626)\n\n\nc minor (0.652)\n\n\nc minor (0.558)\n\n\n\n\n40\n\n\njugos114.krn\n\n\nC major (0.861)\n\n\nF major (0.576)\n\n\nF major (0.798)\n\n\nC major (0.804)\n\n\nF major (0.741)\n\n\n\n\n41\n\n\njugos074.krn\n\n\nG major (0.636)\n\n\nG major (0.78)\n\n\nG major (0.647)\n\n\nG major (0.651)\n\n\nG major (0.651)\n\n\n\n\n42\n\n\njugos060.krn\n\n\ng minor (0.627)\n\n\nd minor (0.573)\n\n\nF major (0.621)\n\n\nB- major (0.586)\n\n\nF major (0.664)\n\n\n\n\n43\n\n\njugos048.krn\n\n\nF major (0.696)\n\n\nF major (0.687)\n\n\nF major (0.647)\n\n\nF major (0.589)\n\n\nF major (0.737)\n\n\n\n\n44\n\n\njugos049.krn\n\n\nA major (0.821)\n\n\nA major (0.754)\n\n\nA major (0.707)\n\n\nA major (0.74)\n\n\nA major (0.738)\n\n\n\n\n45\n\n\njugos061.krn\n\n\nC major (0.684)\n\n\nC major (0.716)\n\n\nF major (0.579)\n\n\nF major (0.68)\n\n\nC major (0.625)\n\n\n\n\n46\n\n\njugos075.krn\n\n\nG major (0.896)\n\n\nG major (0.54)\n\n\nG major (0.814)\n\n\nG major (0.837)\n\n\nG major (0.829)\n\n\n\n\n47\n\n\njugos115.krn\n\n\nG major (0.898)\n\n\nG major (0.835)\n\n\nG major (0.947)\n\n\nG major (0.939)\n\n\nG major (0.948)\n\n\n\n\n48\n\n\njugos101.krn\n\n\nG major (0.819)\n\n\nG major (0.958)\n\n\nG major (0.777)\n\n\nG major (0.709)\n\n\nG major (0.856)\n\n\n\n\n49\n\n\njugos117.krn\n\n\nC major (0.85)\n\n\nC major (0.89)\n\n\nC major (0.784)\n\n\na minor (0.765)\n\n\nC major (0.893)\n\n\n\n\n50\n\n\njugos103.krn\n\n\nG major (0.676)\n\n\nG major (0.862)\n\n\nG major (0.688)\n\n\nD major (0.62)\n\n\nG major (0.737)\n\n\n\n\n51\n\n\njugos063.krn\n\n\nF major (0.572)\n\n\nd minor (0.775)\n\n\nF major (0.561)\n\n\nB- major (0.524)\n\n\nF major (0.635)\n\n\n\n\n52\n\n\njugos077.krn\n\n\na minor (0.622)\n\n\na minor (0.648)\n\n\nG major (0.64)\n\n\nd minor (0.533)\n\n\na minor (0.581)\n\n\n\n\n53\n\n\njugos088.krn\n\n\na minor (0.622)\n\n\nD major (0.689)\n\n\nD major (0.545)\n\n\nD major (0.564)\n\n\nA major (0.439)\n\n\n\n\n54\n\n\njugos089.krn\n\n\na minor (0.594)\n\n\nG major (0.506)\n\n\nG major (0.544)\n\n\nC major (0.583)\n\n\nG major (0.619)\n\n\n\n\n55\n\n\njugos076.krn\n\n\nC major (0.828)\n\n\nC major (0.659)\n\n\nC major (0.733)\n\n\nC major (0.725)\n\n\nC major (0.809)\n\n\n\n\n56\n\n\njugos062.krn\n\n\nG major (0.603)\n\n\ne minor (0.812)\n\n\nG major (0.594)\n\n\nC major (0.597)\n\n\nG major (0.622)\n\n\n\n\n57\n\n\njugos102.krn\n\n\na minor (0.495)\n\n\nG major (0.57)\n\n\ne minor (0.577)\n\n\ne minor (0.54)\n\n\nG major (0.602)\n\n\n\n\n58\n\n\njugos116.krn\n\n\nG major (0.676)\n\n\nG major (0.651)\n\n\nG major (0.749)\n\n\ne minor (0.666)\n\n\nG major (0.774)\n\n\n\n\n59\n\n\njugos047.krn\n\n\nG major (0.835)\n\n\nC major (0.834)\n\n\nC major (0.861)\n\n\nC major (0.834)\n\n\nC major (0.861)\n\n\n\n\n60\n\n\njugos053.krn\n\n\nG major (0.903)\n\n\nG major (0.904)\n\n\nG major (0.786)\n\n\nG major (0.777)\n\n\nG major (0.859)\n\n\n\n\n61\n\n\njugos084.krn\n\n\nD major (0.65)\n\n\ne minor (0.859)\n\n\nG major (0.685)\n\n\nD major (0.665)\n\n\nG major (0.708)\n\n\n\n\n62\n\n\njugos090.krn\n\n\na minor (0.925)\n\n\na minor (0.695)\n\n\na minor (0.79)\n\n\na minor (0.774)\n\n\na minor (0.838)\n\n\n\n\n63\n\n\njugos091.krn\n\n\nE- major (0.711)\n\n\nE- major (0.868)\n\n\nE- major (0.666)\n\n\nE- major (0.632)\n\n\nE- major (0.726)\n\n\n\n\n64\n\n\njugos085.krn\n\n\nG major (0.639)\n\n\nG major (0.739)\n\n\nG major (0.772)\n\n\nG major (0.665)\n\n\nG major (0.805)\n\n\n\n\n65\n\n\njugos052.krn\n\n\nG major (0.769)\n\n\nG major (0.791)\n\n\nG major (0.701)\n\n\ne minor (0.708)\n\n\nG major (0.816)\n\n\n\n\n66\n\n\njugos046.krn\n\n\nG major (0.872)\n\n\nG major (0.839)\n\n\nG major (0.769)\n\n\nG major (0.772)\n\n\nG major (0.835)\n\n\n\n\n67\n\n\njugos118.krn\n\n\nb minor (0.878)\n\n\nG major (0.831)\n\n\nG major (0.801)\n\n\nG major (0.725)\n\n\nG major (0.86)\n\n\n\n\n68\n\n\njugos078.krn\n\n\ng minor (0.705)\n\n\ng minor (0.907)\n\n\nF major (0.565)\n\n\nB- major (0.567)\n\n\ng minor (0.607)\n\n\n\n\n69\n\n\njugos050.krn\n\n\nC major (0.82)\n\n\nF major (0.721)\n\n\nF major (0.951)\n\n\nF major (0.877)\n\n\nF major (0.894)\n\n\n\n\n70\n\n\njugos044.krn\n\n\nG major (0.853)\n\n\nG major (0.93)\n\n\nG major (0.86)\n\n\nG major (0.825)\n\n\nG major (0.865)\n\n\n\n\n71\n\n\njugos093.krn\n\n\nG major (0.729)\n\n\nG major (0.889)\n\n\nG major (0.657)\n\n\nG major (0.644)\n\n\nG major (0.712)\n\n\n\n\n72\n\n\njugos087.krn\n\n\na minor (0.585)\n\n\nG major (0.709)\n\n\nG major (0.55)\n\n\nC major (0.587)\n\n\nG major (0.611)\n\n\n\n\n73\n\n\njugos086.krn\n\n\nb- minor (0.794)\n\n\nb- minor (0.632)\n\n\nb- minor (0.505)\n\n\nb- minor (0.583)\n\n\nb- minor (0.554)\n\n\n\n\n74\n\n\njugos092.krn\n\n\nG major (0.621)\n\n\nG major (0.6)\n\n\nG major (0.686)\n\n\nD major (0.647)\n\n\nG major (0.727)\n\n\n\n\n75\n\n\njugos045.krn\n\n\nG major (0.546)\n\n\ne minor (0.791)\n\n\ne minor (0.652)\n\n\ne minor (0.56)\n\n\ne minor (0.687)\n\n\n\n\n76\n\n\njugos051.krn\n\n\ne minor (0.565)\n\n\nb minor (0.74)\n\n\nD major (0.566)\n\n\nG major (0.579)\n\n\nD major (0.589)\n\n\n\n\n77\n\n\njugos079.krn\n\n\nG major (0.837)\n\n\nG major (0.555)\n\n\nG major (0.903)\n\n\nG major (0.832)\n\n\nG major (0.924)\n\n\n\n\n78\n\n\njugos119.krn\n\n\nG major (0.778)\n\n\nG major (0.933)\n\n\nG major (0.778)\n\n\nG major (0.71)\n\n\nG major (0.858)\n\n\n\n\n79\n\n\njugos109.krn\n\n\nG major (0.637)\n\n\nG major (0.883)\n\n\nG major (0.668)\n\n\nG major (0.583)\n\n\nG major (0.748)\n\n\n\n\n80\n\n\njugos055.krn\n\n\nG major (0.868)\n\n\nG major (0.756)\n\n\nG major (0.816)\n\n\nG major (0.842)\n\n\nG major (0.796)\n\n\n\n\n81\n\n\njugos041.krn\n\n\nG major (0.482)\n\n\ne minor (0.814)\n\n\nG major (0.55)\n\n\nG major (0.547)\n\n\nG major (0.546)\n\n\n\n\n82\n\n\njugos069.krn\n\n\na minor (0.686)\n\n\nG major (0.532)\n\n\nG major (0.719)\n\n\nC major (0.607)\n\n\nG major (0.716)\n\n\n\n\n83\n\n\njugos096.krn\n\n\nG major (0.825)\n\n\nG major (0.805)\n\n\nG major (0.869)\n\n\nG major (0.815)\n\n\nG major (0.865)\n\n\n\n\n84\n\n\njugos082.krn\n\n\nG major (0.705)\n\n\nG major (0.904)\n\n\nG major (0.733)\n\n\nC major (0.609)\n\n\nG major (0.806)\n\n\n\n\n85\n\n\njugos083.krn\n\n\nD major (0.855)\n\n\nG major (0.864)\n\n\nG major (0.864)\n\n\nD major (0.8)\n\n\nG major (0.813)\n\n\n\n\n86\n\n\njugos097.krn\n\n\nG major (0.617)\n\n\nG major (0.885)\n\n\nG major (0.637)\n\n\nD major (0.631)\n\n\nG major (0.638)\n\n\n\n\n87\n\n\njugos068.krn\n\n\nG major (0.829)\n\n\nC major (0.666)\n\n\nC major (0.843)\n\n\nC major (0.77)\n\n\nC major (0.851)\n\n\n\n\n88\n\n\njugos040.krn\n\n\nb minor (0.753)\n\n\nG major (0.907)\n\n\nG major (0.68)\n\n\nD major (0.606)\n\n\nG major (0.673)\n\n\n\n\n89\n\n\njugos054.krn\n\n\nG major (0.838)\n\n\nG major (0.791)\n\n\nG major (0.824)\n\n\nG major (0.765)\n\n\nG major (0.869)\n\n\n\n\n90\n\n\njugos108.krn\n\n\na minor (0.504)\n\n\nd minor (0.905)\n\n\nd minor (0.585)\n\n\nd minor (0.553)\n\n\nd minor (0.566)\n\n\n\n\n91\n\n\njugos042.krn\n\n\nG major (0.66)\n\n\nG major (0.597)\n\n\nG major (0.628)\n\n\nC major (0.622)\n\n\nG major (0.733)\n\n\n\n\n92\n\n\njugos056.krn\n\n\nG major (0.874)\n\n\nG major (0.758)\n\n\nG major (0.854)\n\n\nG major (0.816)\n\n\nG major (0.874)\n\n\n\n\n93\n\n\njugos081.krn\n\n\nG major (0.79)\n\n\nG major (0.916)\n\n\nG major (0.762)\n\n\nG major (0.682)\n\n\nG major (0.848)\n\n\n\n\n94\n\n\njugos095.krn\n\n\nG major (0.792)\n\n\nG major (0.886)\n\n\nG major (0.771)\n\n\nG major (0.728)\n\n\nG major (0.836)\n\n\n\n\n95\n\n\njugos094.krn\n\n\ng minor (0.771)\n\n\ng minor (0.796)\n\n\ng minor (0.745)\n\n\ng minor (0.713)\n\n\ng minor (0.734)\n\n\n\n\n96\n\n\njugos080.krn\n\n\nG major (0.891)\n\n\nG major (0.734)\n\n\nC major (0.692)\n\n\nG major (0.738)\n\n\nG major (0.798)\n\n\n\n\n97\n\n\njugos057.krn\n\n\nF major (0.861)\n\n\nF major (0.754)\n\n\nF major (0.836)\n\n\nF major (0.776)\n\n\nF major (0.89)\n\n\n\n\n98\n\n\njugos043.krn\n\n\nb minor (0.735)\n\n\nG major (0.932)\n\n\nG major (0.823)\n\n\nD major (0.732)\n\n\nG major (0.855)\n\n\n\n\n99\n\n\njugos018.krn\n\n\nb- minor (0.807)\n\n\nb- minor (0.934)\n\n\nb- minor (0.551)\n\n\nb- minor (0.588)\n\n\nb- minor (0.587)\n\n\n\n\n100\n\n\njugos024.krn\n\n\nG major (0.824)\n\n\nG major (0.578)\n\n\nG major (0.873)\n\n\nG major (0.808)\n\n\nG major (0.895)\n\n\n\n\n101\n\n\njugos030.krn\n\n\nG major (0.793)\n\n\nG major (0.968)\n\n\nG major (0.837)\n\n\nG major (0.85)\n\n\nG major (0.848)\n\n\n\n\n102\n\n\njugos031.krn\n\n\nC major (0.797)\n\n\nF major (0.732)\n\n\nF major (0.823)\n\n\nC major (0.776)\n\n\nF major (0.804)\n\n\n\n\n103\n\n\njugos025.krn\n\n\nC major (0.908)\n\n\nC major (0.89)\n\n\nC major (0.831)\n\n\nC major (0.811)\n\n\nC major (0.894)\n\n\n\n\n104\n\n\njugos019.krn\n\n\na minor (0.611)\n\n\nf# minor (0.879)\n\n\na minor (0.53)\n\n\na minor (0.544)\n\n\na minor (0.504)\n\n\n\n\n105\n\n\njugos033.krn\n\n\nD major (0.664)\n\n\nG major (0.488)\n\n\nG major (0.667)\n\n\nG major (0.635)\n\n\nG major (0.602)\n\n\n\n\n106\n\n\njugos027.krn\n\n\ng minor (0.686)\n\n\nF major (0.685)\n\n\nF major (0.51)\n\n\nB- major (0.543)\n\n\nF major (0.549)\n\n\n\n\n107\n\n\njugos026.krn\n\n\nG major (0.895)\n\n\nG major (0.592)\n\n\nG major (0.805)\n\n\nG major (0.791)\n\n\nG major (0.87)\n\n\n\n\n108\n\n\njugos032.krn\n\n\nG major (0.936)\n\n\nG major (0.836)\n\n\nG major (0.878)\n\n\nG major (0.942)\n\n\nG major (0.913)\n\n\n\n\n109\n\n\njugos036.krn\n\n\nb minor (0.715)\n\n\nG major (0.853)\n\n\nG major (0.81)\n\n\nG major (0.726)\n\n\nG major (0.787)\n\n\n\n\n110\n\n\njugos022.krn\n\n\nD major (0.768)\n\n\nD major (0.88)\n\n\nD major (0.819)\n\n\nG major (0.781)\n\n\nD major (0.826)\n\n\n\n\n111\n\n\njugos023.krn\n\n\nC major (0.601)\n\n\nF major (0.883)\n\n\nF major (0.704)\n\n\nC major (0.639)\n\n\nF major (0.714)\n\n\n\n\n112\n\n\njugos037.krn\n\n\nG major (0.767)\n\n\nG major (0.822)\n\n\nG major (0.774)\n\n\nG major (0.724)\n\n\nG major (0.798)\n\n\n\n\n113\n\n\njugos021.krn\n\n\nD major (0.688)\n\n\ne minor (0.806)\n\n\nD major (0.739)\n\n\nG major (0.731)\n\n\nG major (0.762)\n\n\n\n\n114\n\n\njugos035.krn\n\n\nG major (0.881)\n\n\nG major (0.869)\n\n\nG major (0.952)\n\n\nG major (0.951)\n\n\nG major (0.938)\n\n\n\n\n115\n\n\njugos009.krn\n\n\nC major (0.762)\n\n\na minor (0.927)\n\n\nC major (0.752)\n\n\nC major (0.746)\n\n\nC major (0.814)\n\n\n\n\n116\n\n\njugos008.krn\n\n\nG major (0.896)\n\n\nG major (0.77)\n\n\nG major (0.806)\n\n\nG major (0.806)\n\n\nG major (0.872)\n\n\n\n\n117\n\n\njugos034.krn\n\n\nG major (0.897)\n\n\nG major (0.851)\n\n\nG major (0.779)\n\n\nG major (0.756)\n\n\nG major (0.866)\n\n\n\n\n118\n\n\njugos020.krn\n\n\nG major (0.888)\n\n\nG major (0.861)\n\n\nG major (0.86)\n\n\nG major (0.892)\n\n\nG major (0.897)\n\n\n\n\n\n\n\n\nHere, we can see the various windows of keys in a song:\n\nfor kern_file in file_list:\n  krum = analysis.discrete.KrumhanslKessler(kern_file)\n  krum_key = krum.getSolution(kern_file)\n  krum_key.correlationCoefficient\n  p = graph.plot.WindowedKey(kern_file.parts[0])\n  p.run()\n\nOne of these would look like this:\n\n\n\nWindowed analysis using the K-S algorithm"
  },
  {
    "objectID": "class_notes/week_4.html#audio-data",
    "href": "class_notes/week_4.html#audio-data",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "It might be worth having a look at some audio data now. For this, we will use the Spotify API and Ashley Burgoyne’s compmus package, and the spotifyr toolkit.\n\n\nIn order to explore the Spotify API, you will need a client ID and a client “secret”. You can find those here.\n\n\ncorrplot 0.92 loaded\n\n\n\ncircshift &lt;- function(v, n) {\n  if (n == 0) v else c(tail(v, n), head(v, -n))\n}\n# \n# # ### uses the Krumhansl Schmuckler Profiles\nmajor_key &lt;- c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)\nminor_key &lt;- c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)\n\n##sapp's simple weightings\n# major_key &lt;- c(2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1)\n# \n# minor_key &lt;- c(2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0.5, 0.5)\n\nkey_templates &lt;-\n  tribble(\n    ~name, ~template,\n    \"Gb:maj\", circshift(major_key, 6),\n    \"Bb:min\", circshift(minor_key, 10),\n    \"Db:maj\", circshift(major_key, 1),\n    \"F:min\", circshift(minor_key, 5),\n    \"Ab:maj\", circshift(major_key, 8),\n    \"C:min\", circshift(minor_key, 0),\n    \"Eb:maj\", circshift(major_key, 3),\n    \"G:min\", circshift(minor_key, 7),\n    \"Bb:maj\", circshift(major_key, 10),\n    \"D:min\", circshift(minor_key, 2),\n    \"F:maj\", circshift(major_key, 5),\n    \"A:min\", circshift(minor_key, 9),\n    \"C:maj\", circshift(major_key, 0),\n    \"E:min\", circshift(minor_key, 4),\n    \"G:maj\", circshift(major_key, 7),\n    \"B:min\", circshift(minor_key, 11),\n    \"D:maj\", circshift(major_key, 2),\n    \"F#:min\", circshift(minor_key, 6),\n    \"A:maj\", circshift(major_key, 9),\n    \"C#:min\", circshift(minor_key, 1),\n    \"E:maj\", circshift(major_key, 4),\n    \"G#:min\", circshift(minor_key, 8),\n    \"B:maj\", circshift(major_key, 11),\n    \"D#:min\", circshift(minor_key, 3)\n  )\n\nLet’s look at Lucy Dacus’s “Night Shift”.\nThis grabs the track and does all the magic:\n\nnight_shift &lt;-\n  get_tidy_audio_analysis(\"1yYlpGuBiRRf33e1gY61bN\") |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  )\n\nAnd this is just a plotting function:\n\nnight_shift |&gt; \n  compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"euclidean\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n  ) |&gt;\n  ggplot(\n    aes(x = start + duration / 2, width = duration, y = name, fill = d)\n  ) +\n  geom_tile() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_minimal() +\n  labs(x = \"Time (s)\", y = \"\")\n\n\n\n\n\nnight_shift &lt;-\n  get_tidy_audio_analysis(\"1yYlpGuBiRRf33e1gY61bN\") |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  )\n\nLet’s do some exercises:\n\nVisualize a song with all of these weightings.\n\nHow do the algorithms differ?\n\nCan you write a function that would call each weighting as an argument? What would that look like?"
  },
  {
    "objectID": "class_notes/week_4.html#making-our-own",
    "href": "class_notes/week_4.html#making-our-own",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "There are many different ways of calculating key, and what constitutes “tonality” can change quite a bit depending on how you approach it. If using a set of pitches from a corpus to define a key-profile, the question becomes “which corpus?”\nToday, we are going to look at what it means to generate a key-profile for more appropriate key-finding algorithms. We are going to break the class into a few separate sections:\n\nLooking at getting a broad key-profile from a playlist.\nBreaking that into a major and minor key-profile (and discussing the issues and implications with this)\nWorking on an in-class exercise that generates a key-profile from a corpus and then looks at"
  },
  {
    "objectID": "class_notes/week_4.html#whats-the-key-profile-for-indie-pop",
    "href": "class_notes/week_4.html#whats-the-key-profile-for-indie-pop",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "The basic code for getting a key-profile from a playlist is below. The process is as follows:\n\nGet the audio features from a playlist, and add the audio analysis onto the datafame.\nWe then create a “segments” column by using a map function from the tidyverse. Map functions basically apply a function over each element in a list. Here, we are saying “apply the compmus_c_transpose function to the key and segments lists from the add_audio_analysis function.”\n\nWhat does the compmus_c_transpose function do? It takes all of the chroma vectors and transposes them to the key of C, so that we can construct a single set of weightings from pieces in different keys.\n\nWe then only grab this transposed segments column and turn it into a more readable list with the unnest function.\n\nWe then grab the start, duration, and pitches info.\n\nWe then create a “pitches” column, and normalize these raw pitch counts. There are a few ways to do this, and there are different options for this.\nWe then used the compmus_gather_chroma function to take all of those chroma vectors and turn them into a list.\nWe then use the group_by and summarise functions from tidyverse, and get the mean count of each pitch class in the distribution.\n\n\n### grabs the key-profile of the indie-pop playlist.\nindie_pop_key_profile &lt;- get_playlist_audio_features(\"\", \"37i9dQZF1DWWEcRhUVtL8n\") |&gt;\n  add_audio_analysis() |&gt;\n  ## transpose all the chroma vectors to C.\n  mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n  ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n  select(segments) |&gt;\n  unnest(segments) |&gt; \n  select(start, duration, pitches) |&gt; \n  mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n  compmus_gather_chroma() |&gt;\n  group_by(pitch_class) |&gt;\n  summarise(mean_value = mean(value)) \n\nindie_pop_key_profile\n\nIdeally, we’d be able to turn this into a more reusable function. Below we’ve just turned made the playlist URI an argument:\n\nget_key_profile_broad &lt;- function(uri){\n   get_playlist_audio_features(\"\", uri) |&gt;\n   add_audio_analysis() |&gt;\n   ## transpose all the chroma vectors to C. (have I mentioned how great Burgoyne's library is??)\n   mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n   ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n   select(segments) |&gt;\n   unnest(segments) |&gt; \n   select(start, duration, pitches) |&gt; \n   mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n   compmus_gather_chroma() |&gt;\n   group_by(pitch_class) |&gt;\n   summarise(mean_value = median(value)) \n}\n\nAnd now we can just run the function like so:\n\nindie_pop &lt;- get_key_profile_broad(\"37i9dQZF1DWWEcRhUVtL8n\")\nindie_pop\n\nand we can plot it in a pretty straightforward way:\n\nbarplot(indie_pop$mean_value)\n\nSo we can look at other genres pretty easily. Here is me looking at Spotify’s “EDM 2023” playlist:"
  },
  {
    "objectID": "class_notes/week_4.html#whats-the-key-profile-for-edm",
    "href": "class_notes/week_4.html#whats-the-key-profile-for-edm",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "edm &lt;- get_key_profile_broad(\"37i9dQZF1DX1kCIzMYtzum\")\nedm\n\n# A tibble: 12 × 2\n   pitch_class mean_value\n   &lt;fct&gt;            &lt;dbl&gt;\n 1 C                0.250\n 2 C#|Db            0.142\n 3 D                0.182\n 4 D#|Eb            0.169\n 5 E                0.157\n 6 F                0.165\n 7 F#|Gb            0.145\n 8 G                0.228\n 9 G#|Ab            0.148\n10 A                0.154\n11 A#|Bb            0.152\n12 B                0.167\n\n\nand once again we can plot it:\n\nbarplot(edm$mean_value)\n\n\n\n\n\n\n\nFor both of these distributions, we see a strong showing for scale degrees 1 and 5 (they aren’t really labeled in these quickie plots, but it would be the first and seventh column, respectively).\nWith the “Indie Pop” plot, we see a strong showing of scale degrees 1 and 5, and are followed by the diatonic pitches, but with the “EDM” list, scale degrees 2, flat 3, and 3 occur with pretty much the same frequency. It might be worth splitting the major and minor pieces up a bit?"
  },
  {
    "objectID": "class_notes/week_4.html#getting-separate-major-and-minor-key-profiles",
    "href": "class_notes/week_4.html#getting-separate-major-and-minor-key-profiles",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "We could break this into a few parts for our own comfort. Let’s start by just creating a function that grabs the data. As that’s the one that’s quite time intensive, and calls to the API, let’s try to run it only once.\n\ngrab_playlist_info &lt;- function(uri){\n   get_playlist_audio_features(\"\", uri) |&gt;\n   add_audio_analysis() \n}\n\nOnce we have that in place, we can create a variable, and then subset it from there. Here, I’m saving the full list, and then creating a major and a minor variable.\n\nplaylist &lt;- grab_playlist_info(\"37i9dQZF1DX1kCIzMYtzum\")  \nminor &lt;- playlist |&gt; filter(mode == 0)\nmajor &lt;- playlist |&gt; filter(mode == 1)\n\n\nget_pitch_list &lt;- function(input){\n   input |&gt;     \n   mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n   ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n   select(segments) |&gt;\n   unnest(segments) |&gt; \n   select(start, duration, pitches) |&gt; \n   mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n   compmus_gather_chroma() |&gt;\n   group_by(pitch_class) |&gt;\n   summarise(mean_value = mean(value))\n}\n\nAnd now we can get separate pitch lists for major and minor:\n\nminor_key &lt;- get_pitch_list(minor)\nmajor_key &lt;- get_pitch_list(major)\n\nand then of course we can use these to inform our own key mapping.\nWe can start by putting this all into a super quick but inefficient function like this (hoping to improve it as we go along):\n\nkey_plotter &lt;- function(uri, major, minor){\n   major_key &lt;- major\n   minor_key &lt;- minor\n   key_templates &lt;-\n   tribble(\n      ~name, ~template,\n      \"Gb:maj\", circshift(major_key, 6),\n      \"Bb:min\", circshift(minor_key, 10),\n      \"Db:maj\", circshift(major_key, 1),\n      \"F:min\", circshift(minor_key, 5),\n      \"Ab:maj\", circshift(major_key, 8),\n      \"C:min\", circshift(minor_key, 0),\n      \"Eb:maj\", circshift(major_key, 3),\n      \"G:min\", circshift(minor_key, 7),\n      \"Bb:maj\", circshift(major_key, 10),\n      \"D:min\", circshift(minor_key, 2),\n      \"F:maj\", circshift(major_key, 5),\n      \"A:min\", circshift(minor_key, 9),\n      \"C:maj\", circshift(major_key, 0),\n      \"E:min\", circshift(minor_key, 4),\n      \"G:maj\", circshift(major_key, 7),\n      \"B:min\", circshift(minor_key, 11),\n      \"D:maj\", circshift(major_key, 2),\n      \"F#:min\", circshift(minor_key, 6),\n      \"A:maj\", circshift(major_key, 9),\n      \"C#:min\", circshift(minor_key, 1),\n      \"E:maj\", circshift(major_key, 4),\n      \"G#:min\", circshift(minor_key, 8),\n      \"B:maj\", circshift(major_key, 11),\n      \"D#:min\", circshift(minor_key, 3)\n  )\n\ntune &lt;-\n  get_tidy_audio_analysis(uri) |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  ) \n\ntune |&gt; compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"euclidean\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n  ) |&gt; \n  ggplot(\n    aes(x = start + duration / 2, width = duration, y = name, fill = d)\n  ) +\n  geom_tile() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_minimal() +\n  labs(x = \"Time (s)\", y = \"\")\n\n}"
  },
  {
    "objectID": "class_notes/week_4.html#one-piece-and-many-key-profiles",
    "href": "class_notes/week_4.html#one-piece-and-many-key-profiles",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "Looking at Lucy Dacus’s “Night Shift” with EDM Key Profiles:\n\nedm_major_key &lt;- c(0.2949827,0.1842662, 0.2249348, 0.1796559, 0.2532545, 0.2391564, 0.2028676, 0.2607747, 0.1765553, 0.2105823, 0.1806760, 0.2562869)\n# \nedm_minor_key &lt;- c(0.3247214, 0.1767437, 0.2066454, 0.2482824, 0.1811887, 0.2263670, 0.1830838, 0.2662832, 0.2340293, 0.1888321, 0.2203257, 0.2047107)\nkey_plotter(\"1yYlpGuBiRRf33e1gY61bN\", edm_major_key, edm_minor_key)\n\n\n\n\nAnd here is the piece with the more traditional Krumhansl-Schmuckler key profiles:\n\nkey_plotter(\"1yYlpGuBiRRf33e1gY61bN\", ks_major_key, ks_minor_key)\n\n\n\n\nWe can load our “indie pop” but now in major and minor:\n\nplaylist &lt;- grab_playlist_info(\"37i9dQZF1DWWEcRhUVtL8n\")  \nindie_minor &lt;- playlist |&gt; filter(mode == 0)\nindie_major &lt;- playlist |&gt; filter(mode == 1)\nindie_minor &lt;- get_pitch_list(indie_minor)\nindie_major &lt;- get_pitch_list(indie_major)\n\nAnd then we put these weightings into the plotter:\n\nkey_plotter(\"1yYlpGuBiRRf33e1gY61bN\", ks_major_key, ks_minor_key)"
  },
  {
    "objectID": "class_notes/week_4.html#exercise",
    "href": "class_notes/week_4.html#exercise",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "",
    "text": "Pick one piece and construct a genre-specific key-profile that might be used to explain its tonal make-up.\n\nExplain this musically."
  },
  {
    "objectID": "class_notes/week_4.html#exploring-spotify",
    "href": "class_notes/week_4.html#exploring-spotify",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "Exploring Spotify",
    "text": "Exploring Spotify\nBy now, you should have an API key and secret. Also download the spotifyr package and the compmus package if you haven’t already."
  },
  {
    "objectID": "class_notes/week_4.html#grabbing-dans-discover-playlist",
    "href": "class_notes/week_4.html#grabbing-dans-discover-playlist",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "Grabbing Dan’s “Discover” Playlist",
    "text": "Grabbing Dan’s “Discover” Playlist\nThe first step will be to get the audio features of the playlist, and run it all into an audio analysis tool. Here’s what that will give us.\n\ndf &lt;- get_playlist_audio_features(\"\", \"37i9dQZEVXcIDdjTZ1FKnJ\") |&gt;\n  add_audio_analysis() \n\nThen we create a segments variable, and use the “c transpose” toolkit from compmus. I then take the segments, unnest it (it is a nested list), and then grab the pitches (and unnest that).\n\ndf |&gt; mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n  select(segments) |&gt; unnest(segments) |&gt; select(pitches) |&gt; unnest(pitches) |&gt; \n  head(12)\n\n# A tibble: 12 × 1\n   pitches\n     &lt;dbl&gt;\n 1   0.293\n 2   0.143\n 3   0.549\n 4   0.264\n 5   0.309\n 6   0.102\n 7   0.323\n 8   1    \n 9   0.331\n10   0.153\n11   0.181\n12   0.225\n\n\nHere, I’ve just taken a specific moment. This shows us that Spotify is the most confident the pitch “4” is this pitch at the moment we’re looking at.\nIf we want to grab the “key profile” of my playlist, we can use the following code:\n\n### grabs the key-profile of the indie-pop playlist.\ndf|&gt; \n  ## transpose all the chroma vectors to C.\n  mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n  ## grab the segments data and unnest it, then only grabbing the start, duration, and pitches info.\n  select(segments) |&gt;\n  unnest(segments) |&gt; \n  select(start, duration, pitches) |&gt; \n  mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n  compmus_gather_chroma() |&gt;\n  group_by(pitch_class) |&gt;\n  summarise(mean_value = mean(value)) \n\ndans_discover\n\nNote how it grabs the audio, normalizes the pitches, grabs all of the chroma, and then runs a group_by and a summarise for each of the pitches.\n\nGetting the Key for Each Song\nThis will give us a list of keys and a sum of their weights. We can then take the list in descending order and grab one of them.\n\ntune &lt;-\n  get_tidy_audio_analysis(\"1yYlpGuBiRRf33e1gY61bN\") |&gt;\n  compmus_align(sections, segments) |&gt;\n  select(sections) |&gt;\n  unnest(sections) |&gt;\n  mutate(\n    pitches =\n      map(segments,\n          compmus_summarise, pitches,\n          method = \"mean\", norm = \"manhattan\"\n      )\n  ) \n\n    tune |&gt; compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"pearson\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n    ) |&gt; \n    group_by(name)  |&gt;\n    summarise(weight = sum(d)) |&gt; \n    arrange(weight)\n\n# A tibble: 24 × 2\n   name   weight\n   &lt;fct&gt;   &lt;dbl&gt;\n 1 A:maj    5.36\n 2 D:maj    7.22\n 3 D:min    9.56\n 4 F#:min   9.97\n 5 A:min   10.3 \n 6 B:min   12.0 \n 7 C#:min  12.0 \n 8 E:maj   12.9 \n 9 G:maj   13.5 \n10 E:min   15.3 \n# ℹ 14 more rows\n\n\nHere we want the lowest number, and it seems to make sense. This piece is in A major and perhaps D major? Our algorithm did a pretty good job.\n\nnight_shift &lt;- get_track_audio_features(\"1yYlpGuBiRRf33e1gY61bN\")\nnight_shift$key\n\n[1] 9\n\nnight_shift$mode\n\n[1] 1\n\n\nSpotify says it’s in A major!\nThe code above uses something called key_templates which (you might remember) we can define with out key profiles.\nSo we can add our own here! We start with the Krumansl-Schmuckler weightings, but here are Sapps as well (just comment out the first and uncomment the second).\n\nmajor_key &lt;- c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)\nminor_key &lt;- c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)\n\n#sapp's simple weightings\n# major_key &lt;- c(2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1)\n# minor_key &lt;- c(2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0.5, 0.5)\n\nkey_templates &lt;-\n  tribble(\n    ~name, ~template,\n    \"Gb:maj\", circshift(major_key, 6),\n    \"Bb:min\", circshift(minor_key, 10),\n    \"Db:maj\", circshift(major_key, 1),\n    \"F:min\", circshift(minor_key, 5),\n    \"Ab:maj\", circshift(major_key, 8),\n    \"C:min\", circshift(minor_key, 0),\n    \"Eb:maj\", circshift(major_key, 3),\n    \"G:min\", circshift(minor_key, 7),\n    \"Bb:maj\", circshift(major_key, 10),\n    \"D:min\", circshift(minor_key, 2),\n    \"F:maj\", circshift(major_key, 5),\n    \"A:min\", circshift(minor_key, 9),\n    \"C:maj\", circshift(major_key, 0),\n    \"E:min\", circshift(minor_key, 4),\n    \"G:maj\", circshift(major_key, 7),\n    \"B:min\", circshift(minor_key, 11),\n    \"D:maj\", circshift(major_key, 2),\n    \"F#:min\", circshift(minor_key, 6),\n    \"A:maj\", circshift(major_key, 9),\n    \"C#:min\", circshift(minor_key, 1),\n    \"E:maj\", circshift(major_key, 4),\n    \"G#:min\", circshift(minor_key, 8),\n    \"B:maj\", circshift(major_key, 11),\n    \"D#:min\", circshift(minor_key, 3)\n  )\n\nIf I rerun this code with Sapp’s simple weightings, it thinks it’s in D major:\n\n    tune |&gt; compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"pearson\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n    ) |&gt; \n    group_by(name)  |&gt;\n    summarise(weight = sum(d)) |&gt; \n    arrange(weight)\n\n# A tibble: 24 × 2\n   name   weight\n   &lt;fct&gt;   &lt;dbl&gt;\n 1 A:maj    5.36\n 2 D:maj    7.22\n 3 D:min    9.56\n 4 F#:min   9.97\n 5 A:min   10.3 \n 6 B:min   12.0 \n 7 C#:min  12.0 \n 8 E:maj   12.9 \n 9 G:maj   13.5 \n10 E:min   15.3 \n# ℹ 14 more rows\n\n\nMaybe it is in D major?\nWhat if I use my indie pop profile?\n\nindie_pop_playlist &lt;- grab_playlist_info(\"37i9dQZF1DX1kCIzMYtzum\")  \nminor &lt;- indie_pop_playlist |&gt; filter(mode == 0)\nmajor &lt;- indie_pop_playlist |&gt; filter(mode == 1)\nindie_pop_minor &lt;- get_pitch_list(minor) |&gt; select(mean_value)\nindie_pop_major &lt;- get_pitch_list(major) |&gt; select(mean_value) \n\nI can take the key profiles given above and put them in the code below. While I’m at it though, I’m going to also grab the key profile from my discover playlist!\n\ndan_discover_playlist &lt;- grab_playlist_info(\"37i9dQZEVXcIDdjTZ1FKnJ\")  \nminor &lt;- dan_discover_playlist |&gt; filter(mode == 0)\nmajor &lt;- dan_discover_playlist |&gt; filter(mode == 1)\ndan_minor &lt;- get_pitch_list(minor) |&gt; select(mean_value)\ndan_major &lt;- get_pitch_list(major) |&gt; select(mean_value) \n\n\n# major_key &lt;- c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)\n# minor_key &lt;- c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)\n\n#sapp's simple weightings\n# major_key &lt;- c(2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1)\n# minor_key &lt;- c(2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0.5, 0.5)\n\n## my indie pop profile\nmajor_key &lt;- as.numeric(unlist(indie_pop_major))\nminor_key &lt;- as.numeric(unlist(indie_pop_minor))\n\n## dan's discover playlist\n# major_key &lt;- as.numeric(unlist(dan_major))\n# minor_key &lt;- as.numeric(unlist(dan_minor))\n\n\nkey_templates &lt;-\n  tribble(\n    ~name, ~template,\n    \"Gb:maj\", circshift(major_key, 6),\n    \"Bb:min\", circshift(minor_key, 10),\n    \"Db:maj\", circshift(major_key, 1),\n    \"F:min\", circshift(minor_key, 5),\n    \"Ab:maj\", circshift(major_key, 8),\n    \"C:min\", circshift(minor_key, 0),\n    \"Eb:maj\", circshift(major_key, 3),\n    \"G:min\", circshift(minor_key, 7),\n    \"Bb:maj\", circshift(major_key, 10),\n    \"D:min\", circshift(minor_key, 2),\n    \"F:maj\", circshift(major_key, 5),\n    \"A:min\", circshift(minor_key, 9),\n    \"C:maj\", circshift(major_key, 0),\n    \"E:min\", circshift(minor_key, 4),\n    \"G:maj\", circshift(major_key, 7),\n    \"B:min\", circshift(minor_key, 11),\n    \"D:maj\", circshift(major_key, 2),\n    \"F#:min\", circshift(minor_key, 6),\n    \"A:maj\", circshift(major_key, 9),\n    \"C#:min\", circshift(minor_key, 1),\n    \"E:maj\", circshift(major_key, 4),\n    \"G#:min\", circshift(minor_key, 8),\n    \"B:maj\", circshift(major_key, 11),\n    \"D#:min\", circshift(minor_key, 3)\n  )\n\n    tune |&gt; compmus_match_pitch_template(\n    key_templates,         # Change to chord_templates if descired\n    method = \"pearson\",  # Try different distance metrics\n    norm = \"manhattan\"     # Try different norms\n    ) |&gt; \n    group_by(name)  |&gt;\n    summarise(weight = sum(d)) |&gt; \n    arrange(weight)\n\n# A tibble: 24 × 2\n   name   weight\n   &lt;fct&gt;   &lt;dbl&gt;\n 1 D:maj    6.62\n 2 A:maj    6.98\n 3 D:min    8.71\n 4 F#:min   9.99\n 5 A:min   10.4 \n 6 B:min   12.0 \n 7 G:maj   12.3 \n 8 C#:min  12.6 \n 9 E:min   13.3 \n10 C:maj   14.1 \n# ℹ 14 more rows\n\n\nSo this shows that my “indie pop” score agrees more with the Sapp simple weightings than either the Krumhansl Schmuckler or the Spotify algoithm. Indie Pop and Sapp think it’s D major, but Spotify and Krumhansl think A major. When I used my discover playlist, it also says A major (see below).\n\n   name   weight\n   &lt;fct&gt;   &lt;dbl&gt;\n 1 A:maj    5.75\n 2 D:maj    6.60\n 3 B:min    8.65\n 4 D:min   11.0 \n 5 F#:min  11.3 \n 6 C#:min  11.4 \n 7 A:min   12.1 \n 8 G:maj   12.2 \n 9 E:maj   15.1 \n10 E:min   15.5"
  },
  {
    "objectID": "class_notes/week_4.html#gold-medal-question",
    "href": "class_notes/week_4.html#gold-medal-question",
    "title": "Week 4: Conceptual Debates (Key-Finding, Entropy, etc.)",
    "section": "Gold Medal Question",
    "text": "Gold Medal Question\nCan you write a function that compares multiple keys given many profiles of a whole playlist?\nSteps: 1. Grab a playlist from Spotify 2. Grab the key profile 3. Include and argument that allows you to match keys with many key profiles. 4. Output this comparison as a table."
  },
  {
    "objectID": "class_notes/week_7.html",
    "href": "class_notes/week_7.html",
    "title": "Week 8: Adding Features",
    "section": "",
    "text": "Look at running a principal components analysis for authorship\nWork on some models for classifying data\nDiscuss how we might evaluate our models\n\nThis week, we will start by moving from clustering to PCA, or pricinpal components analysis. PCA is often seen as a way of reducing the dimensions of features, and here we will explore what it looks like when exploring questions of authorship.\nWe will follow this by looking at what it means to train a classifier, and some of the research questions we might ask of a classifier.\n\n\nWe will be using a of libraries today:\n\n\n\nPCAs are often used for reducing dimensions when we have lots of variables but a model might be better suited from combining those variables. PCAs have also been used a fair bit to explore questions of authorship. Here we have a question of authorship using symbolic data taken from scores. We are trying to explore the music of Josquin.\nHere we load the data in:\n\n# complete_data &lt;- read_csv(here(\"data\", \"attribution_data_new.csv\", na.strings=c(\"\",\"NA\", header=T)))\ncomplete_data &lt;- read.csv(\"../data/attribution_data_new.csv\", na.strings=c(\"\",\"NA\"), header=T)\ncomplete_data &lt;- complete_data[,-62]\n\nJesse Rodin’s Josquin Research Project has given levels of security for attribution, including pieces that we know are Josquin’s, those we think might be, and those which are more questionable.\n\n# Josquin attribution level 1 and palestrina\n\njosquin &lt;- complete_data[complete_data$Composer == 'Josquin des Prez',-12]\n\njosquin_secure &lt;- josquin[josquin$Attribution.Level &lt;= 2 ,]\njosquin_secure$Composer &lt;- as.character(josquin_secure$Composer)\njosquin_less_secure &lt;- josquin[ josquin$Attribution.Level &gt;= 3,]\n\n\n####Other composers\nbach &lt;- complete_data[complete_data$Composer == \"Bach_Johann Sebastian\",-12]\nlarue &lt;- complete_data[complete_data$Composer == \"la Rue_Pierre de\",-12]\npalestrina &lt;- complete_data[complete_data$Composer == \"Palestrina_Giovanni Perluigi da\",-12]\nockeghem &lt;- complete_data[complete_data$Composer == \"Johannes Ockeghem\",-12]\norto &lt;- complete_data[complete_data$Composer == \"de Orto_Marbrianus\",-12]\ndufay &lt;- complete_data[complete_data$Composer == \"Du Fay_Guillaume\",-12]\n\njosquin_bach &lt;- rbind(josquin_secure, bach)\njosquin_palestrina &lt;- rbind(josquin_secure, palestrina)\njosquin_larue &lt;- rbind(josquin_secure, larue)\n\ncomparison &lt;- rbind(josquin_secure, dufay)\n\n\ncolumns_wanted &lt;- c(5:11)  \nMatrix &lt;- comparison[,columns_wanted]\nMatrix &lt;- as.matrix(Matrix)\nMatrix[is.na(Matrix)] &lt;- 0\n# log.pieces &lt;- log(Matrix)\nlog.pieces &lt;- log(Matrix)\ncomposer &lt;- comparison[,1]\n\nThis code runs the actual principal components analysis.\nIt also provides a scree plot, allowing us to see which components are the most heavily weighted. This can allow us to reduce the dimensions as we see fit.\n\n####principle component analysis.\n\npieces.pca &lt;- prcomp(Matrix,\n                 center = TRUE,\n                 scale. = TRUE) \nplot(pieces.pca, type = \"l\", main=\"Principal Components Analysis\")\n\n\n\n\nIt’s worth taking some time to explore what each of these components actually means and how they’re weighted. PCA is weighting instances of parallel motion and similar motion pretty heavily, but negatively weighting pitch entropy and oblique motion. PC2 seems to be looking at nPVI and 9-8 suspensions.\n\nprint(pieces.pca)\n\nStandard deviations (1, .., p=7):\n[1] 1.3651251 1.1932956 1.0473249 0.9758057 0.8158066 0.7627338 0.6450502\n\nRotation (n x k) = (7 x 7):\n                         PC1         PC2         PC3         PC4         PC5\nnPVI_Entire       -0.1534310  0.28077115 -0.77204065  0.00852347  0.47773321\nNine_Eight        -0.1018707  0.59859586  0.02341681  0.52670532 -0.12881933\npitch_correlation -0.1550940  0.39505005  0.02896214 -0.83452001 -0.15900704\npitch_entropy     -0.1600989  0.50110624  0.56438102  0.04875023  0.32761392\nparallel_motion    0.4600560  0.38613864 -0.26230330 -0.01533229 -0.49612767\nsimilar_motion     0.6300842  0.05699415  0.06600453  0.03642203 -0.03731014\noblique_motion    -0.5547412 -0.05768156 -0.10430981  0.14881862 -0.61239508\n                         PC6         PC7\nnPVI_Entire       -0.2145105 -0.16511611\nNine_Eight         0.5736302 -0.08770651\npitch_correlation  0.2642076 -0.16592149\npitch_entropy     -0.5428772  0.01765806\nparallel_motion   -0.3378146  0.45819860\nsimilar_motion    -0.1086246 -0.76214894\noblique_motion    -0.3667346 -0.38260361\n\n\nAs we can see, about 65% of the variance is accounted for with the first two principal components:\n\nsummary(pieces.pca)\n\nImportance of components:\n                          PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     1.3651 1.1933 1.0473 0.9758 0.81581 0.76273 0.64505\nProportion of Variance 0.2662 0.2034 0.1567 0.1360 0.09508 0.08311 0.05944\nCumulative Proportion  0.2662 0.4697 0.6263 0.7624 0.85745 0.94056 1.00000\n\n\nPlotting our two composers with the first two principal components.\n\ng &lt;- ggbiplot(pieces.pca, obs.scale = 1, var.scale = 1, \n              groups = composer, ellipse = TRUE, \n              circle = TRUE)\ng &lt;- g + scale_color_discrete(name = '')\ng &lt;- g + theme(legend.direction = 'horizontal', \n               legend.position = 'top') +\n               theme_bw()\nprint(g)\n\n\n\n# we can change the number of components\n# seven_component_model &lt;- data.frame(pieces.pca$x[,1:8])\n\nWe can also look at how much each of these features is being weighted within the first two components.\n\ntheta &lt;- seq(0,2*pi,length.out = 100)\ncircle &lt;- data.frame(x = cos(theta), y = sin(theta))\np &lt;- ggplot(circle,aes(x,y)) + geom_path()\n\nloadings &lt;- data.frame(pieces.pca$rotation, \n                       .names = row.names(pieces.pca$rotation))\np + geom_text(data=loadings, \n              mapping=aes(x = PC1, y = PC2, label = .names, colour = .names)) +\n  coord_fixed(ratio=1) +\n  labs(x = \"PC1\", y = \"PC2\") +\n  theme_bw()\n\n\n\n\n\n\n\nA classifier is a model that assigns a label to data based on the input. There are many types of classifiers, and we will be evaluating various models throughout the week. Our goal will be to train a model on the features generally associated with a category, and then test the accuracy of that model. For now, a good starting point might be our Christmas Song question from last week.\n\n\n\nFirst, let’s get the data and add a column that tells us whether it’s a Christmas song or not\n\n### get the data and add yes/no column.\nchristmas &lt;- get_playlist_audio_features(\"\", \"5OP7itTh52BMfZS1DJrdlv\")\nchristmas$christmas &lt;- \"yes\"\n\nnot &lt;- get_playlist_audio_features(\"\", \"6i2Qd6OpeRBAzxfscNXeWp\")\nnot$christmas &lt;- \"no\"\n\n## combine the two datasets and get the columns we want to use.\nchristmas_subset &lt;-rbind(christmas, not)\nchristmas_subset &lt;- christmas_subset |&gt; \n    select(c(\"christmas\", \"acousticness\", \"liveness\", \"danceability\", \"loudness\", \"speechiness\", \"valence\"))\n\nNow we can use the createDataPartition function from the caret library to create a testing and a training dataset. Here, I’ve chosen a 70/30 partition of training and testing, but you can adjust as you see fit.\n\nTrain &lt;- createDataPartition(christmas_subset$christmas, p=0.7, list=FALSE)\ntraining &lt;- christmas_subset[ Train, ]\ntesting &lt;- christmas_subset[ -Train, ]\n\nWe can pretty easily implement something like a neural network, using our training dataset to train it:\n\nmod_fit &lt;- caret::train(christmas ~ .,  \n                 data=training, method=\"nnet\", importance = \"christmas\")\n\nOnce we’ve trained this model, we can test it on our testing dataset, and see how well it does:\n\npred &lt;- predict(mod_fit, testing)\nconfusionMatrix(pred, as.factor(testing$christmas), positive = \"yes\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction no yes\n       no  25   8\n       yes 10  22\n                                          \n               Accuracy : 0.7231          \n                 95% CI : (0.5981, 0.8269)\n    No Information Rate : 0.5385          \n    P-Value [Acc &gt; NIR] : 0.001783        \n                                          \n                  Kappa : 0.4455          \n                                          \n Mcnemar's Test P-Value : 0.813664        \n                                          \n            Sensitivity : 0.7333          \n            Specificity : 0.7143          \n         Pos Pred Value : 0.6875          \n         Neg Pred Value : 0.7576          \n             Prevalence : 0.4615          \n         Detection Rate : 0.3385          \n   Detection Prevalence : 0.4923          \n      Balanced Accuracy : 0.7238          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\nSo what does this all mean? Let’s define some terms.\n\nAccuracy:\n\nthe accuracy rate. Just how many things it got right.\n\n95% CI:\n\nthe confidence interval of the accuracy.\n\nNo information rate:\n\ngiven no more information other than the overall distribution, how likely are you to be correct if you just pick the “majority class.”\nif you have an accuracy rate of 80%, but the majority class is 80%, then your model isn’t terribly useful.\n\nP-Value:\n\nlikelihood of chance.\n\nKappa:\n\nmeasures the agreement between two raters and ratings. Here it’s looking at the difference between observed accuracy and random chance given the distribution in the dataset.\n\nMcNemar’s Test P-Value:\n\nthis is looking at the two distributions (from a 2x2 table), and determines if they are significantly different,\n\nSensitivity:\n\ngiven that a result is actually a thing, what is the probability that our model will predict that event’s results?\n\nSpecificity:\n\ngiven that a result is not actually a thing, what is the probability that our model will predict that?\n\nPos Predictive Value:\n\nthe probability that a predicted ‘positive’ class is actually positive.\n\nNeg Predictive Value:\n\nthe probability that a predicted ‘negative’ class is actually negative.\n\nPrevalence:\n\nthe prevalence of the ‘positive event’\n\nDetection Rate:\n\nthe rate of true events also predicted to be events\n\nDetection Prevalence\n\nthe prevalence of predicted events\n\nBalanced Accuracy:\n\nthe average of the proportion corrects of each class individually\n\n\n\n\nWe can look at which features the model is using…\n\nplot(varImp(mod_fit))\n\n\n\n\n\n\n\n\n\nUse PCA to explore the works of two artists. How well do they “separate”?\nRun a classifier on two groups (it can be the same two artists, or two distinct groups). How well does your model do?\n\nToday we are going to look at different models and evaluating models. Our research question will be training a model to decipher John Lennon songs from Paul McCartney songs with various classifiers."
  },
  {
    "objectID": "class_notes/week_7.html#getting-started",
    "href": "class_notes/week_7.html#getting-started",
    "title": "Week 8: Adding Features",
    "section": "",
    "text": "We will be using a of libraries today:"
  },
  {
    "objectID": "class_notes/week_7.html#pca-and-authorship",
    "href": "class_notes/week_7.html#pca-and-authorship",
    "title": "Week 8: Adding Features",
    "section": "",
    "text": "PCAs are often used for reducing dimensions when we have lots of variables but a model might be better suited from combining those variables. PCAs have also been used a fair bit to explore questions of authorship. Here we have a question of authorship using symbolic data taken from scores. We are trying to explore the music of Josquin.\nHere we load the data in:\n\n# complete_data &lt;- read_csv(here(\"data\", \"attribution_data_new.csv\", na.strings=c(\"\",\"NA\", header=T)))\ncomplete_data &lt;- read.csv(\"../data/attribution_data_new.csv\", na.strings=c(\"\",\"NA\"), header=T)\ncomplete_data &lt;- complete_data[,-62]\n\nJesse Rodin’s Josquin Research Project has given levels of security for attribution, including pieces that we know are Josquin’s, those we think might be, and those which are more questionable.\n\n# Josquin attribution level 1 and palestrina\n\njosquin &lt;- complete_data[complete_data$Composer == 'Josquin des Prez',-12]\n\njosquin_secure &lt;- josquin[josquin$Attribution.Level &lt;= 2 ,]\njosquin_secure$Composer &lt;- as.character(josquin_secure$Composer)\njosquin_less_secure &lt;- josquin[ josquin$Attribution.Level &gt;= 3,]\n\n\n####Other composers\nbach &lt;- complete_data[complete_data$Composer == \"Bach_Johann Sebastian\",-12]\nlarue &lt;- complete_data[complete_data$Composer == \"la Rue_Pierre de\",-12]\npalestrina &lt;- complete_data[complete_data$Composer == \"Palestrina_Giovanni Perluigi da\",-12]\nockeghem &lt;- complete_data[complete_data$Composer == \"Johannes Ockeghem\",-12]\norto &lt;- complete_data[complete_data$Composer == \"de Orto_Marbrianus\",-12]\ndufay &lt;- complete_data[complete_data$Composer == \"Du Fay_Guillaume\",-12]\n\njosquin_bach &lt;- rbind(josquin_secure, bach)\njosquin_palestrina &lt;- rbind(josquin_secure, palestrina)\njosquin_larue &lt;- rbind(josquin_secure, larue)\n\ncomparison &lt;- rbind(josquin_secure, dufay)\n\n\ncolumns_wanted &lt;- c(5:11)  \nMatrix &lt;- comparison[,columns_wanted]\nMatrix &lt;- as.matrix(Matrix)\nMatrix[is.na(Matrix)] &lt;- 0\n# log.pieces &lt;- log(Matrix)\nlog.pieces &lt;- log(Matrix)\ncomposer &lt;- comparison[,1]\n\nThis code runs the actual principal components analysis.\nIt also provides a scree plot, allowing us to see which components are the most heavily weighted. This can allow us to reduce the dimensions as we see fit.\n\n####principle component analysis.\n\npieces.pca &lt;- prcomp(Matrix,\n                 center = TRUE,\n                 scale. = TRUE) \nplot(pieces.pca, type = \"l\", main=\"Principal Components Analysis\")\n\n\n\n\nIt’s worth taking some time to explore what each of these components actually means and how they’re weighted. PCA is weighting instances of parallel motion and similar motion pretty heavily, but negatively weighting pitch entropy and oblique motion. PC2 seems to be looking at nPVI and 9-8 suspensions.\n\nprint(pieces.pca)\n\nStandard deviations (1, .., p=7):\n[1] 1.3651251 1.1932956 1.0473249 0.9758057 0.8158066 0.7627338 0.6450502\n\nRotation (n x k) = (7 x 7):\n                         PC1         PC2         PC3         PC4         PC5\nnPVI_Entire       -0.1534310  0.28077115 -0.77204065  0.00852347  0.47773321\nNine_Eight        -0.1018707  0.59859586  0.02341681  0.52670532 -0.12881933\npitch_correlation -0.1550940  0.39505005  0.02896214 -0.83452001 -0.15900704\npitch_entropy     -0.1600989  0.50110624  0.56438102  0.04875023  0.32761392\nparallel_motion    0.4600560  0.38613864 -0.26230330 -0.01533229 -0.49612767\nsimilar_motion     0.6300842  0.05699415  0.06600453  0.03642203 -0.03731014\noblique_motion    -0.5547412 -0.05768156 -0.10430981  0.14881862 -0.61239508\n                         PC6         PC7\nnPVI_Entire       -0.2145105 -0.16511611\nNine_Eight         0.5736302 -0.08770651\npitch_correlation  0.2642076 -0.16592149\npitch_entropy     -0.5428772  0.01765806\nparallel_motion   -0.3378146  0.45819860\nsimilar_motion    -0.1086246 -0.76214894\noblique_motion    -0.3667346 -0.38260361\n\n\nAs we can see, about 65% of the variance is accounted for with the first two principal components:\n\nsummary(pieces.pca)\n\nImportance of components:\n                          PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     1.3651 1.1933 1.0473 0.9758 0.81581 0.76273 0.64505\nProportion of Variance 0.2662 0.2034 0.1567 0.1360 0.09508 0.08311 0.05944\nCumulative Proportion  0.2662 0.4697 0.6263 0.7624 0.85745 0.94056 1.00000\n\n\nPlotting our two composers with the first two principal components.\n\ng &lt;- ggbiplot(pieces.pca, obs.scale = 1, var.scale = 1, \n              groups = composer, ellipse = TRUE, \n              circle = TRUE)\ng &lt;- g + scale_color_discrete(name = '')\ng &lt;- g + theme(legend.direction = 'horizontal', \n               legend.position = 'top') +\n               theme_bw()\nprint(g)\n\n\n\n# we can change the number of components\n# seven_component_model &lt;- data.frame(pieces.pca$x[,1:8])\n\nWe can also look at how much each of these features is being weighted within the first two components.\n\ntheta &lt;- seq(0,2*pi,length.out = 100)\ncircle &lt;- data.frame(x = cos(theta), y = sin(theta))\np &lt;- ggplot(circle,aes(x,y)) + geom_path()\n\nloadings &lt;- data.frame(pieces.pca$rotation, \n                       .names = row.names(pieces.pca$rotation))\np + geom_text(data=loadings, \n              mapping=aes(x = PC1, y = PC2, label = .names, colour = .names)) +\n  coord_fixed(ratio=1) +\n  labs(x = \"PC1\", y = \"PC2\") +\n  theme_bw()"
  },
  {
    "objectID": "class_notes/week_7.html#classifiers",
    "href": "class_notes/week_7.html#classifiers",
    "title": "Week 8: Adding Features",
    "section": "",
    "text": "A classifier is a model that assigns a label to data based on the input. There are many types of classifiers, and we will be evaluating various models throughout the week. Our goal will be to train a model on the features generally associated with a category, and then test the accuracy of that model. For now, a good starting point might be our Christmas Song question from last week."
  },
  {
    "objectID": "class_notes/week_7.html#returning-to-our-christmas-song-problem",
    "href": "class_notes/week_7.html#returning-to-our-christmas-song-problem",
    "title": "Week 8: Adding Features",
    "section": "",
    "text": "First, let’s get the data and add a column that tells us whether it’s a Christmas song or not\n\n### get the data and add yes/no column.\nchristmas &lt;- get_playlist_audio_features(\"\", \"5OP7itTh52BMfZS1DJrdlv\")\nchristmas$christmas &lt;- \"yes\"\n\nnot &lt;- get_playlist_audio_features(\"\", \"6i2Qd6OpeRBAzxfscNXeWp\")\nnot$christmas &lt;- \"no\"\n\n## combine the two datasets and get the columns we want to use.\nchristmas_subset &lt;-rbind(christmas, not)\nchristmas_subset &lt;- christmas_subset |&gt; \n    select(c(\"christmas\", \"acousticness\", \"liveness\", \"danceability\", \"loudness\", \"speechiness\", \"valence\"))\n\nNow we can use the createDataPartition function from the caret library to create a testing and a training dataset. Here, I’ve chosen a 70/30 partition of training and testing, but you can adjust as you see fit.\n\nTrain &lt;- createDataPartition(christmas_subset$christmas, p=0.7, list=FALSE)\ntraining &lt;- christmas_subset[ Train, ]\ntesting &lt;- christmas_subset[ -Train, ]\n\nWe can pretty easily implement something like a neural network, using our training dataset to train it:\n\nmod_fit &lt;- caret::train(christmas ~ .,  \n                 data=training, method=\"nnet\", importance = \"christmas\")\n\nOnce we’ve trained this model, we can test it on our testing dataset, and see how well it does:\n\npred &lt;- predict(mod_fit, testing)\nconfusionMatrix(pred, as.factor(testing$christmas), positive = \"yes\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction no yes\n       no  25   8\n       yes 10  22\n                                          \n               Accuracy : 0.7231          \n                 95% CI : (0.5981, 0.8269)\n    No Information Rate : 0.5385          \n    P-Value [Acc &gt; NIR] : 0.001783        \n                                          \n                  Kappa : 0.4455          \n                                          \n Mcnemar's Test P-Value : 0.813664        \n                                          \n            Sensitivity : 0.7333          \n            Specificity : 0.7143          \n         Pos Pred Value : 0.6875          \n         Neg Pred Value : 0.7576          \n             Prevalence : 0.4615          \n         Detection Rate : 0.3385          \n   Detection Prevalence : 0.4923          \n      Balanced Accuracy : 0.7238          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\nSo what does this all mean? Let’s define some terms.\n\nAccuracy:\n\nthe accuracy rate. Just how many things it got right.\n\n95% CI:\n\nthe confidence interval of the accuracy.\n\nNo information rate:\n\ngiven no more information other than the overall distribution, how likely are you to be correct if you just pick the “majority class.”\nif you have an accuracy rate of 80%, but the majority class is 80%, then your model isn’t terribly useful.\n\nP-Value:\n\nlikelihood of chance.\n\nKappa:\n\nmeasures the agreement between two raters and ratings. Here it’s looking at the difference between observed accuracy and random chance given the distribution in the dataset.\n\nMcNemar’s Test P-Value:\n\nthis is looking at the two distributions (from a 2x2 table), and determines if they are significantly different,\n\nSensitivity:\n\ngiven that a result is actually a thing, what is the probability that our model will predict that event’s results?\n\nSpecificity:\n\ngiven that a result is not actually a thing, what is the probability that our model will predict that?\n\nPos Predictive Value:\n\nthe probability that a predicted ‘positive’ class is actually positive.\n\nNeg Predictive Value:\n\nthe probability that a predicted ‘negative’ class is actually negative.\n\nPrevalence:\n\nthe prevalence of the ‘positive event’\n\nDetection Rate:\n\nthe rate of true events also predicted to be events\n\nDetection Prevalence\n\nthe prevalence of predicted events\n\nBalanced Accuracy:\n\nthe average of the proportion corrects of each class individually\n\n\n\n\nWe can look at which features the model is using…\n\nplot(varImp(mod_fit))"
  },
  {
    "objectID": "class_notes/week_7.html#exercise",
    "href": "class_notes/week_7.html#exercise",
    "title": "Week 8: Adding Features",
    "section": "",
    "text": "Use PCA to explore the works of two artists. How well do they “separate”?\nRun a classifier on two groups (it can be the same two artists, or two distinct groups). How well does your model do?\n\nToday we are going to look at different models and evaluating models. Our research question will be training a model to decipher John Lennon songs from Paul McCartney songs with various classifiers."
  },
  {
    "objectID": "class_notes/week_7.html#getting-the-data",
    "href": "class_notes/week_7.html#getting-the-data",
    "title": "Week 8: Adding Features",
    "section": "Getting the Data",
    "text": "Getting the Data\n\njohn &lt;- get_artist_audio_features('john lennon')\npaul &lt;- get_artist_audio_features('paul mccartney')\nboth &lt;- rbind(john, paul)\n\nWhat is the balance of pieces like? It looks like we have far more McCartney than Lennon pieces. What does this mean for our model?\n\ntable(both$artist_name)\n\n\n   John Lennon Paul McCartney \n           584            984 \n\n\nWe then can grab only the features that we want to explore for this model.\n\nboth_subset &lt;- both |&gt; select(c(\"artist_name\", \"acousticness\", \"liveness\", \"danceability\", \"loudness\", \"speechiness\", \"valence\"))\n\nBefore running a clustering, PCA, or a classifier such as a k-nearest neighbor, it’s probably good to standardize your data. This means that the data is consistent, and prevents wide ranges from dominating the results. Here we’ve scaled all of our data with the z-score of the data according with the rest of the data for that category.\nI’ve also (temporarily) split the data from the artist, and then brought it all back together with cbind.\n\ndata &lt;- both_subset[,-1]\nartists &lt;- both_subset[,1]\ndata &lt;- data %&gt;% mutate_all(~(scale(.) %&gt;% as.vector))\nboth_artists &lt;- cbind(artists, data)"
  },
  {
    "objectID": "class_notes/week_7.html#cross-validation",
    "href": "class_notes/week_7.html#cross-validation",
    "title": "Week 8: Adding Features",
    "section": "Cross-Validation",
    "text": "Cross-Validation\nCross-validation splits the data up into a testing and training set, and evaluates it.\n\nK-folds cross validation:\nK refers to the number of groups that data is split into.\n\nIt randomizes the data\nsplits it into the specified number of groups\nfor each group, split into a training and testing set, and then evaluate\n\n\nctrl &lt;- trainControl(method = \"repeatedcv\", number = 2, savePredictions = TRUE)\n\n\nTrain &lt;- createDataPartition(both_artists$artists, p=0.7, list=FALSE)\ntraining &lt;- both_artists[ Train, ]\ntesting &lt;- both_artists[ -Train, ]\n\nLet’s look at our results with a logistic regression:\n\nmod_fit &lt;- train(artists ~ .,  data=both_artists, method=\"glm\", family=\"binomial\",\n                 trControl = ctrl, tuneLength = 10)\n\ntesting$artists &lt;- as.factor(testing$artists)\npred &lt;- predict(mod_fit, newdata=testing)\nconfusionMatrix(data=pred, testing$artists)\n\nConfusion Matrix and Statistics\n\n                Reference\nPrediction       John Lennon Paul McCartney\n  John Lennon             75             53\n  Paul McCartney         100            242\n                                        \n               Accuracy : 0.6745        \n                 95% CI : (0.63, 0.7167)\n    No Information Rate : 0.6277        \n    P-Value [Acc &gt; NIR] : 0.0194128     \n                                        \n                  Kappa : 0.2633        \n                                        \n Mcnemar's Test P-Value : 0.0002001     \n                                        \n            Sensitivity : 0.4286        \n            Specificity : 0.8203        \n         Pos Pred Value : 0.5859        \n         Neg Pred Value : 0.7076        \n             Prevalence : 0.3723        \n         Detection Rate : 0.1596        \n   Detection Prevalence : 0.2723        \n      Balanced Accuracy : 0.6245        \n                                        \n       'Positive' Class : John Lennon   \n                                        \n\n\nIt looks like the accuracy is about 76%, but pay attention to the sensitivity and the specificity values.\nRecall that sensitivity is a measurement of how well the model can detect a “positive” instance, and specificity measures how well the model is finding true negatives.\nSensitivity can be defined as follows:\n\nSensitivity = (True Positive)/(True Positive + False Negative)\n\nand specificity can be defined as follows:\n\nSpecificity = (True Negative)/(True Negative + False Positive)\n\nSo this model is quite good at finding the negative class (here defined as McCartney), but not great at finding the positive class (Lennon)."
  },
  {
    "objectID": "class_notes/week_7.html#other-models",
    "href": "class_notes/week_7.html#other-models",
    "title": "Week 8: Adding Features",
    "section": "Other Models",
    "text": "Other Models\nLet’s run the same code again, but now with a k-nearest neighbor. For our sanity, let’s put it into a function.\n\nmodel_evaluation &lt;- function(method){\n    Train &lt;- createDataPartition(both_artists$artists, p=0.7, list=FALSE)\n    training &lt;- both_artists[ Train, ]\n    testing &lt;- both_artists[ -Train, ]\n    mod_fit &lt;- train(artists ~ .,  \n                     data=training, method=method)\n    pred &lt;- predict(mod_fit, newdata=testing)\n\n    accuracy &lt;- table(pred, testing[,\"artists\"])\n    sum(diag(accuracy))/sum(accuracy)\n    testing$artists &lt;- as.factor(testing$artists)\n    confusionMatrix(data=pred, testing$artists)\n    \n}\nmodel_evaluation(\"kknn\")\n\nConfusion Matrix and Statistics\n\n                Reference\nPrediction       John Lennon Paul McCartney\n  John Lennon            102             62\n  Paul McCartney          73            233\n                                          \n               Accuracy : 0.7128          \n                 95% CI : (0.6695, 0.7533)\n    No Information Rate : 0.6277          \n    P-Value [Acc &gt; NIR] : 6.287e-05       \n                                          \n                  Kappa : 0.3775          \n                                          \n Mcnemar's Test P-Value : 0.3894          \n                                          \n            Sensitivity : 0.5829          \n            Specificity : 0.7898          \n         Pos Pred Value : 0.6220          \n         Neg Pred Value : 0.7614          \n             Prevalence : 0.3723          \n         Detection Rate : 0.2170          \n   Detection Prevalence : 0.3489          \n      Balanced Accuracy : 0.6863          \n                                          \n       'Positive' Class : John Lennon     \n                                          \n\n\nNote that it performs quite well! It’s better at finding the “John Lennon” model.\nWhy do we think this model performed better? A comparison of models can be found here.\n\nNeural Net\nA neural net doesn’t seem to do as well.\n\nmodel_evaluation(\"nnet\")"
  },
  {
    "objectID": "class_notes/week_7.html#comparing-models",
    "href": "class_notes/week_7.html#comparing-models",
    "title": "Week 8: Adding Features",
    "section": "Comparing Models",
    "text": "Comparing Models\n\nLogistic Regression\nK-nearest neighbor\nneural net\nLearning Vector Quantization\ngradient boosted machine\nsupport vector machine\n\nWe can train different models explicitly (without a function) for now.\n\nset.seed(1234)\ncontrol &lt;- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n\n# train logistic regression\nmodelglm &lt;- train(artists ~ ., data=both_artists, method=\"glm\", trControl=control)\n\n# train knn\nmodelknn &lt;- train(artists ~ ., data=both_artists, method=\"kknn\", trControl=control)\n\n# train nnet\nmodelnnet &lt;- train(artists ~ ., data=both_artists, method=\"nnet\", trControl=control)\n\n# train the LVQ model\nmodelLvq &lt;- train(artists ~ ., data=both_artists, method=\"lvq\", trControl=control)\n\n# train the GBM model\nset.seed(7)\nmodelGbm &lt;- train(artists ~ ., data=both_artists, method=\"gbm\", trControl=control)\n\n# train the SVM model\nset.seed(7)\nmodelSvm &lt;- train(artists ~., data=both_artists, method=\"svmRadial\", trControl=control)\n\n# train the random forest\nrandomforest &lt;- train(artists~., data=both_artists, method=\"ranger\", trControl=control)\n\nWe can actually look at the resampling of the dataset for each model, and get the results for each model:\n\n# collect resamples\nresults &lt;- resamples(list(LVQ=modelLvq, GBM=modelGbm, SVM=modelSvm,knn=modelknn, nnet=modelnnet, glm=modelglm, rf=randomforest))\n\n# summarize the distributions\nsummary(results)\n\n\nCall:\nsummary.resamples(object = results)\n\nModels: LVQ, GBM, SVM, knn, nnet, glm, rf \nNumber of resamples: 30 \n\nAccuracy \n          Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nLVQ  0.6050955 0.6415973 0.6602564 0.6600220 0.6751592 0.7133758    0\nGBM  0.6962025 0.7439980 0.7619124 0.7663809 0.7878695 0.8397436    0\nSVM  0.6687898 0.7179487 0.7388535 0.7387526 0.7687306 0.8012821    0\nknn  0.7324841 0.7647041 0.7809603 0.7832078 0.8012821 0.8333333    0\nnnet 0.6794872 0.7208987 0.7324841 0.7363845 0.7527715 0.8076923    0\nglm  0.6089744 0.6634820 0.6858974 0.6862284 0.7099359 0.7594937    0\nrf   0.7388535 0.8028602 0.8210844 0.8237734 0.8450584 0.9050633    0\n\nKappa \n           Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nLVQ  0.08665105 0.1683163 0.2101309 0.2206380 0.2633926 0.3847244    0\nGBM  0.32297804 0.4362291 0.4827239 0.4877173 0.5394920 0.6557203    0\nSVM  0.27879859 0.3771507 0.4167157 0.4276538 0.4885911 0.5730932    0\nknn  0.42590980 0.4981390 0.5401244 0.5399265 0.5824790 0.6505858    0\nnnet 0.29398986 0.3882580 0.4259220 0.4245391 0.4615117 0.5824411    0\nglm  0.07503888 0.2320983 0.2821086 0.2882337 0.3352471 0.4441770    0\nrf   0.44522968 0.5735189 0.6111771 0.6168420 0.6640556 0.7935900    0\n\n\nIt might be better to look at the accuracy for each model. Here we have the accuracy rating as well as Cohen’s Kappa, which is like accuracy but also incorporates the imbalance of the dataset.\n\n# boxplots of results\nbwplot(results)\n\n\n\n\nHere’s another plot:\n\n# dot plots of results\ndotplot(results)\n\n\n\n\nIs it possible to use this for a research question??\nWhat if we use our neural net model but on a different dataset? How about the beatles dataset that is available on Spotify (which admittedly isn’t as much as we’d like).\n\nGrabbing Beatles Data\nWe can start by getting the data from Spotify:\n\nbeatles &lt;- get_artist_audio_features('the beatles')\nbeatles_subset &lt;- beatles |&gt; select(c(\"artist_name\", \"acousticness\", \"energy\", \"instrumentalness\", \"liveness\", \"danceability\", \"loudness\", \"speechiness\", \"valence\"))\n\n\n\nPredicting\nNow we can use the models that we’ve trained, but on new data. Here we use the k-nearest neighbor models.\n\nbeatles_knn &lt;- predict(modelknn, newdata=beatles_subset)\nbeatles_nnet &lt;- predict(modelnnet, newdata=beatles_subset)\nbeatles_glm &lt;- predict(modelglm, newdata=beatles_subset)\nbeatles_svm &lt;- predict(modelSvm, newdata=beatles_subset) \n\nNow, we are going to create a data frame of the track name, and the results from the model.\n\nclassified_data &lt;- as.data.frame(cbind(beatles_knn, beatles_nnet, beatles_glm, beatles_svm, beatles$track_name))\nclassified_data |&gt; datatable(filter =\"top\") \n\n\n\n\n\n\n(Note that this table doesn’t seem to be rendering correctly when pushed online)."
  },
  {
    "objectID": "class_notes/week_7.html#summary",
    "href": "class_notes/week_7.html#summary",
    "title": "Week 8: Adding Features",
    "section": "Summary",
    "text": "Summary\nWhat I like about this is that we can take something about authorship that we know, and then use it to explore authorship of things that are a little more ambiguous. It can also teach us a fair bit about the specific models. Why do we think some performed so much better than others?\n\nExercise:\nLet’s try to build an east/west coast rap classifier (an outdated concept, I know):\nHere are some important steps for us to go through as we think about training a classifier:\n\nGrab data\npartition and train model\ncompare models\nuse it to predict a new dataset.\n\n\nLet’s grab the data.\nHere I’m going to grab two playlists, one about “East coast” rap, and the other about “West coast”.\n\neast_coast &lt;- get_playlist_audio_features(\"\", \"3pu8tsqTW52aUtYFZN3g4A\")\neast_coast$coast &lt;- \"east\"\nwest_coast &lt;- get_playlist_audio_features(\"\", \"6lAOSVxxvGuEhPtZguaeav\")\nwest_coast$coast &lt;- \"west\"\nboth &lt;- rbind(east_coast, west_coast)\n\n####standardize and clean a bit\n\nNow I’m going to grab the features that are important to me. Here it’s the “coast” variable, followed by the standard “global features” that the Spotify API provides.\n\nboth &lt;- both %&gt;% select(c(\"coast\", \"acousticness\", \"energy\", \"instrumentalness\", \"liveness\", \"danceability\", \"loudness\", \"speechiness\", \"valence\"))\n\ndata &lt;- both[,-1]\ncoast &lt;- both[,1]\ndata &lt;- data %&gt;% mutate_all(~(scale(.) %&gt;% as.vector))\nboth &lt;- cbind(coast, data)\n\nHere we can run a k-folds cross-validation:\nHere, the data is split into 10 subsets (or folds), and trains on k-1 of the folds (here 9), and tested on 1 of them. Then it repeats it a few times. In this case, 3.\n\nset.seed(1234)\ncontrol &lt;- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n\nHere we can run the cross-validation with different types of classifiers and plot the results.\n\n# train logistic regression\nmodelglm &lt;- train(coast ~ ., data=both, method=\"glm\", trControl=control)\n\n# train knn\nmodelknn &lt;- train(coast ~ ., data=both, method=\"kknn\", trControl=control)\n\n# train nnet\nmodelnnet &lt;- train(coast ~ ., data=both, method=\"nnet\", trControl=control)\n\n# train the LVQ model\nmodelLvq &lt;- train(coast ~ ., data=both, method=\"lvq\", trControl=control)\n\n# train the GBM model\nmodelGbm &lt;- train(coast ~ ., data=both, method=\"gbm\", trControl=control)\n\n# train the SVM model\nmodelSvm &lt;- train(coast ~., data=both, method=\"svmRadial\", trControl=control)\n\n# train the random forest\nrandomforest &lt;- train(coast~., data=both, method=\"ranger\", trControl=control)\n\n# collect resamples\nresults &lt;- resamples(list(LVQ=modelLvq, GBM=modelGbm, SVM=modelSvm,knn=modelknn, nnet=modelnnet, glm=modelglm, rf=randomforest))\n\n\n# summarize the distributions\nsummary(results)\nbwplot(results)\n\n\n\n\nNow we can test our model on a dataset from outside of our initial training/testing stage:\n\nkendrick_data &lt;- get_artist_audio_features('kendrick lamar')\n\nkendrick &lt;- kendrick_data |&gt; select(c(\"acousticness\", \"energy\", \"instrumentalness\", \"liveness\", \"danceability\", \"loudness\", \"speechiness\", \"valence\"))\n\nkendrick &lt;- kendrick %&gt;% mutate_all(~(scale(.) %&gt;% as.vector))\n\nkendrick_rf &lt;- predict(randomforest, newdata=kendrick)\nkendrick_knn &lt;- predict(modelknn, newdata=kendrick)\nkendrick_nnet &lt;- predict(modelnnet, newdata=kendrick)\ntable(kendrick_rf)\n\nkendrick_rf\neast west \n 115   27 \n\nclassified_data &lt;- as.data.frame(cbind(kendrick_rf, kendrick_knn, kendrick_nnet, kendrick_data$track_name))\nclassified_data$kendrick_knn &lt;- if_else(classified_data$kendrick_knn == 2, \"West\", \"East\")\nclassified_data$kendrick_rf &lt;- if_else(classified_data$kendrick_rf == 2, \"West\", \"East\")\nclassified_data$kendrick_nnet &lt;- if_else(classified_data$kendrick_nnet == 2, \"West\", \"East\")\nclassified_data$track_name &lt;- kendrick$track_name\nclassified_data |&gt; datatable(filter =\"top\") \n\n\n\n\n\n\nPlease note that this is a totally ridiculous classifier for Kendrick Lamar, but hopefully it demonstrates some possible techniques.\nWhat would be a better research question?"
  },
  {
    "objectID": "class_notes/week_7.html#global-features-of-interest",
    "href": "class_notes/week_7.html#global-features-of-interest",
    "title": "Week 8: Adding Features",
    "section": "Global features of interest",
    "text": "Global features of interest\n\nMetadata we’ve been using\n\nartist_name\nalbum_release_date\nalbum_release_year\nalbum_release_date_precision\navailable_markets\ntrack_name\nalbum_name\n\n\n\nContinuous Variables\n\ndanceability\nenergy\nloudness\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nduration_ms\nkey_confidence\nmode_confidence\ntime_signature_confidence\ntempo_confidence\nstart_of_fadeout\nend_of_fadeout\nduration\n\n\n\nContinuous Variables from Lyrics\n\nTF-IDF\nSentiment analysis ()\n\n\n\nCategorical Variables\n\nmode\nexplicit\nkey\nkey_name\nmode_name\nkey_mode\ntime_signature"
  },
  {
    "objectID": "class_notes/week_7.html#relationship-to-the-broader-key-profile",
    "href": "class_notes/week_7.html#relationship-to-the-broader-key-profile",
    "title": "Week 8: Adding Features",
    "section": "Relationship to the Broader Key Profile",
    "text": "Relationship to the Broader Key Profile\nOne way of exploring a piece is by looking at how it fits within a broader key profile. For example, if we have one key profile taken from a large collection, how does a specific piece relate to that collection in terms of pitch content?\nHere, we can start by getting a key profile of a playlist.\n\ngrab_playlist_info &lt;- function(uri){\n   get_playlist_audio_features(\"\", uri) |&gt;\n   add_audio_analysis() \n}\nplaylist &lt;- grab_playlist_info(\"37i9dQZF1DX1kCIzMYtzum\")  \n\nThen we can grab chroma and pitches with code from earlier in the quarter (provided by Burgoyne examples):\n\nget_pitch_list &lt;- function(input){\n   ##burgoyne's comp_mus code for gathering key profiles from chroma.\n   input |&gt;     \n   mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n   select(segments) |&gt;\n   unnest(segments) |&gt; \n   select(start, duration, pitches) |&gt; \n   mutate(pitches = map(pitches, compmus_normalise, \"euclidean\")) |&gt;\n   compmus_gather_chroma() |&gt;\n   group_by(pitch_class) |&gt;\n   summarise(mean_value = mean(value))\n}\n\nThen we just need to grab each list, and provide a pitch correlation (here I’ve used a loop, which might not be the most efficient way to do it in R).\n\npitch_list &lt;- get_pitch_list(playlist)\nplaylist$pitch_cor &lt;- NA\nfor(i in 1:nrow(playlist)){\n    pitch &lt;- get_pitch_list(playlist[i,])\n    playlist$pitch_cor[i] &lt;- cor(pitch$mean_value, pitch_list$mean_value)\n}\n\n\nExercise\n\nCan you grab a collection, and then look at how each piece in that collection relates to the broader key profile?"
  },
  {
    "objectID": "class_notes/week_7.html#transition-probabilities",
    "href": "class_notes/week_7.html#transition-probabilities",
    "title": "Week 8: Adding Features",
    "section": "Transition Probabilities",
    "text": "Transition Probabilities\nWe could also grab transition probabilities from note to note. Here we use previously used code to get chroma that go from one to another.\n\nchroma_names &lt;- c(\"C\", \"C#|Db\",\"D\", \"D#|Eb\", \"E\", \"F\", \"F#|Gb\",\"G\", \"G#|Ab\",\"A\", \"A#|Bb\",\"B\" )\n\n\nx &lt;- playlist |&gt;  \n    mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n    select(segments) |&gt;\n    unnest(segments) |&gt;\n    select(start, duration, pitches) |&gt;\n    unnest(cols = pitches)\nx$chroma &lt;- rep(chroma_names, nrow(x)/12)\nx &lt;- x |&gt;\n  filter(pitches == 1) |&gt;\n  mutate(chroma2 = lead(chroma))\nx |&gt; select(chroma, chroma2) |&gt; table() |&gt; heatmap(Rowv = NA,\n        Colv = NA)\n\n\n\n\nWe might also want to run it as proportions, rather than raw counts:\n\npairs &lt;-  x |&gt; select(chroma, chroma2) |&gt; table()\nprop.table(pairs) |&gt; heatmap(Rowv = NA,\n        Colv = NA)\n\n\n\n\nWe can convert this data to rows and columns like this, and can then move toward adding it to the dataset.\n\ngrab_pitch_pairs &lt;- function(input){\n    x &lt;- input |&gt;  \n    mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n    select(segments) |&gt;\n    unnest(segments) |&gt;\n    select(start, duration, pitches) |&gt;\n    unnest(cols = pitches)\n\n    x$chroma &lt;- rep(chroma_names, nrow(x)/12)\n    x &lt;- x |&gt;\n      filter(pitches == 1) |&gt;\n      mutate(chroma2 = lead(chroma))\n    pair_proportion &lt;- prop.table(pairs)\n    pair_proportion &lt;- as.matrix(pair_proportion)\n\n    # melt the data.frame\n    df &lt;- reshape2::melt(pair_proportion, na.rm = TRUE)\n    df$combined &lt;- paste0(df$chroma,\"-\",df$chroma2)\n    df$combined &lt;- as.factor(df$combined)\n    df &lt;- as_tibble(df)\n    y &lt;- df |&gt; select(value, combined)\n    print(y)\n}\n\nThis is how we’d get the transitions from each pitch:\n\nn &lt;- grab_pitch_pairs(playlist) \n\n# A tibble: 144 × 2\n      value combined\n      &lt;dbl&gt; &lt;fct&gt;   \n 1 0.0150   A-A     \n 2 0.00326  A#|Bb-A \n 3 0.00345  B-A     \n 4 0.00577  C-A     \n 5 0.00112  C#|Db-A \n 6 0.00404  D-A     \n 7 0.00274  D#|Eb-A \n 8 0.00460  E-A     \n 9 0.00366  F-A     \n10 0.000927 F#|Gb-A \n# ℹ 134 more rows\n\n\nAnd we can pivot it to a table format with pivot_wide.\n\nn |&gt; pivot_wider(names_from = combined, values_from = value)\n\n# A tibble: 1 × 144\n   `A-A` `A#|Bb-A`   `B-A`   `C-A` `C#|Db-A`   `D-A` `D#|Eb-A`   `E-A`   `F-A`\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 0.0150   0.00326 0.00345 0.00577   0.00112 0.00404   0.00274 0.00460 0.00366\n# ℹ 135 more variables: `F#|Gb-A` &lt;dbl&gt;, `G-A` &lt;dbl&gt;, `G#|Ab-A` &lt;dbl&gt;,\n#   `A-A#|Bb` &lt;dbl&gt;, `A#|Bb-A#|Bb` &lt;dbl&gt;, `B-A#|Bb` &lt;dbl&gt;, `C-A#|Bb` &lt;dbl&gt;,\n#   `C#|Db-A#|Bb` &lt;dbl&gt;, `D-A#|Bb` &lt;dbl&gt;, `D#|Eb-A#|Bb` &lt;dbl&gt;, `E-A#|Bb` &lt;dbl&gt;,\n#   `F-A#|Bb` &lt;dbl&gt;, `F#|Gb-A#|Bb` &lt;dbl&gt;, `G-A#|Bb` &lt;dbl&gt;, `G#|Ab-A#|Bb` &lt;dbl&gt;,\n#   `A-B` &lt;dbl&gt;, `A#|Bb-B` &lt;dbl&gt;, `B-B` &lt;dbl&gt;, `C-B` &lt;dbl&gt;, `C#|Db-B` &lt;dbl&gt;,\n#   `D-B` &lt;dbl&gt;, `D#|Eb-B` &lt;dbl&gt;, `E-B` &lt;dbl&gt;, `F-B` &lt;dbl&gt;, `F#|Gb-B` &lt;dbl&gt;,\n#   `G-B` &lt;dbl&gt;, `G#|Ab-B` &lt;dbl&gt;, `A-C` &lt;dbl&gt;, `A#|Bb-C` &lt;dbl&gt;, `B-C` &lt;dbl&gt;, …\n\n\nWe can put all of this together like so (using the playlist variable from before.)\n\nchroma_names &lt;- c(\"C\", \"C#|Db\",\"D\", \"D#|Eb\", \"E\", \"F\", \"F#|Gb\",\"G\", \"G#|Ab\",\"A\", \"A#|Bb\",\"B\" )\n\n\nx &lt;- playlist |&gt;  \n  mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n  select(segments, track.name) |&gt;\n  unnest(segments) |&gt;\n  select(track.name, start, duration, pitches) |&gt;\n  unnest(cols = pitches)\n\n\nx$chroma &lt;- rep(chroma_names, nrow(x)/12)\n\nx &lt;- x |&gt;\n  filter(pitches == 1) |&gt;\n  mutate(chroma2 = lead(chroma))  |&gt;\n  select(track.name, chroma, chroma2)\n\n\nnew_df &lt;- x |&gt;\n  group_by(track.name) |&gt;\n  select(-track.name) |&gt;\n  table() |&gt;\n  prop.table() |&gt;\n  data.frame() |&gt;\n  tibble() |&gt;\n  mutate(bigram = paste(chroma, \"to \", chroma2)) |&gt;\n  select(track.name, Freq, bigram) |&gt;\n  pivot_wider(names_from = bigram, values_from = Freq)\n\nAdding missing grouping variables: `track.name`\n\ndf &lt;- cbind(playlist, new_df)\n\nWe can display this beast of a table like so.\n\ndf |&gt; datatable(filter = \"top\")\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\n\n\nx &lt;- playlist |&gt;  \n    mutate(segments = map2(segments, key, compmus_c_transpose)) |&gt;\n    select(segments) |&gt;\n    unnest(segments) |&gt;\n    select(start, duration, pitches) |&gt;\n    unnest(cols = pitches)\nx$chroma &lt;- rep(chroma_names, nrow(x)/12)\nx &lt;- x |&gt;\n  filter(pitches == 1) |&gt;\n  mutate(chroma2 = lead(chroma)) \nx\n\n# A tibble: 71,235 × 5\n   start duration pitches chroma chroma2\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  \n 1 0        0.232       1 G      C      \n 2 0.232    0.232       1 C      E      \n 3 0.464    0.227       1 E      C      \n 4 0.691    0.227       1 C      G      \n 5 0.917    0.220       1 G      C      \n 6 1.14     0.222       1 C      E      \n 7 1.36     0.255       1 E      C      \n 8 1.61     0.239       1 C      G      \n 9 1.85     0.226       1 G      C      \n10 2.08     0.232       1 C      E      \n# ℹ 71,225 more rows"
  },
  {
    "objectID": "class_notes/week_7.html#getting-timbre",
    "href": "class_notes/week_7.html#getting-timbre",
    "title": "Week 8: Adding Features",
    "section": "Getting timbre",
    "text": "Getting timbre\nTimbre is measured in Spotify with cepstra. This measurement was derived in speech analysis (and is a re-arrangement of the word spectrum-singular: cepstrum). An excellent overview can be found here.\nThe Spotify API writes that it is a “vector that includes 12 unbounded values roughly centered around 0. Those values are high level abstractions of the spectral surface, ordered by degree of importance.”\nThe first dimension is an average loudness, the second is about “brightness”, the third is about “flatness”, and the fourth through the twelfth roughly correspond to the strength of the attack.\n\n\n\nSpotify’s Timbre Functions\n\n\nTimbre for “This is America”\n\nthis_is_america &lt;-\n  get_tidy_audio_analysis(\"0b9oOr2ZgvyQu88wzixux9\") |&gt;  \n  compmus_align(bars, segments) |&gt; \n  select(bars) |&gt;                                     \n  unnest(bars) |&gt;                                     \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"mean\", norm = \"euclidean\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"mean\", norm = \"euclidean\"            \n      )\n  )\n\nHere, we can use the compmus_gather_timbre function from compmus. Here we see the distribution of cepstra in “This is America”.\n\nthis_is_america |&gt;\n  compmus_gather_timbre() |&gt; \n    ggplot(aes(y=value, x=basis)) + \n    geom_violin(position=\"dodge\", alpha=0.5) +\n    theme_bw()\n\n\n\n\nSimilar to a chromagram, we can plot the https://en.wikipedia.org/wiki/Mel-frequency_cepstrum to demonstrate changing timbre throughout the piece.\n\nthis_is_america |&gt;\n  compmus_gather_timbre() |&gt;\n  ggplot(\n    aes(\n      x = start + duration / 2,\n      width = duration,\n      y = basis,\n      fill = value\n    )\n  ) +\n  geom_tile() +\n  labs(x = \"Time (s)\", y = NULL, fill = \"Magnitude\") +\n  scale_fill_viridis_c() +                              \n  theme_classic()"
  },
  {
    "objectID": "class_notes/week_7.html#comparing-solo-instrument-pieces",
    "href": "class_notes/week_7.html#comparing-solo-instrument-pieces",
    "title": "Week 8: Adding Features",
    "section": "Comparing Solo Instrument Pieces",
    "text": "Comparing Solo Instrument Pieces\nLet’s compare a solo trumpet (BWV 1067, orchestral suite no.2) and a flute\n\nbwv1067_trumpet &lt;-\n  get_tidy_audio_analysis(\"6Tv19wcEeyvNBmhRGY59bY\") |&gt;  \n  compmus_align(bars, segments) |&gt; \n  select(bars) |&gt;                                     \n  unnest(bars) |&gt;                                     \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"mean\", norm = \"euclidean\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"mean\", norm = \"euclidean\"            \n      )\n  )\n\nbwv1067_trumpet |&gt;\n  compmus_gather_timbre() |&gt;\n  ggplot(\n    aes(\n      x = start + duration / 2,\n      width = duration,\n      y = basis,\n      fill = value\n    )\n  ) +\n  geom_tile() +\n  labs(x = \"Time (s)\", y = NULL, fill = \"Magnitude\") +\n  scale_fill_viridis_c() +                              \n  theme_classic()\n\n\n\n\nand flute (this recording).\n\nbwv1067_flute &lt;-\n  get_tidy_audio_analysis(\"2Ej8j8vN0hlRulT2DJKu52\") |&gt;  \n  compmus_align(bars, segments) |&gt; \n  select(bars) |&gt;                                     \n  unnest(bars) |&gt;                                     \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"mean\", norm = \"euclidean\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"mean\", norm = \"euclidean\"            \n      )\n  )\n\nbwv1067_flute |&gt;\n  compmus_gather_timbre() |&gt;\n  ggplot(\n    aes(\n      x = start + duration / 2,\n      width = duration,\n      y = basis,\n      fill = value\n    )\n  ) +\n  geom_tile() +\n  labs(x = \"Time (s)\", y = NULL, fill = \"Magnitude\") +\n  scale_fill_viridis_c() +                              \n  theme_classic()"
  },
  {
    "objectID": "class_notes/week_7.html#exercise-3",
    "href": "class_notes/week_7.html#exercise-3",
    "title": "Week 8: Adding Features",
    "section": "Exercise:",
    "text": "Exercise:\nHow might we incorporate timbre in our own research questions?\nI have a theory that tempo and brightness are related in our playlist. Let’s see if they’re related.\n\ntimbre &lt;- playlist |&gt;  \n  compmus_align(bars, segments) |&gt; \n  select(track.name, bars) |&gt;                                     \n  unnest(bars) |&gt;                                     \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"mean\", norm = \"euclidean\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"mean\", norm = \"euclidean\"            \n      )\n  )\n\ntimbre_coeffs &lt;- \n  timbre |&gt;\n  compmus_gather_timbre() |&gt; \n  select(track.name, basis, value) |&gt; \n  group_by(basis, track.name) |&gt; \n  mutate(mean_timbre = mean(value)) |&gt; \n  select(track.name, mean_timbre) |&gt; \n  unique() |&gt; \n  pivot_wider(names_from = basis, values_from = mean_timbre)\n\nAdding missing grouping variables: `basis`\n\nnew_playlist &lt;- merge(timbre_coeffs, playlist)\n\nnew_playlist |&gt; datatable(filter=\"top\")\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\n\nI now have a dataframe that includes timbre. So let’s look at how brightness (here operationalized as c02), might correspond with tempo.\n\ncor(new_playlist$c02, new_playlist$tempo)\n\nWarning in cor(new_playlist$c02, new_playlist$tempo): the standard deviation is\nzero\n\n\n[1] NA\n\n\nIt’s not a terribly strong correlation, but perhaps we should plot it anyway.\n\nplot(c02 ~ tempo, data=new_playlist)\nabline(lm(c02 ~ tempo, data=new_playlist), col=\"red\")\n\n\n\nsummary(lm(c02 ~ tempo, data=new_playlist))\n\nWarning in summary.lm(lm(c02 ~ tempo, data = new_playlist)): essentially\nperfect fit: summary may be unreliable\n\n\n\nCall:\nlm(formula = c02 ~ tempo, data = new_playlist)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-2.191e-16 -3.483e-18  6.060e-18  8.914e-18  5.841e-17 \n\nCoefficients:\n             Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) 6.078e-02  2.559e-17 2.376e+15  &lt; 2e-16 ***\ntempo       9.524e-19  1.908e-19 4.991e+00 2.61e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.491e-17 on 98 degrees of freedom\nMultiple R-squared:  0.5047,    Adjusted R-squared:  0.4997 \nF-statistic: 99.87 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nSo it’s significant, but not terribly useful (not accounting for much variance)."
  },
  {
    "objectID": "class_notes/week_7.html#self-similarity-matrices-and-form",
    "href": "class_notes/week_7.html#self-similarity-matrices-and-form",
    "title": "Week 8: Adding Features",
    "section": "Self-Similarity Matrices and Form",
    "text": "Self-Similarity Matrices and Form\nWe can look at musical form through the use of self-similarity matrices. There are some nice technical explanations of them here and here.\nPut succinctly, we want to compare each element of the sequence of musical events with one another.\nMüller writes:\n\nThe two most prominent structures in SSMs […] are referred to as blocks and paths. If the feature sequence captures musical properties that stay somewhat constant over the duration of an entire musical part, each of the feature vectors is similar to all other feature vectors within this segment. As a result, an entire block of large values appears in the SSM. In other words, homogeneity properties correspond to block-like structures. If the feature sequence contains two repeating subsequences (e.g., two segments corresponding to the same melody), the corresponding elements of the two subsequences are similar to each other. As a result, a path (or stripe) of high similarity running parallel to the main diagonal becomes visible in the SSM. In other words, repetitive properties correspond to path-like structures. (from this notebook)\n\n\n\n\nFrom Müller\n\n\n\nBrahms’s “Hungarian Dance No. 5” (performed by Isaac Stern)\n\nbrahms_stern &lt;-\n  get_tidy_audio_analysis(\"1PKtuxuLUbXeJNa05bfAOT\")  |&gt; \n  compmus_align(bars, segments) |&gt;                     \n  select(bars) |&gt;                                      \n  unnest(bars) |&gt;                                      \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"rms\", norm = \"manhattan\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"rms\", norm = \"manhattan\"              \n      )\n  )\n\nbrahms_stern |&gt;\n  compmus_self_similarity(timbre, \"cosine\") |&gt; \n  ggplot(\n    aes(\n      x = xstart + xduration / 2,\n      width = xduration,\n      y = ystart + yduration / 2,\n      height = yduration,\n      fill = d\n    )\n  ) +\n  geom_tile() +\n  coord_fixed() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\nBrahms’s “Hungarian Dance No. 5” (Abbado)\n\nbrahms_abbado &lt;-\n  get_tidy_audio_analysis(\"02TadnJNMcVjr4baY39H1p\")  |&gt; \n  compmus_align(bars, segments) |&gt;                     \n  select(bars) |&gt;                                      \n  unnest(bars) |&gt;                                      \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"rms\", norm = \"euclidean\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"rms\", norm = \"euclidean\"              \n      )\n  )\n\nbrahms_abbado |&gt;\n  compmus_self_similarity(timbre, \"cosine\") |&gt; \n  ggplot(\n    aes(\n      x = xstart + xduration / 2,\n      width = xduration,\n      y = ystart + yduration / 2,\n      height = yduration,\n      fill = d\n    )\n  ) +\n  geom_tile() +\n  coord_fixed() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\nBowie’s Life on Mars\nHere can we see a self-similarity matrix of David Bowie’s “Life on Mars”. Let’s listen along to it.\n\nlife_on_mars &lt;-\n  get_tidy_audio_analysis(\"3ZE3wv8V3w2T2f7nOCjV0N\")  |&gt; \n  compmus_align(bars, segments) |&gt;                     \n  select(bars) |&gt;                                      \n  unnest(bars) |&gt;                                      \n  mutate(\n    pitches =\n      map(segments,\n        compmus_summarise, pitches,\n        method = \"rms\", norm = \"euclidean\"              \n      )\n  ) |&gt;\n  mutate(\n    timbre =\n      map(segments,\n        compmus_summarise, timbre,\n        method = \"rms\", norm = \"euclidean\"              \n      )\n  )\n\n\nlife_on_mars |&gt;\n  compmus_self_similarity(timbre, \"cosine\") |&gt; \n  ggplot(\n    aes(\n      x = xstart + xduration / 2,\n      width = xduration,\n      y = ystart + yduration / 2,\n      height = yduration,\n      fill = d\n    )\n  ) +\n  geom_tile() +\n  coord_fixed() +\n  scale_fill_viridis_c(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"\", y = \"\")"
  },
  {
    "objectID": "class_notes/week_7.html#exercise-4",
    "href": "class_notes/week_7.html#exercise-4",
    "title": "Week 8: Adding Features",
    "section": "Exercise:",
    "text": "Exercise:\nLet’s look at two performances of the same piece. How do timbres change? Are there any hypotheses that might be worth looking into?"
  },
  {
    "objectID": "class_notes/week_8.html",
    "href": "class_notes/week_8.html",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "",
    "text": "Today:\n\nTalk about discussion posts\nQuick aside on grabbing specific features from Timbre\nLooking at lyric analysis\n\nWednesday:\n\nProjects due this week (Wednesday Night at 11:59)\nBegin discussion on Recommender Systems (the topic of project 4)\n\n\n\n## Loading some libraries\nlibrary(tidytext)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(textdata)\nlibrary(DT)\nlibrary(spotifyr)\n\n\nAttaching package: 'spotifyr'\n\nThe following object is masked from 'package:tidytext':\n\n    tidy\n\nlibrary(compmus)"
  },
  {
    "objectID": "class_notes/week_8.html#what-dataset-to-use",
    "href": "class_notes/week_8.html#what-dataset-to-use",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "What dataset to use?",
    "text": "What dataset to use?\nIt’s quite difficult to get lyrics from online sources at the moment. Many of the R interfaces for the Genius API seem to be quite deprecated. Kaggle does have many datasets available, including about 10GB of Genius data. For today, let’s just look at a small dataset of TAylor Swift lyrics."
  },
  {
    "objectID": "class_notes/week_8.html#what-is-tf-idf",
    "href": "class_notes/week_8.html#what-is-tf-idf",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "What is TF-IDF?",
    "text": "What is TF-IDF?\n\ntaylor &lt;- read.csv(\"~/Downloads/taylor_swift_lyrics.csv\")\n\nThere’s been some interesting stuff done on lyrics already. We can modify an existing tutorial on Ed Sheeran for today’s discussion.\n\ntaylor_word_count &lt;- taylor %&gt;%\n  unnest_tokens(word, lyric) %&gt;%\n  group_by(track_title, album) %&gt;%\n  summarise(num_words = n()) %&gt;%\n  arrange(desc(num_words)) \n\n`summarise()` has grouped output by 'track_title'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "class_notes/week_8.html#filtering-words",
    "href": "class_notes/week_8.html#filtering-words",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Filtering Words",
    "text": "Filtering Words\nThe anti_join function from the tidyverse basically joins all columns that don’t match something. Here, it’s the words that tidytext has defined has stop words.\n\nwords_filtered &lt;- taylor %&gt;%\n  unnest_tokens(word, lyric) %&gt;%\n  anti_join(stop_words) %&gt;%\n  distinct()\n\nJoining with `by = join_by(word)`"
  },
  {
    "objectID": "class_notes/week_8.html#plotting-the-most-words",
    "href": "class_notes/week_8.html#plotting-the-most-words",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Plotting the most words",
    "text": "Plotting the most words\n\nwords_filtered %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(30) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot() +\n    geom_col(aes(word, n), fill = 'light blue') +\n    theme(legend.position = \"none\", \n          plot.title = element_text(hjust = 0.5),\n          panel.grid.major = element_blank()) +\n    xlab(\"\") + \n    ylab(\"Song Count\") +\n    ggtitle(\"Most Frequently Used Words in Lyrics\") +\n    coord_flip() +\n     theme_bw()\n\nSelecting by n"
  },
  {
    "objectID": "class_notes/week_8.html#word-counts",
    "href": "class_notes/week_8.html#word-counts",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Word Counts",
    "text": "Word Counts\n\ntaylor_word_count %&gt;%\n  ggplot() +\n    geom_density(aes(x = num_words, fill = album), alpha = 0.5, position = 'stack') +\n    ylab(\"Song Density\") + \n    xlab(\"Word Count per Song\") +\n    ggtitle(\"Word Count Distribution\") +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.title = element_blank(),\n          panel.grid.minor.y = element_blank()) +\n          theme_bw()\n\n\n\n\n\nWords over Time\nHere we can see the changing word count over time in Taylor Swift’s albums.\n\nwords &lt;- words_filtered %&gt;%\n  group_by(year) %&gt;%\n  count(word, year, sort = TRUE) %&gt;%\n  slice(seq_len(8)) %&gt;%\n  ungroup() %&gt;%\n  arrange(year, n) %&gt;%\n  mutate(row = row_number())\n\nwords %&gt;%\n  ggplot(aes(row, n, fill = year)) +\n    geom_col(show.legend = NULL) +\n    labs(x = NULL, y = \"Song Count\") +\n    ggtitle(\"Words Across the Year\") + \n    theme_bw() +  \n    facet_wrap(~year, scales = \"free\") +\n    scale_x_continuous(  # This handles replacement of row \n      breaks = words$row, # notice need to reuse data frame\n      labels = words$word) +\n    coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_8.html#words-by-album",
    "href": "class_notes/week_8.html#words-by-album",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Words by Album",
    "text": "Words by Album\nThis basically does the same as before, but breaks it down by album and not year.\n\nwords &lt;- words_filtered %&gt;%\n  group_by(album) %&gt;%\n  count(word, album, sort = TRUE) %&gt;%\n  slice(seq_len(8)) %&gt;%\n  ungroup() %&gt;%\n  arrange(album, n) %&gt;%\n  mutate(row = row_number())\n\nwords %&gt;%\n  ggplot(aes(row, n, fill = album)) +\n    geom_col(show.legend = NULL) +\n    labs(x = NULL, y = \"Song Count\") +\n    ggtitle(\"Words Across the Album\") + \n    theme_bw() +  \n    facet_wrap(~album, scales = \"free\") +\n    scale_x_continuous(  # This handles replacement of row \n      breaks = words$row, # notice need to reuse data frame\n      labels = words$word) +\n    coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_8.html#tf-idf",
    "href": "class_notes/week_8.html#tf-idf",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "TF-IDF",
    "text": "TF-IDF\nWhere it starts to get interesting is when we can begin to employ metrics of frequency in relation to other data points. The Term Infrequency-Inverse Document Frequency (TF-IDF) metric is a good starting point for that.\nBasically, TF-IDF measures not just how often a word occurs, but how often it occurs in relation to other collections. So if there’s a word that occurs everywhere (like “love”), it’s not really weighted as highly.\n\ntfidf_words_album &lt;- taylor %&gt;%\n  unnest_tokens(word, lyric) %&gt;%\n  distinct() %&gt;%\n  count(album, word, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  bind_tf_idf(word, album, n) %&gt;%\n  arrange(desc(tf_idf))\n\nThis grabs the top 10 words per album. Notice that the tf_idf metric is simply the product of tf (term frequency) multiplied by idf (inverse document frequency).\n\ntop_tfidf_words_album &lt;- tfidf_words_album %&gt;% \n  group_by(album) %&gt;% \n  slice(seq_len(10)) %&gt;%\n  ungroup() %&gt;%\n  arrange(album, tf_idf) %&gt;%\n  mutate(row = row_number())  \n\ntop_tfidf_words_album %&gt;% datatable(filter=\"top\")\n\n\n\n\n\n\nWe can plot the data like so:\n\ntop_tfidf_words_album %&gt;%\n  ggplot(aes(x = row, tf_idf, fill = album)) +\n  geom_col(show.legend = NULL) +\n  labs(x = NULL, y = \"TF-IDF\") + \n  ggtitle(\"Important Words by Album (as measured by TF-IDF)\") +\n  theme_bw() +  \n  facet_wrap(~album,\n             scales = \"free\") +\n  scale_x_continuous(  # this handles replacement of row \n    breaks = top_tfidf_words_album$row, # notice need to reuse data frame\n    labels = top_tfidf_words_album$word) +\n  coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_8.html#sentiment-analysis",
    "href": "class_notes/week_8.html#sentiment-analysis",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nWe can then run sentiment analysis on the lyrics after unnesting and getting rid of stop words.\n\ntaylor_words &lt;- taylor %&gt;%\n  ##this breaks the lyrics up into words.\n  unnest_tokens(word, lyric) %&gt;% \n  ## the stop words come from tidytext.\n  anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\n\nWe will start with the bing classification (named after the PI of the research group, Liu Bing). This classifies words as either positive or negative sentiment. See this PsychStat book for more on these metrics.\n\ntaylor_bing &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"bing\"))\n\nJoining with `by = join_by(word)`\n\n\nWe can also run the nrc word list, which puts words into positive or negative categories, but also uses 8 other emotions, including:\n\nanger\nanticipation\ndisgust\nfear\njoy\nsadness\nsurprise\ntrust\n\nSee the “sentiment” column below in the table. To what extent do we agree with these categories? Do they seem useful to you?\n\ntaylor_nrc &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"nrc\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc %&gt;% datatable(filter =\"top\") \n\n\n\n\n\n\nWe can clean this up by getting rid of the positive and negative emotions, if we’d like:\n\ntaylor_nrc_no_pos_neg &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"nrc\")) %&gt;%\n  filter(!sentiment %in% c(\"positive\", \"negative\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc_no_pos_neg %&gt;% datatable(filter =\"top\")\n\n\n\n\n\n\nAnd here we can get have only the listing of words rated as “positive” or “negative”.\n\ntaylor_nrc_pos_neg &lt;- taylor_words %&gt;%\n  inner_join(get_sentiments(\"nrc\")) %&gt;%\n  filter(sentiment %in% c(\"positive\", \"negative\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc_pos_neg %&gt;% datatable(filter =\"top\")\n\n\n\n\n\n\nAnd here we can plot everything:\n\nnrc_plot &lt;- taylor_nrc %&gt;%\n  group_by(sentiment) %&gt;%\n  summarise(word_count = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(sentiment = reorder(sentiment, word_count)) %&gt;%\n  ggplot(aes(sentiment, word_count, fill = -word_count)) +\n  geom_col() +\n  theme_bw() +\n  labs(x = NULL, y = \"Word Count\") +\n  ggtitle(\"NRC Sentiment\") +\n  coord_flip()\nnrc_plot + guides(fill=FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\nWe can write a function to look at the various sentiments of a tune, which we can then join with other data.\n\ncalculate_sentiment &lt;- function(df){\n  df %&gt;%\n    group_by(track_title) %&gt;%\n    unnest_tokens(word, lyric) %&gt;%\n    left_join(get_sentiments(\"nrc\"), multiple = \"all\") %&gt;%\n    filter(!is.na(sentiment)) %&gt;%\n    count(sentiment) %&gt;%\n    pivot_wider(names_from = sentiment, values_from = n) %&gt;%\n    mutate(sentiment = positive - negative)\n}\n\ncalculate_sentiment(taylor) \n\nJoining with `by = join_by(word)`\n\n\nWarning in left_join(., get_sentiments(\"nrc\"), multiple = \"all\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 14 of `x` matches multiple rows in `y`.\nℹ Row 7687 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 94 × 12\n# Groups:   track_title [94]\n   track_title  anger anticipation disgust  fear   joy negative positive sadness\n   &lt;chr&gt;        &lt;int&gt;        &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;    &lt;int&gt;   &lt;int&gt;\n 1 ...Ready fo…     3           10       4     9     8        9        9       4\n 2 22               9           13       9     7    11       12       14      10\n 3 A Perfectly…     4            8       4     4    12        5       14       5\n 4 A Place In …     1            4       1     1     3        4        4       2\n 5 All Too Well     5            6       3     2     4       11        7       6\n 6 All You Had…    NA           NA       1    NA     2        5        2       4\n 7 Back To Dec…     1           17      NA     9    16        9       22       7\n 8 Bad Blood       22            3      20    22    27       24       27      22\n 9 Begin Again     NA            4      NA    NA     6        1       13       1\n10 Better Than…     9           14       6    12    11       14       17       5\n# ℹ 84 more rows\n# ℹ 3 more variables: surprise &lt;int&gt;, trust &lt;int&gt;, sentiment &lt;int&gt;\n\n\nAnd we can combine it with Spotify data!\nLet’s get the spotify data…\n\nts &lt;- get_artist_audio_features(\"Taylor Swift\")\n# ts &lt;- get_playlist_audio_fea\"tures(\"spotify\", \"3dgpO6mDWzdpMhyttrVi9t?si=b4f962245cb7468a\")\n\nAnd now we can combine the data together…\n\nts_basic_audio &lt;- ts %&gt;%\n  select(track_name, danceability:tempo, album_name) %&gt;%\n  rename(track_title = track_name)\n\njoined_ts &lt;- calculate_sentiment(taylor) %&gt;%\n  left_join(ts_basic_audio)\n\nJoining with `by = join_by(word)`\n\n\nWarning in left_join(., get_sentiments(\"nrc\"), multiple = \"all\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 14 of `x` matches multiple rows in `y`.\nℹ Row 7687 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nJoining with `by = join_by(track_title)`\n\njoined_ts %&gt;% \n  datatable(filter=\"top\")\n\n\n\n\n\n\nHere’s the code to plot the overall positive/negative of the tune:\n\nts &lt;- get_artist_audio_features(\"Taylor Swift\")\n\n\nts_basic_audio &lt;- ts %&gt;%\n  select(track_name, danceability:tempo) %&gt;%\n  rename(track_title = track_name) |&gt;\n  distinct()\n\njoined_ts &lt;- calculate_sentiment(taylor) %&gt;%\n  left_join(ts_basic_audio, multiple = \"all\")\n\nJoining with `by = join_by(word)`\n\n\nWarning in left_join(., get_sentiments(\"nrc\"), multiple = \"all\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 14 of `x` matches multiple rows in `y`.\nℹ Row 7687 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nJoining with `by = join_by(track_title)`\n\njoined_ts %&gt;%\n  select(track_title, positive, negative) %&gt;%\n  pivot_longer(cols = positive:negative, names_to = \"sentiment\", values_to = \"value\") %&gt;%\n  ggplot(aes(x = reorder(track_title, value), y = value, color = sentiment)) +\n  geom_point() +\n  coord_flip() +\n  theme_classic() +\n  labs(title = \"Taylor's Sentiments Across Tracks\",\n       y = 'Sentiment Value',\n       x = \"Track\")\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "class_notes/week_8.html#blur-and-oasis",
    "href": "class_notes/week_8.html#blur-and-oasis",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Blur and Oasis",
    "text": "Blur and Oasis\nThis data is taken from the “Million Song Dataset” from Spotify.\n\noasis &lt;- read.csv(\"oasis.csv\")\nblur &lt;- read.csv(\"blur.csv\")\n\nAnd we can begin getting words like this:\n\noasis_words &lt;- oasis %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  anti_join(stop_words) %&gt;%\n  distinct()\n\nContinuing with a summary like so…\n\nfull_word_count &lt;- oasis %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  group_by(track_title) %&gt;%\n  summarise(num_words = n()) %&gt;%\n  arrange(desc(num_words))"
  }
]